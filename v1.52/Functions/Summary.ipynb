{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hero.Coli Data Analysis Summary\n",
    "\n",
    "List of readworthy results from Hero.Coli data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "[Preparation](#preparation)\n",
    "1. [Google form analysis](#gform)\n",
    "2. [Game sessions](#sessions)\n",
    "3. [Per session and per user analysis](#peruser)\n",
    "4. [User comparison](#usercomp)\n",
    "5. [Game map](#map)\n",
    "    1. [List of questions](#qlist)\n",
    "    2. [English](#enform)\n",
    "    3. [French](#frform)\n",
    "    4. [Language selection](#langsel)\n",
    "3. [Basic operations](#basicops)\n",
    "4. [Checkpoint / Question matching](#checkquestmatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "<a id=preparation />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run \"../Functions/1. Google form analysis.ipynb\"\n",
    "%run \"../Functions/4. User comparison.ipynb\"\n",
    "%run \"../Utilities/Plot.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Google form analysis\n",
    "<a id=gform />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 answers to scientific questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setAnswerTemporalities(gform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSciBinarized = getAllBinarized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        allSciBinarized,\n",
    "                        _abs=True,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlations on game questions',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        allSciBinarized,\n",
    "                        _abs=True,\n",
    "                        _clustered=True,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = False,\n",
    "                        _figsize = (20,20),\n",
    "                        _metric='correlation'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 answers to all questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setAnswerTemporalities(gform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allBinarized = getAllBinarized( _source = correctAnswers + demographicAnswers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allBinarized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        allBinarized,\n",
    "                        _abs=True,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlation of all answers',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        allBinarized,\n",
    "                        _abs=True,\n",
    "                        _clustered=True,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = False,\n",
    "                        _figsize = (20,20),\n",
    "                        _metric = 'correlation',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 answers to all questions, only before having played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setAnswerTemporalities(gform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "befores = gform.copy()\n",
    "befores = befores[befores['Temporality'] == 'before']\n",
    "print(len(befores))\n",
    "allBeforesBinarized = getAllBinarized( _source = correctAnswers + demographicAnswers, _form = befores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        allBeforesBinarized,\n",
    "                        _abs=True,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlation of all answers - before playing',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 answers to all questions, only after having played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setAnswerTemporalities(gform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afters = gform.copy()\n",
    "afters = afters[afters['Temporality'] == 'after']\n",
    "print(len(afters))\n",
    "allAftersBinarized = getAllBinarized( _source = correctAnswers + demographicAnswers, _form = afters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        allAftersBinarized,\n",
    "                        _abs=True,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlation of all answers - after playing',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Game sessions\n",
    "<a id=sessions />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Per session and per user analysis\n",
    "<a id=peruser />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. User comparison\n",
    "<a id=usercomp />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresBefore = pd.Series()\n",
    "\n",
    "for userIndex in befores.index:\n",
    "    scoresBefore[str(userIndex)] = getScore(befores.loc[userIndex,localplayerguidkey])['before'][0][0]\n",
    "\n",
    "scoresAfter = pd.Series()\n",
    "for userIndex in afters.index:\n",
    "    scoresAfter[str(userIndex)] = getScore(afters.loc[userIndex,localplayerguidkey])['after'][0][0]\n",
    "\n",
    "print(\"before\\n\\tmean: {}\\n\\tstd: {}\\nafter\\n\\tmean: {}\\n\\tstd: {}\".format(\n",
    "    scoresBefore.mean(),\n",
    "    scoresBefore.std(),\n",
    "    scoresAfter.mean(),\n",
    "    scoresAfter.std())\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score on each question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSciBinarized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#totalPerQuestion = np.dot(np.ones(allSciBinarized.shape[0]), allSciBinarized)\n",
    "#totalPerQuestion.shape\n",
    "totalPerQuestionSci = np.dot(np.ones(allSciBinarized.shape[0]), allSciBinarized)\n",
    "totalPerQuestionAll = np.dot(np.ones(allBinarized.shape[0]), allBinarized)\n",
    "totalPerQuestionDFAll = pd.DataFrame(data=np.dot(np.ones(allBinarized.shape[0]), allBinarized), index=allBinarized.columns)\n",
    "percentagePerQuestionAll = totalPerQuestionDFAll*100 / allBinarized.shape[0]\n",
    "#totalPerQuestionDF\n",
    "#percentagePerQuestion\n",
    "\n",
    "#before\n",
    "totalPerQuestionDFBefore = pd.DataFrame(\n",
    "    data=np.dot(np.ones(allBeforesBinarized.shape[0]), allBeforesBinarized), index=allBeforesBinarized.columns\n",
    ")\n",
    "percentagePerQuestionBefore = totalPerQuestionDFBefore*100 / allBeforesBinarized.shape[0]\n",
    "\n",
    "#after\n",
    "totalPerQuestionDFAfter = pd.DataFrame(\n",
    "    data=np.dot(np.ones(allAftersBinarized.shape[0]), allAftersBinarized), index=allAftersBinarized.columns\n",
    ")\n",
    "percentagePerQuestionAfter = totalPerQuestionDFAfter*100 / allAftersBinarized.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_fig = plt.figure(figsize=(20,20))\n",
    "ax1 = plt.subplot(131)\n",
    "ax2 = plt.subplot(132)\n",
    "ax3 = plt.subplot(133)\n",
    "ax2.get_yaxis().set_visible(False)\n",
    "ax3.get_yaxis().set_visible(False)\n",
    "sns.heatmap(percentagePerQuestionAll.round().astype(int),ax=ax1,cmap=plt.cm.jet,square=True,annot=True,fmt='d', cbar=False)\n",
    "sns.heatmap(percentagePerQuestionBefore.round().astype(int),ax=ax2,cmap=plt.cm.jet,square=True,annot=True,fmt='d', cbar=False)\n",
    "sns.heatmap(percentagePerQuestionAfter.round().astype(int),ax=ax3,cmap=plt.cm.jet,square=True,annot=True,fmt='d', cbar=True)\n",
    "ax1.set_title('percentage correct per question - all')\n",
    "ax2.set_title('percentage correct per question - before')\n",
    "ax3.set_title('percentage correct per question - after')\n",
    "# Fine-tune figure; make subplots close to each other and hide x ticks for\n",
    "# all but bottom plot.\n",
    "_fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentagePerQuestionConcatenated = pd.concat([\n",
    "    percentagePerQuestionAll,\n",
    "    percentagePerQuestionBefore,\n",
    "    percentagePerQuestionAfter]\n",
    "    , axis=1)\n",
    "_fig = plt.figure(figsize=(20,20))\n",
    "_ax1 = plt.subplot(111)\n",
    "_ax1.set_title('percentage correct per question: all, before, after')\n",
    "sns.heatmap(percentagePerQuestionConcatenated.round().astype(int),ax=_ax1,cmap=plt.cm.jet,square=True,annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users who answered both before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realBefores = befores[befores['Have you played the current version of Hero.Coli?'] == 'No']\n",
    "len(realBefores), len(befores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bothall = gform.copy()\n",
    "realBefores = befores[befores['Have you played the current version of Hero.Coli?'] == 'No']\n",
    "bothall = bothall[bothall[localplayerguidkey].isin(realBefores[localplayerguidkey])]\n",
    "bothall = bothall[bothall[localplayerguidkey].isin(afters[localplayerguidkey])]\n",
    "\n",
    "bothbefores = bothall[bothall['Temporality'] == 'before']\n",
    "bothafters = bothall[bothall['Temporality'] == 'after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bothscoresBefore = pd.Series()\n",
    "\n",
    "for userIndex in bothbefores.index:\n",
    "    bothscoresBefore[str(userIndex)] = getScore(bothbefores.loc[userIndex,localplayerguidkey])['before'][0][0]\n",
    "\n",
    "bothscoresAfter = pd.Series()\n",
    "for userIndex in bothafters.index:\n",
    "    bothscoresAfter[str(userIndex)] = getScore(bothafters.loc[userIndex,localplayerguidkey])['after'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"count: {}\\nbefore\\n\\tmean: {}\\n\\tstd: {}\\nafter\\n\\tmean: {}\\n\\tstd: {}\".format(\n",
    "    len(bothall),\n",
    "    bothscoresBefore.mean(),\n",
    "    bothscoresBefore.std(),\n",
    "    bothscoresAfter.mean(),\n",
    "    bothscoresAfter.std())\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bothallBinarized = getAllBinarized( _source = correctAnswers + demographicAnswers, _form = bothall)\n",
    "bothallBeforesBinarized = getAllBinarized( _source = correctAnswers + demographicAnswers, _form = bothbefores)\n",
    "bothallAftersBinarized = getAllBinarized( _source = correctAnswers + demographicAnswers, _form = bothafters)\n",
    "\n",
    "plotCorrelationMatrix(\n",
    "                        bothallBinarized,\n",
    "                        _abs=True,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlation of all pre- & post-test answers of those who answered both',\n",
    "                    )\n",
    "\n",
    "plotCorrelationMatrix(\n",
    "                        bothallBeforesBinarized,\n",
    "                        _abs=True,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlation of all pre-test answers of those who answered both',\n",
    "                    )\n",
    "\n",
    "plotCorrelationMatrix(\n",
    "                        bothallAftersBinarized,\n",
    "                        _abs=True,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlation of all post-test answers of those who answered both',\n",
    "                    )\n",
    "\n",
    "\n",
    "bothtotalPerQuestionDFAll = pd.DataFrame(data=np.dot(np.ones(bothallBinarized.shape[0]), bothallBinarized), index=bothallBinarized.columns)\n",
    "bothpercentagePerQuestionAll = bothtotalPerQuestionDFAll*100 / bothallBinarized.shape[0]\n",
    "\n",
    "#before\n",
    "bothtotalPerQuestionDFBefore = pd.DataFrame(\n",
    "    data=np.dot(np.ones(bothallBeforesBinarized.shape[0]), bothallBeforesBinarized), index=bothallBeforesBinarized.columns\n",
    ")\n",
    "bothpercentagePerQuestionBefore = bothtotalPerQuestionDFBefore*100 / bothallBeforesBinarized.shape[0]\n",
    "\n",
    "#after\n",
    "bothtotalPerQuestionDFAfter = pd.DataFrame(\n",
    "    data=np.dot(np.ones(bothallAftersBinarized.shape[0]), bothallAftersBinarized), index=bothallAftersBinarized.columns\n",
    ")\n",
    "bothpercentagePerQuestionAfter = bothtotalPerQuestionDFAfter*100 / bothallAftersBinarized.shape[0]\n",
    "\n",
    "\n",
    "bothpercentagePerQuestionConcatenated = pd.concat([\n",
    "    bothpercentagePerQuestionAll,\n",
    "    bothpercentagePerQuestionBefore,\n",
    "    bothpercentagePerQuestionAfter]\n",
    "    , axis=1)\n",
    "_fig = plt.figure(figsize=(20,20))\n",
    "_ax1 = plt.subplot(111)\n",
    "_ax1.set_title('percentage correct per question: all, before, after')\n",
    "sns.heatmap(bothpercentagePerQuestionConcatenated.round().astype(int),ax=_ax1,cmap=plt.cm.jet,square=True,annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## percentagesCrossCorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentagesCrossCorrect = getCrossCorrectAnswers(allSciBinarized).round().astype(int)*100 / allSciBinarized.shape[0]\n",
    "percentagesCrossCorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_fig = plt.figure(figsize=(20,20))\n",
    "_ax = plt.subplot(111)\n",
    "_ax.set_title('percentage correct')\n",
    "sns.heatmap(percentagesCrossCorrect.round().astype(int),ax=_ax,cmap=plt.cm.jet,square=True,annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentagesConditionalCrossCorrect = getCrossCorrectAnswers(allSciBinarized).round().astype(int)*100 / totalPerQuestionSci\n",
    "percentagesConditionalCrossCorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_fig = plt.figure(figsize=(20,20))\n",
    "_ax = plt.subplot(111)\n",
    "_ax.set_title('percentage correct, conditionnally: p(y | x)')\n",
    "sns.heatmap(percentagesConditionalCrossCorrect.round().astype(int).fillna(0),ax=_ax,cmap=plt.cm.jet,square=True,annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small sample\n",
    "#allData = getAllUserVectorData( getAllUsers( df152 )[:10] )\n",
    "\n",
    "# complete set\n",
    "#allData = getAllUserVectorData( getAllUsers( df152 ) )\n",
    "\n",
    "# subjects who answered the gform\n",
    "allData = getAllUserVectorData( getAllResponders(), _source = correctAnswers )\n",
    "\n",
    "# 10 subjects who answered the gform\n",
    "#allData = getAllUserVectorData( getAllResponders()[:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAllUserVectorDataCorrelationMatrix(allData.T, _abs=True, _figsize = (40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(allData.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allBinarized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Game map\n",
    "<a id=map />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#players = df152.loc[:, playerFilteringColumns]\n",
    "players = safeGetNormalizedRedMetricsCSV( df152 )\n",
    "players.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#players = players.dropna(how='any')\n",
    "#players.head(1)\n",
    "#df152.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = players[~players['userId'].isin(excludedIDs)];\n",
    "players.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sessions (filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionscount = players[\"sessionId\"].nunique()\n",
    "sessionscount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sessions of dev IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uniqueplayers = players['userId']\n",
    "uniqueplayers = uniqueplayers.unique()\n",
    "uniqueplayers.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#uniqueplayers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uniqueplatforms = players['customData.platform'].unique()\n",
    "uniqueplatforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints passed / furthest checkpoint (unfiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = df152.loc[:, checkpointsRelevantColumns]\n",
    "checkpoints = checkpoints[checkpoints['type']=='reach'].loc[:,['section','sessionId']]\n",
    "checkpoints = checkpoints[checkpoints['section'].str.startswith('tutorial', na=False)]\n",
    "checkpoints = checkpoints.groupby(\"sessionId\")\n",
    "checkpoints = checkpoints.max()\n",
    "checkpoints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxCheckpointTable = pd.DataFrame({\"maxCheckpoint\" : checkpoints.values.flatten()})\n",
    "maxCheckpointCounts = maxCheckpointTable[\"maxCheckpoint\"].value_counts()\n",
    "maxCheckpointCounts['Start'] = None\n",
    "maxCheckpointCounts = maxCheckpointCounts.sort_index()\n",
    "print('\\nmaxCheckpointCounts=\\n{0}'.format(str(maxCheckpointCounts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "maxCheckpointCountsTable = pd.DataFrame({\"maxCheckpoint\" : maxCheckpointCounts.values})\n",
    "maxCheckpointCountsTableCount = maxCheckpointCountsTable.sum(0)[0]\n",
    "maxCheckpointCountsTableCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoints.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCheckpointCountsTable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCheckpointCountsTable.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "genericTreatment( maxCheckpointCountsTable, \"best checkpoint reached\", \"game sessions\", 0, maxCheckpointCountsTableCount, False, True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starts = df152.loc[:, checkpointsRelevantColumns]\n",
    "#starts = checkpoints[checkpoints['type']=='start'].loc[:,['playerId']]\n",
    "#starts = checkpoints[checkpoints['section'].str.startswith('tutorial', na=False)]\n",
    "#starts = checkpoints.groupby(\"playerId\")\n",
    "#starts = checkpoints.max()\n",
    "#starts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTutorial1Count = sessionscount\n",
    "neverReachedGameSessionCount = startTutorial1Count - maxCheckpointCountsTableCount\n",
    "fullMaxCheckpointCounts = maxCheckpointCounts\n",
    "fullMaxCheckpointCounts['Start'] = neverReachedGameSessionCount\n",
    "fullMaxCheckpointCountsTable = pd.DataFrame({\"fullMaxCheckpoint\" : fullMaxCheckpointCounts.values})\n",
    "\n",
    "genericTreatment( fullMaxCheckpointCountsTable, \"best checkpoint reached\", \"game sessions\", 0, startTutorial1Count, False, True )\n",
    "\n",
    "print('\\nfullMaxCheckpointCountsTable=\\n{0}'.format(fullMaxCheckpointCountsTable))\n",
    "fullMaxCheckpointCountsTable.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration of playing sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "durations = players.groupby(\"sessionId\").agg({ \"serverTime\": [ np.min, np.max  ] })\n",
    "durations[\"duration\"] = pd.to_datetime(durations[\"serverTime\"][\"amax\"]) - pd.to_datetime(durations[\"serverTime\"][\"amin\"])\n",
    "durations[\"duration\"] = durations[\"duration\"].map(lambda x: np.timedelta64(x, 's'))\n",
    "durations = durations.sort_values(by=['duration'], ascending=[False])\n",
    "durations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "durations.loc[:,'duration']\n",
    "durations = durations[4:]\n",
    "durations[\"duration_seconds\"] = durations[\"duration\"].map(lambda x: pd.Timedelta(x).seconds)\n",
    "maxDuration = np.max(durations[\"duration_seconds\"])\n",
    "durations[\"duration_rank\"] = durations[\"duration_seconds\"].rank(ascending=False)\n",
    "durations.plot(x=\"duration_rank\", y=\"duration_seconds\")\n",
    "plt.xlabel(\"game session\")\n",
    "plt.ylabel(\"time played (s)\")\n",
    "plt.legend('')\n",
    "plt.xlim(0, sessionscount)\n",
    "plt.ylim(0, maxDuration)\n",
    "durations[\"duration_seconds\"].describe()\n",
    "durations.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
