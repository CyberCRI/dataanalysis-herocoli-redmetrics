{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hero.Coli Data Analysis Summary\n",
    "\n",
    "List of readworthy results from Hero.Coli data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "[Preparation](#preparation)\n",
    "1. [Google form analysis](#gform)\n",
    "2. [Game sessions](#sessions)\n",
    "3. [Per session and per user analysis](#peruser)\n",
    "4. [User comparison](#usercomp)\n",
    "5. [Game map](#map)\n",
    "    1. [List of questions](#qlist)\n",
    "    2. [English](#enform)\n",
    "    3. [French](#frform)\n",
    "    4. [Language selection](#langsel)\n",
    "3. [Basic operations](#basicops)\n",
    "4. [Checkpoint / Question matching](#checkquestmatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "<a id=preparation />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run \"../Functions/1. Google form analysis.ipynb\"\n",
    "%run \"../Functions/4. User comparison.ipynb\"\n",
    "%run \"../Utilities/Plot.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Google form analysis\n",
    "<a id=gform />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 answers to scientific questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setAnswerTemporalities(gform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSciBinarized = getAllBinarized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        allSciBinarized,\n",
    "                        _abs=True,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlations on game questions',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        allSciBinarized,\n",
    "                        _abs=True,\n",
    "                        _clustered=True,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = False,\n",
    "                        _figsize = (20,20),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 answers to all questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setAnswerTemporalities(gform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allBinarized = getAllBinarized( _source = correctAnswers + demographicAnswers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        allBinarized,\n",
    "                        _abs=True,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlation of all answers',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        allBinarized,\n",
    "                        _abs=True,\n",
    "                        _clustered=True,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = False,\n",
    "                        _figsize = (20,20),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 answers to all questions, only before having played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setAnswerTemporalities(gform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "befores = gform.copy()\n",
    "befores = befores[befores['Temporality'] == 'before']\n",
    "print(len(befores))\n",
    "allBeforesBinarized = getAllBinarized( _source = correctAnswers + demographicAnswers, _form = befores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        allBeforesBinarized,\n",
    "                        _abs=True,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlation of all answers - before playing',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 answers to all questions, only after having played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setAnswerTemporalities(gform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afters = gform.copy()\n",
    "afters = afters[afters['Temporality'] == 'after']\n",
    "print(len(afters))\n",
    "allAftersBinarized = getAllBinarized( _source = correctAnswers + demographicAnswers, _form = afters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        allAftersBinarized,\n",
    "                        _abs=True,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlation of all answers - after playing',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Game sessions\n",
    "<a id=sessions />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Per session and per user analysis\n",
    "<a id=peruser />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. User comparison\n",
    "<a id=usercomp />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresBefore = pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getScore(befores.loc[userIndex,localplayerguidkey])['before'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for userIndex in befores.index:\n",
    "    scoresBefore[str(userIndex)] = getScore(befores.loc[userIndex,localplayerguidkey])['before'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresBefore.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresBefore.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresAfter = pd.Series()\n",
    "for userIndex in afters.index:\n",
    "    scoresAfter[str(userIndex)] = getScore(afters.loc[userIndex,localplayerguidkey])['after'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresAfter.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scoresAfter.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score on each question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSciBinarized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalPerQuestion = np.dot(np.ones(allSciBinarized.shape[0]), allSciBinarized)\n",
    "totalPerQuestion.shape\n",
    "\n",
    "totalPerQuestionDF = pd.DataFrame(data=np.dot(np.ones(allSciBinarized.shape[0]), allSciBinarized), index=allSciBinarized.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalPerQuestionDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "percentagePerQuestion = totalPerQuestionDF*100 / allSciBinarized.shape[0]\n",
    "percentagePerQuestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_fig = plt.figure(figsize=(20,20))\n",
    "_ax = plt.subplot(111)\n",
    "_ax.set_title('percentage correct per question')\n",
    "sns.heatmap(percentagePerQuestion.astype(int),ax=_ax,cmap=plt.cm.jet,square=True,annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentagesCrossCorrect = getCrossCorrectAnswers(allSciBinarized).astype(int)*100 / allSciBinarized.shape[0]\n",
    "percentagesCrossCorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_fig = plt.figure(figsize=(20,20))\n",
    "_ax = plt.subplot(111)\n",
    "_ax.set_title('percentage correct')\n",
    "sns.heatmap(percentagesCrossCorrect.astype(int),ax=_ax,cmap=plt.cm.jet,square=True,annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentagesConditionalCrossCorrect = getCrossCorrectAnswers(allSciBinarized).astype(int)*100 / totalPerQuestion\n",
    "percentagesConditionalCrossCorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_fig = plt.figure(figsize=(20,20))\n",
    "_ax = plt.subplot(111)\n",
    "_ax.set_title('percentage correct, conditionnally: p(y | x)')\n",
    "sns.heatmap(percentagesConditionalCrossCorrect.astype(int).fillna(0),ax=_ax,cmap=plt.cm.jet,square=True,annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small sample\n",
    "#allData = getAllUserVectorData( getAllUsers( df152 )[:10] )\n",
    "\n",
    "# complete set\n",
    "#allData = getAllUserVectorData( getAllUsers( df152 ) )\n",
    "\n",
    "# subjects who answered the gform\n",
    "allData = getAllUserVectorData( getAllResponders() )\n",
    "\n",
    "# 10 subjects who answered the gform\n",
    "#allData = getAllUserVectorData( getAllResponders()[:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(allData.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allBinarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run \"../Functions/1. Google form analysis.ipynb\"\n",
    "%run \"../Functions/4. User comparison.ipynb\"\n",
    "%run \"../Utilities/Plot.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAllUserVectorDataCorrelationMatrix(allData.T, _abs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Game map\n",
    "<a id=map />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#players = df152.loc[:, playerFilteringColumns]\n",
    "players = safeGetNormalizedRedMetricsCSV( df152 )\n",
    "players.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#players = players.dropna(how='any')\n",
    "#players.head(1)\n",
    "#df152.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = players[~players['userId'].isin(excludedIDs)];\n",
    "players.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sessions (filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionscount = players[\"sessionId\"].nunique()\n",
    "sessionscount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sessions of dev IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uniqueplayers = players['userId']\n",
    "uniqueplayers = uniqueplayers.unique()\n",
    "uniqueplayers.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#uniqueplayers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uniqueplatforms = players['customData.platform'].unique()\n",
    "uniqueplatforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints passed / furthest checkpoint (unfiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = df152.loc[:, checkpointsRelevantColumns]\n",
    "checkpoints = checkpoints[checkpoints['type']=='reach'].loc[:,['section','sessionId']]\n",
    "checkpoints = checkpoints[checkpoints['section'].str.startswith('tutorial', na=False)]\n",
    "checkpoints = checkpoints.groupby(\"sessionId\")\n",
    "checkpoints = checkpoints.max()\n",
    "checkpoints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxCheckpointTable = pd.DataFrame({\"maxCheckpoint\" : checkpoints.values.flatten()})\n",
    "maxCheckpointCounts = maxCheckpointTable[\"maxCheckpoint\"].value_counts()\n",
    "maxCheckpointCounts['Start'] = None\n",
    "maxCheckpointCounts = maxCheckpointCounts.sort_index()\n",
    "print('\\nmaxCheckpointCounts=\\n{0}'.format(str(maxCheckpointCounts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "maxCheckpointCountsTable = pd.DataFrame({\"maxCheckpoint\" : maxCheckpointCounts.values})\n",
    "maxCheckpointCountsTableCount = maxCheckpointCountsTable.sum(0)[0]\n",
    "maxCheckpointCountsTableCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoints.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCheckpointCountsTable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCheckpointCountsTable.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "genericTreatment( maxCheckpointCountsTable, \"best checkpoint reached\", \"game sessions\", 0, maxCheckpointCountsTableCount, False, True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starts = df152.loc[:, checkpointsRelevantColumns]\n",
    "#starts = checkpoints[checkpoints['type']=='start'].loc[:,['playerId']]\n",
    "#starts = checkpoints[checkpoints['section'].str.startswith('tutorial', na=False)]\n",
    "#starts = checkpoints.groupby(\"playerId\")\n",
    "#starts = checkpoints.max()\n",
    "#starts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTutorial1Count = sessionscount\n",
    "neverReachedGameSessionCount = startTutorial1Count - maxCheckpointCountsTableCount\n",
    "fullMaxCheckpointCounts = maxCheckpointCounts\n",
    "fullMaxCheckpointCounts['Start'] = neverReachedGameSessionCount\n",
    "fullMaxCheckpointCountsTable = pd.DataFrame({\"fullMaxCheckpoint\" : fullMaxCheckpointCounts.values})\n",
    "\n",
    "genericTreatment( fullMaxCheckpointCountsTable, \"best checkpoint reached\", \"game sessions\", 0, startTutorial1Count, False, True )\n",
    "\n",
    "print('\\nfullMaxCheckpointCountsTable=\\n{0}'.format(fullMaxCheckpointCountsTable))\n",
    "fullMaxCheckpointCountsTable.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration of playing sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "durations = players.groupby(\"sessionId\").agg({ \"serverTime\": [ np.min, np.max  ] })\n",
    "durations[\"duration\"] = pd.to_datetime(durations[\"serverTime\"][\"amax\"]) - pd.to_datetime(durations[\"serverTime\"][\"amin\"])\n",
    "durations[\"duration\"] = durations[\"duration\"].map(lambda x: np.timedelta64(x, 's'))\n",
    "durations = durations.sort_values(by=['duration'], ascending=[False])\n",
    "durations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "durations.loc[:,'duration']\n",
    "durations = durations[4:]\n",
    "durations[\"duration_seconds\"] = durations[\"duration\"].map(lambda x: pd.Timedelta(x).seconds)\n",
    "maxDuration = np.max(durations[\"duration_seconds\"])\n",
    "durations[\"duration_rank\"] = durations[\"duration_seconds\"].rank(ascending=False)\n",
    "durations.plot(x=\"duration_rank\", y=\"duration_seconds\")\n",
    "plt.xlabel(\"game session\")\n",
    "plt.ylabel(\"time played (s)\")\n",
    "plt.legend('')\n",
    "plt.xlim(0, sessionscount)\n",
    "plt.ylim(0, maxDuration)\n",
    "durations[\"duration_seconds\"].describe()\n",
    "durations.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
