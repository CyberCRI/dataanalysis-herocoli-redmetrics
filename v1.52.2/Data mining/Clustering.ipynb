{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run dataFormating.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from pandas.plotting import scatter_matrix, parallel_coordinates\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "from math import *\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-usable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function counts the number of occurences for each unique element in a list\n",
    "def get_cnt(lVals):\n",
    "    d = dict(zip(lVals, [0] * len(lVals)))\n",
    "    for x in lVals:\n",
    "        d[x] += 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function fit a KMeans clustering model on the data, for each number of clusters in a specified range.\n",
    "# It displays the silhouette analysis plot for each number of clusters and outputs the silhouette scores\n",
    "# The higher the silhouette score, the more distinct the clusters are. In a good clustering, all clusters raise above the average\n",
    "# Source: http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py\n",
    "def tryKmeans(dataset, rangeNbClusters=[2, 3, 4, 5]):\n",
    "    results = []\n",
    "    \n",
    "    # For each number of clusters\n",
    "    for n_clusters in rangeNbClusters:\n",
    "        # Create a subplot with 1 row and 1 column, make it possible to easily add plots in the function later if needed\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(12, 6)\n",
    "\n",
    "        # The 1st subplot is the silhouette plot\n",
    "        # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "        # lie within [-0.1, 1]\n",
    "        ax.set_xlim([-0.1, 1])\n",
    "        # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "        # plots of individual clusters, to demarcate them clearly.\n",
    "        ax.set_ylim([0, len(dataset) + (n_clusters + 1) * 10])\n",
    "\n",
    "        # Initialize the clusterer with n_clusters value and a random generator\n",
    "        # seed of 10 for reproducibility.\n",
    "        clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "        cluster_labels = clusterer.fit_predict(dataset)\n",
    "\n",
    "        # The silhouette_score gives the average value for all the samples.\n",
    "        # This gives a perspective into the density and separation of the formed\n",
    "        # clusters\n",
    "        silhouette_avg = silhouette_score(dataset, cluster_labels)\n",
    "        \n",
    "        # Save the silhouette score, the size of each cluster and the cluster assignement labels\n",
    "        results.append([n_clusters, silhouette_avg, get_cnt(clusterer.labels_), clusterer.labels_])\n",
    "\n",
    "        # Compute the silhouette scores for each sample\n",
    "        sample_silhouette_values = silhouette_samples(dataset, cluster_labels)\n",
    "\n",
    "        y_lower = 10\n",
    "        for i in range(n_clusters):\n",
    "            # Aggregate the silhouette scores for samples belonging to\n",
    "            # cluster i, and sort them\n",
    "            ith_cluster_silhouette_values = \\\n",
    "                sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "            ith_cluster_silhouette_values.sort()\n",
    "\n",
    "            size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "\n",
    "            color = cm.spectral(float(i) / n_clusters)\n",
    "            ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                              0, ith_cluster_silhouette_values,\n",
    "                              facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "            # Label the silhouette plots with their cluster numbers at the middle\n",
    "            ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "            # Compute the new y_lower for next plot\n",
    "            y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "        ax.set_title(\"The silhouette plot for the various clusters.\")\n",
    "        ax.set_xlabel(\"The silhouette coefficient values\")\n",
    "        ax.set_ylabel(\"Cluster label\")\n",
    "\n",
    "        # The vertical line for average silhouette score of all the values\n",
    "        ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "        ax.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        ax.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "        plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                      \"with n_clusters = %d\" % n_clusters),\n",
    "                     fontsize=14, fontweight='bold')\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes the initial data, result of tryKmeans and a chosen number of clusters\n",
    "# It returns the label assignements of the sample\n",
    "# If specified, it plots the parallel coordinates plot\n",
    "# If specified, display only specified clusters\n",
    "def detailsKmeans(initData, kmeansResult, nbClusters, displayParallelCoord = False, clusterLabels = [], clustersToDisplay = [], scale = False):\n",
    "    # Add cluster assignement to the data\n",
    "    assignements = list(kmeansResult.loc[kmeansResult[\"Number of clusters\"] == nbClusters,'Label assignements'])[0]\n",
    "    assignements = pd.DataFrame(data = assignements, columns = [\"Index of cluster\"], index = initData.index)\n",
    "    \n",
    "    # Displays\n",
    "    if displayParallelCoord:\n",
    "        nbGroups = ceil(len(initData.columns) / 8)\n",
    "        print(\"Will split columns into {} groups\".format(nbGroups))\n",
    "        progressBar = FloatProgress(value = 0.0, min = 0.0, max = nbGroups)\n",
    "        display(progressBar)\n",
    "        # The data is split into several groups of columns for display\n",
    "        for i in range(nbGroups):\n",
    "            # Plot the data for the selected columns\n",
    "            rangeMin = i * 8\n",
    "            rangeMax = min(len(initData.columns), i * 8 + 9)\n",
    "            scaledData = initData.iloc[:,rangeMin:rangeMax].copy()\n",
    "            # Deal with scaling if specified\n",
    "            if scale:\n",
    "                col = scaledData.columns\n",
    "                ind = scaledData.index\n",
    "                scaledData = preprocessing.scale(scaledData)\n",
    "                scaledData = pd.DataFrame(data = scaledData, columns=col, index=ind)\n",
    "            labelledData = pd.concat([scaledData, assignements], axis = 1, join = \"inner\")\n",
    "            # Select only some clusters if specified\n",
    "            if len(clustersToDisplay) > 0:\n",
    "                labelledData = labelledData.loc[labelledData[\"Index of cluster\"].isin(clustersToDisplay), :]\n",
    "            fig, ax = plt.subplots()\n",
    "            fig.set_size_inches(17, 3)\n",
    "            ax = parallel_coordinates(labelledData, 'Index of cluster')\n",
    "            \n",
    "            # Beautification\n",
    "            plt.xticks(rotation=60)\n",
    "            if len(clusterLabels) > 0:\n",
    "                handles, labels = ax.get_legend_handles_labels()\n",
    "                ax.legend(handles, clusterLabels)\n",
    "            plt.show()\n",
    "            \n",
    "            progressBar.value += 1.0\n",
    "    \n",
    "    return assignements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes the frequency of True answers (scientific questions) or of each possible answer (non-scientific questions) for each cluster of a given clustering\n",
    "# The specified question can be \"allScience\" (return table for all scientific questions) or the tag of any question\n",
    "# If specific question and nbClusters = 2, print t-test between clusters\n",
    "def freqByCluster(initData, kmeansResult, nbClusters, question) :\n",
    "    # Add cluster assignement to the data\n",
    "    assignements = list(kmeansResult.loc[kmeansResult[\"Number of clusters\"] == nbClusters,'Label assignements'])[0]\n",
    "    assignements = pd.DataFrame(data = assignements, columns = [\"Index of cluster\"], index = initData.index)\n",
    "    \n",
    "    # Get the size of the clusters\n",
    "    sizeOfClusters = kmeansResult.loc[kmeansResult[\"Number of clusters\"] == nbClusters,'Size of cluster'][0]\n",
    "    \n",
    "    # All scientific questions\n",
    "    if question == \"allScience\":\n",
    "        labelledData = initData.loc[:, \"Q1\":\"Q27\"]\n",
    "        labelledData = pd.concat([labelledData, assignements], axis = 1, join = \"inner\")\n",
    "        answersByCluster = pd.DataFrame()\n",
    "        for cluster in range(nbClusters):\n",
    "            nameOfCluster = \"Cluster \" + str(cluster)\n",
    "            answersByCluster[nameOfCluster] = labelledData[labelledData[\"Index of cluster\"] == cluster].sum()\n",
    "            answersByCluster[nameOfCluster] = answersByCluster[nameOfCluster].divide(sizeOfClusters[cluster])\n",
    "        answersByCluster.drop(\"Index of cluster\", inplace=True)\n",
    "    # For a specific question\n",
    "    else:\n",
    "        labelledData = pd.concat([initData, assignements], axis = 1, join = \"inner\")\n",
    "        labelledData = labelledData.loc[:,[question, \"Index of cluster\"]]\n",
    "        if (nbClusters == 2):\n",
    "            group1 = labelledData[labelledData[\"Index of cluster\"] == 0][question]\n",
    "            group2 = labelledData[labelledData[\"Index of cluster\"] == 1][question]\n",
    "            print(stats.ttest_ind(group1, group2))\n",
    "        answersByCluster = pd.DataFrame()\n",
    "        for cluster in range(nbClusters):\n",
    "            nameOfCluster = \"Cluster \" + str(cluster)\n",
    "            frequencies = labelledData[labelledData[\"Index of cluster\"] == cluster].groupby(question).count()\n",
    "            frequencies = frequencies.divide(sizeOfClusters[cluster])\n",
    "            frequencies = pd.DataFrame(data = frequencies[\"Index of cluster\"].values, index = list(frequencies.index), columns = [nameOfCluster])\n",
    "            answersByCluster = pd.concat([answersByCluster, frequencies], axis=1)\n",
    "        answersByCluster.fillna(value = 0, inplace = True)\n",
    "        \n",
    "    return answersByCluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can the data be clustered according to the answers given to the before questionnaire?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If scientific questions are coded by answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to matrix\n",
    "beforeMat = beforeForms.as_matrix()\n",
    "# Standardise data\n",
    "beforeMat = preprocessing.scale(beforeMat)\n",
    "# Cluster using KMeans, and silhouette analysis to evaluate the pertinence of the clusters\n",
    "beforeResults = tryKmeans(beforeMat)\n",
    "# Format results as a DataFrame\n",
    "beforeResults = pd.DataFrame(data=beforeResults, columns=['Number of clusters', 'Average silhouette score', 'Size of cluster', 'Label assignements'])\n",
    "beforeResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: No interesting clustering (30/11/2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If scientific questions are coded by correctedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to matrix\n",
    "beforeCorrectedMat = beforeCorrectedForms.as_matrix()\n",
    "# Standardise data\n",
    "beforeCorrectedMat = preprocessing.scale(beforeCorrectedMat)\n",
    "# Cluster using KMeans, and silhouette analysis to evaluate the pertinence of the clusters\n",
    "beforeCorrectedResults = tryKmeans(beforeCorrectedMat)\n",
    "# Format results as a DataFrame\n",
    "beforeCorrectedResults = pd.DataFrame(data=beforeCorrectedResults, columns=['Number of clusters', 'Average silhouette score', 'Size of cluster', 'Label assignements'])\n",
    "beforeCorrectedResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Possible 2-clustering (17/01/2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display parallel coordinates plot\n",
    "assignements = detailsKmeans(beforeCorrectedForms, beforeCorrectedResults, 2, displayParallelCoord=True, clusterLabels=[\"Group 1\", \"Group 2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute frequency of correct answers for each group and each question\n",
    "correctAnswersByCluster = freqByCluster(beforeCorrectedForms, beforeCorrectedResults, 2, \"allScience\")\n",
    "correctAnswersByCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(correctAnswersByCluster[\"Cluster 0\"], correctAnswersByCluster[\"Cluster 1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute frequency of different levels of biology study for each group and each question\n",
    "biologyStudyPerCluster = freqByCluster(beforeCorrectedForms, beforeCorrectedResults, 2, \"biologyStudy\")\n",
    "biologyStudyPerCluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute frequency of different levels of biology interest for each group and each question\n",
    "biologyInterestPerCluster = freqByCluster(beforeCorrectedForms, beforeCorrectedResults, 2, \"biologyInterest\")\n",
    "biologyInterestPerCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute score and compare clusters\n",
    "beforeCorrectedForms[\"sum\"] = beforeCorrectedForms.loc[:,\"Q1\":\"Q27\"].sum(axis=1)\n",
    "scorePerCluster = freqByCluster(beforeCorrectedForms, beforeCorrectedResults, 2, \"sum\")\n",
    "scorePerCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Two clusters, with one small cluster of highly interested subjects with very high level of correct answers (and high score) and big cluster of average interest and low level of correct answers (and low score). (30/01/2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can the data be clustered according to the answers given to the after questionnaire?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If scientific questions are coded by answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to matrix\n",
    "afterMat = afterForms.as_matrix()\n",
    "# Standardise the data\n",
    "afterMat = preprocessing.scale(afterMat)\n",
    "# Cluster using KMeans, and silhouette analysis to evaluate the pertinence of the clusters\n",
    "afterResults = tryKmeans(afterMat)\n",
    "# Format results as a DataFrame\n",
    "afterResults = pd.DataFrame(data=afterResults, columns=['Number of clusters', 'Average silhouette score', 'Size of cluster', 'Label assignements'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: No interesting clustering (30/11/2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If scientific questions are coded by correctedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to matrix\n",
    "afterCorrectedMat = afterCorrectedForms.as_matrix()\n",
    "# Standardise the data\n",
    "afterCorrectedMat = preprocessing.scale(afterCorrectedMat)\n",
    "# Cluster using KMeans, and silhouette analysis to evaluate the pertinence of the clusters\n",
    "afterCorrectedResults = tryKmeans(afterCorrectedMat)\n",
    "# Format results as a DataFrame\n",
    "afterCorrectedResults = pd.DataFrame(data=afterCorrectedResults, columns=['Number of clusters', 'Average silhouette score', 'Size of cluster', 'Label assignements'])\n",
    "afterCorrectedResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: No interesting clustering (16/01/2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can the data be clustered according to the answers given to the questionnaire?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If scientific questions are coded by answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If only before and after questionnaires are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to matrix\n",
    "defMat = defForms.drop(\"temporality\", axis=1).as_matrix()\n",
    "# Standardise data\n",
    "defMat = preprocessing.scale(defMat)\n",
    "# Cluster using KMeans, and silhouette analysis to evaluate the pertinence of the clusters\n",
    "defResults = tryKmeans(defMat)\n",
    "# Format results as a DataFrame\n",
    "defResults = pd.DataFrame(data=defResults, columns=['Number of clusters', 'Average silhouette score', 'Size of cluster', 'Label assignements'])\n",
    "defResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: The data could be clustered in two groups\n",
    "Note: The silhouette coefficient probably never goes very high because of the binary aspect of most of the data (30/11/2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis: The two groups identified by the clustering algorithm correspond to the \"before\" and \"after\" questionnaires.\n",
    "Note: The temporality feature was not included in the clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display parallel coordinates plot and confusion matrix\n",
    "assignements = detailsKmeans(defForms, defResults, 2, displayParallelCoord=True, clusterLabels=[\"Predicted before\", \"Predicted after\"])\n",
    "assignements = pd.concat([assignements, defForms[\"temporality\"]], axis=1, join='inner')\n",
    "defConfusionMat = confusion_matrix(list(assignements[\"temporality\"]), list(assignements[\"Index of cluster\"]))\n",
    "defConfusionMat = pd.DataFrame(data = defConfusionMat, columns=[\"Predicted before\", \"Predicted after\"], index = [\"Actual after\", \"Actual before\"])\n",
    "defConfusionMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Hypothesis verified. Parallel coordinates plot is not very informative because of the high number of features and the high proportion of binary features, use only for data exploration (30/12/2017)\n",
    "Would be interesting to see if those that are predicted before while they are after share specific characteristics. (16/01/2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If all questionnaires are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to matrix\n",
    "allMat = allForms.drop(\"temporality\", axis=1).as_matrix()\n",
    "# Standardise data\n",
    "allMat = preprocessing.scale(allMat)\n",
    "# Cluster using KMeans, and silhouette analysis to evaluate the pertinence of the clusters\n",
    "allResults = tryKmeans(allMat)\n",
    "# Format results as a DataFrame\n",
    "allResults = pd.DataFrame(data=allResults, columns=['Number of clusters', 'Average silhouette score', 'Size of cluster', 'Label assignements'])\n",
    "allResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: No interesting clustering (16/01/2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignements = detailsKmeans(allForms, allResults, 2)\n",
    "assignements = pd.concat([assignements, allForms[\"temporality\"]], axis=1, join='inner')\n",
    "defConfusionMat = confusion_matrix(list(assignements[\"temporality\"]), list(assignements[\"Index of cluster\"]))\n",
    "defConfusionMat = pd.DataFrame(data = defConfusionMat, columns=[\"Predicted undefined\", \"Predicted before\", \"Predicted after\"], index = [\"Actual undefined\", \"Actual after\", \"Actual before\"])\n",
    "defConfusionMat.drop(\"Predicted undefined\", axis=1, inplace=True)\n",
    "defConfusionMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Compared to previous test, the undefined class is too big. (16/01/2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO RAPHAEL : Manually check the undefined temporalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If scientific questions are coded by correctedness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If only before and after questionnaires are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to matrix\n",
    "defCorrectedMat = defCorrectedForms.drop(\"temporality\", axis=1).as_matrix()\n",
    "# Standardise data\n",
    "defCorrectedMat = preprocessing.scale(defCorrectedMat)\n",
    "# Cluster using KMeans, and silhouette analysis to evaluate the pertinence of the clusters\n",
    "defCorrectedResults = tryKmeans(defCorrectedMat)\n",
    "# Format results as a DataFrame\n",
    "defCorrectedResults = pd.DataFrame(data=defCorrectedResults, columns=['Number of clusters', 'Average silhouette score', 'Size of cluster', 'Label assignements'])\n",
    "defCorrectedResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: The data could be clustered in two groups and the clustering is slightly better than with scientific questions coded by answers\n",
    "Note: The silhouette coefficient probably never goes very high because of the binary aspect of most of the data (01/12/2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis: The two groups identified by the clustering algorithm correspond to the \"before\" and \"after\" questionnaires.\n",
    "Note: The temporality feature was not included in the clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignements = detailsKmeans(defCorrectedForms, defCorrectedResults, 2, displayParallelCoord=True, clusterLabels=[\"Predicted after\", \"Predicted before\"])\n",
    "assignements = pd.concat([assignements, defCorrectedForms[\"temporality\"]], axis=1, join='inner')\n",
    "defCorrectedConfusionMat = confusion_matrix(list(assignements[\"temporality\"]), list(assignements[\"Index of cluster\"]))\n",
    "defCorrectedConfusionMat = pd.DataFrame(data = defCorrectedConfusionMat, columns=[\"Predicted after\", \"Predicted before\"], index = [\"Actual after\", \"Actual before\"])\n",
    "defCorrectedConfusionMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Hypothesis verified. Parallel coordinates plot is not very informative because of the high proportion of binary features, use only for data exploration. Better than with scientific questions coded by answers (16/01/2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If all questionnaires are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to matrix\n",
    "allCorrectedMat = allCorrectedForms.drop(\"temporality\", axis=1).as_matrix()\n",
    "# Standardise data\n",
    "allCorrectedMat = preprocessing.scale(allCorrectedMat)\n",
    "# Cluster using KMeans, and silhouette analysis to evaluate the pertinence of the clusters\n",
    "allCorrectedResults = tryKmeans(allCorrectedMat)\n",
    "# Format results as a DataFrame\n",
    "allCorrectedResults = pd.DataFrame(data=allCorrectedResults, columns=['Number of clusters', 'Average silhouette score', 'Size of cluster', 'Label assignements'])\n",
    "allCorrectedResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: The data could be clustered in two groups. Three groups could be interesting but not enough data points in third cluster to conclude. (30/11/2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignements = detailsKmeans(allCorrectedForms, allCorrectedResults, 2, displayParallelCoord=True, clusterLabels=[\"Predicted after\", \"Predicted before\"])\n",
    "assignements = pd.concat([assignements, allCorrectedForms[\"temporality\"]], axis=1, join='inner')\n",
    "defCorrectedConfusionMat = confusion_matrix(list(assignements[\"temporality\"]), list(assignements[\"Index of cluster\"]))\n",
    "defCorrectedConfusionMat = pd.DataFrame(data = defCorrectedConfusionMat, columns=[\"Predicted undefined\", \"Predicted after\", \"Predicted before\"], index = [\"Actual undefined\", \"Actual after\", \"Actual before\"])\n",
    "defCorrectedConfusionMat.drop(\"Predicted undefined\", axis=1, inplace=True)\n",
    "defCorrectedConfusionMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Compared to previous test, the presence of questionnaire that were realised neither just before nor just after the play test is not detected, but it does not impact the prediction of the before and after temporalities (01/12/2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO RAPHAEL : Manually check the undefined temporalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can the data be clustered according to the answers given to both the before and the after questionnaire?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If scientific questions are coded by answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to matrix\n",
    "beforeAndAfterMat = beforeAndAfterForms.as_matrix()\n",
    "# Standardise the data\n",
    "beforeAndAfterMat = preprocessing.scale(beforeAndAfterMat)\n",
    "# Cluster using KMeans, and silhouette analysis to evaluate the pertinence of the clusters\n",
    "beforeAndAfterResults = tryKmeans(beforeAndAfterMat)\n",
    "# Format results as a DataFrame\n",
    "beforeAndAfterResults = pd.DataFrame(data=beforeAndAfterResults, columns=['Number of clusters', 'Average silhouette score', 'Size of cluster', 'Label assignements'])\n",
    "beforeAndAfterResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: No interesting clustering (30/11/2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If scientific questions are coded by correctedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to matrix\n",
    "beforeAndAfterCorrectedMat = beforeAndAfterCorrectedForms.as_matrix()\n",
    "# Standardise the data\n",
    "beforeAndAfterCorrectedMat = preprocessing.scale(beforeAndAfterCorrectedMat)\n",
    "# Cluster using KMeans, and silhouette analysis to evaluate the pertinence of the clusters\n",
    "beforeAndAfterCorrectedResults = tryKmeans(beforeAndAfterCorrectedMat)\n",
    "# Format results as a DataFrame\n",
    "beforeAndAfterCorrectedResults = pd.DataFrame(data=beforeAndAfterCorrectedResults, columns=['Number of clusters', 'Average silhouette score', 'Size of cluster', 'Label assignements'])\n",
    "beforeAndAfterCorrectedResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: The data could be clustered in two groups (01/12/2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignements = detailsKmeans(beforeAndAfterCorrectedForms, beforeAndAfterCorrectedResults, 2, displayParallelCoord=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute frequency of correct answers for each group and each question\n",
    "correctAnswersByCluster = freqByCluster(beforeAndAfterCorrectedForms, beforeAndAfterCorrectedResults, 2, \"previousPlay_before\")\n",
    "correctAnswersByCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute frequency of correct answers for each group and each question\n",
    "correctAnswersByCluster = freqByCluster(beforeAndAfterCorrectedForms, beforeAndAfterCorrectedResults, 2, \"biologyInterest_before\")\n",
    "correctAnswersByCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute frequency of correct answers for each group and each question\n",
    "correctAnswersByCluster = freqByCluster(beforeAndAfterCorrectedForms, beforeAndAfterCorrectedResults, 2, \"biologyStudy_before\")\n",
    "correctAnswersByCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute frequency of correct answers for each group and each question\n",
    "correctAnswersByCluster = freqByCluster(beforeAndAfterCorrectedForms, beforeAndAfterCorrectedResults, 2, \"biologyInterest_after\")\n",
    "correctAnswersByCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TODO Raphael: Look in details at scientific questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Can the data be clustered according to the RedMetrics values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to matrix\n",
    "allDataMat = allData.iloc[:,:-1].as_matrix()\n",
    "# Standardise the data\n",
    "allDataMat = preprocessing.scale(allDataMat)\n",
    "# Cluster using KMeans, and silhouette analysis to evaluate the pertinence of the clusters\n",
    "allDataResults = tryKmeans(allDataMat, rangeNbClusters=[2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "# Format results as a DataFrame\n",
    "allDataResults = pd.DataFrame(data=allDataResults, columns=['Number of clusters', 'Average silhouette score', 'Size of cluster', 'Label assignements'])\n",
    "allDataResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Conclusion: Could be clustered in two groups (17/01/2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the parallel coordinates plot for 2 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "assignements = detailsKmeans(allData, allDataResults, 2, displayParallelCoord=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Raphaeal : Check in details, Maybe check sub-divisions of clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only sessions where the player has answered the questionnaire before and after playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to matrix\n",
    "fullProcessDataMat = fullProcessData.as_matrix()\n",
    "# Standardise the data\n",
    "fullProcessDataMat = preprocessing.scale(fullProcessDataMat)\n",
    "# Cluster using KMeans, and silhouette analysis to evaluate the pertinence of the clusters\n",
    "fullProcessDataResults = tryKmeans(fullProcessDataMat, rangeNbClusters=[2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "# Format results as a DataFrame\n",
    "fullProcessDataResults = pd.DataFrame(data=fullProcessDataResults, columns=['Number of clusters', 'Average silhouette score', 'Size of cluster', 'Label assignements'])\n",
    "fullProcessDataResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Conclusion: The data can be clustered in uneven two groups. Not enough data? (17/01/2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignements = detailsKmeans(fullProcessData, fullProcessDataResults, 2, displayParallelCoord=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute frequency of different levels of scores for each group\n",
    "scores_before = freqByCluster(fullProcessData, fullProcessDataResults, 2, \"scorebefore\")\n",
    "scores_after = freqByCluster(fullProcessData, fullProcessDataResults, 2, \"scoreafter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare groups for behaviors\n",
    "freqByCluster(fullProcessData, fullProcessDataResults, 2, \"configure\")\n",
    "freqByCluster(fullProcessData, fullProcessDataResults, 2, \"craft\")\n",
    "freqByCluster(fullProcessData, fullProcessDataResults, 2, \"equip\")\n",
    "freqByCluster(fullProcessData, fullProcessDataResults, 2, \"death\")\n",
    "freqByCluster(fullProcessData, fullProcessDataResults, 2, \"add\")\n",
    "freqByCluster(fullProcessData, fullProcessDataResults, 2, \"unequip\")\n",
    "freqByCluster(fullProcessData, fullProcessDataResults, 2, \"remove\")\n",
    "freqByCluster(fullProcessData, fullProcessDataResults, 2, \"pickup\")\n",
    "freqByCluster(fullProcessData, fullProcessDataResults, 2, \"reach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: No difference in score between groups but difference in behaviours. Small group didn't play a lot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Can the data be clustered according to the RedMetrics and the answers to the after questionnaire?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## If scientific questions are coded by answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to matrix\n",
    "gameAndAfterMat = gameAndAfterData.as_matrix()\n",
    "# Standardise the data\n",
    "gameAndAfterMat = preprocessing.scale(gameAndAfterMat)\n",
    "# Cluster using KMeans, and silhouette analysis to evaluate the pertinence of the clusters\n",
    "gameAndAfterResults = tryKmeans(gameAndAfterMat)\n",
    "# Format results as a DataFrame\n",
    "gameAndAfterResults = pd.DataFrame(data=gameAndAfterResults, columns=['Number of clusters', 'Average silhouette score', 'Size of cluster', 'Label assignements'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: No interesting clustering (19/12/2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If scientific questions are coded by correctedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to matrix\n",
    "gameAndCorrectedAfterMat = gameAndCorrectedAfterData.as_matrix()\n",
    "# Standardise the data\n",
    "gameAndCorrectedAfterMat = preprocessing.scale(gameAndCorrectedAfterMat)\n",
    "# Cluster using KMeans, and silhouette analysis to evaluate the pertinence of the clusters\n",
    "gameAndCorrectedAfterResults = tryKmeans(gameAndCorrectedAfterMat)\n",
    "# Format results as a DataFrame\n",
    "gameAndCorrectedAfterResults = pd.DataFrame(data=gameAndCorrectedAfterResults, columns=['Number of clusters', 'Average silhouette score', 'Size of cluster', 'Label assignements'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: No interesting clustering (19/12/2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
