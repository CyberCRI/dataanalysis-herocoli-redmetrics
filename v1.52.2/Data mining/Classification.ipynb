{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run dataFormating.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print (sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "from math import *\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import normaltest\n",
    "\n",
    "from matplotlib.pyplot import boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questionnaire only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can the answers to the scientific questions be used to predict if the questionnaire was filled before or after the game?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I am using only decision tree methods here because other methods like naive bayes do not make sense on categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If scientific questions are coded by answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns that correspond to scientific questions\n",
    "scientificColumns = [x for x in list(defForms.columns.values) if x[0] == \"Q\"]\n",
    "\n",
    "# Pick features and target\n",
    "features = defForms.loc[:, scientificColumns]\n",
    "target = defForms[\"temporality\"].astype('int') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify using decision trees -accounts for the small size of the dataset and the categorical nature of the features\n",
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=2, random_state=0, max_features=\"auto\")\n",
    "scores = cross_val_score(clf, features, target)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify using random forests -accounts for the small size of the dataset and the categorical nature of the features, limit overfitting\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0, bootstrap=True)\n",
    "scores = cross_val_score(clf, features, target)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify using extra tree classifiers, more random than random forest methods\n",
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0, bootstrap=True)\n",
    "scores = cross_val_score(clf, features, target)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Accuracy is around 85%. Not bad but we expected better (17/01/2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If scientific questions are coded by correctedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns that correspond to scientific questions\n",
    "scientificColumns = [x for x in list(defCorrectedForms.columns.values) if x[0] == \"Q\"]\n",
    "\n",
    "# Pick features and target\n",
    "features = defCorrectedForms.loc[:, scientificColumns]\n",
    "target = defCorrectedForms[\"temporality\"].astype('int') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify using decision trees -accounts for the small size of the dataset and the categorical nature of the features\n",
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=2, random_state=0, max_features=\"auto\")\n",
    "scores = cross_val_score(clf, features, target)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify using random forests -accounts for the small size of the dataset and the categorical nature of the features, limit overfitting\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0, bootstrap=True)\n",
    "scores = cross_val_score(clf, features, target)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify using extra tree classifiers, more random than random forest methods\n",
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0, bootstrap=True)\n",
    "scores = cross_val_score(clf, features, target)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Accuracy is around 80%. Not bad but we expected better (19/12/2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RedMetrics only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDataClassif.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can the score of a player be predicted with their RedMetrics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove id\n",
    "anonymousData = allDataClassif.drop(\"anonymousID\", axis = 1)\n",
    "\n",
    "# Get features and target\n",
    "# Only select rows where scoreafter is not negative\n",
    "features = anonymousData[anonymousData[\"scoreafter\"] >= 0].drop(\"scoreafter\", axis = 1)\n",
    "target = anonymousData[anonymousData[\"scoreafter\"] >= 0][\"scoreafter\"]\n",
    "\n",
    "# Center and scale data\n",
    "features = preprocessing.scale(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso regression with cross-validation\n",
    "model = Lasso()\n",
    "scores = cross_val_score(model, features, target, cv=10)\n",
    "boxplot(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Score cannot be predicted by the table of RedMetrics data (30/01/2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove id\n",
    "anonymousData = allDataClassif.drop(\"anonymousID\", axis = 1)\n",
    "\n",
    "# Get features and target\n",
    "# Only select rows where scoreafter is not negative\n",
    "features = anonymousData[anonymousData[\"scoreafter\"] >= 0].drop(\"scoreafter\", axis = 1)\n",
    "target = anonymousData[anonymousData[\"scoreafter\"] >= 0][\"scoreafter\"]\n",
    "\n",
    "# Add polynomial features\n",
    "secondDegreeFeatures = preprocessing.PolynomialFeatures(degree=2, interaction_only=False, include_bias=True)\n",
    "features = secondDegreeFeatures.fit_transform(features)\n",
    "\n",
    "# Center and scale data\n",
    "features = preprocessing.scale(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso regression with cross-validation\n",
    "model = Lasso()\n",
    "scores = cross_val_score(model, features, target, cv=10)\n",
    "boxplot(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Score cannot be predicted by the table of RedMetrics data + second degree polynomial (30/01/2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try by reducing the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove id\n",
    "anonymousData = allDataClassif.drop(\"anonymousID\", axis = 1)\n",
    "\n",
    "# Get features and target\n",
    "# Only select rows where scoreafter is not negative\n",
    "features = anonymousData[anonymousData[\"scoreafter\"] >= 0]\n",
    "features = features[[\"craft\", \"death\", \"add\", \"remove\", \"reach\", \"maxChapter\"] + list(range(15))]\n",
    "target = anonymousData[anonymousData[\"scoreafter\"] >= 0][\"scoreafter\"]\n",
    "\n",
    "# Add polynomial features\n",
    "secondDegreeFeatures = preprocessing.PolynomialFeatures(degree=2, interaction_only=False, include_bias=True)\n",
    "features = secondDegreeFeatures.fit_transform(features)\n",
    "\n",
    "# Center and scale data\n",
    "features = preprocessing.scale(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso regression with cross-validation\n",
    "model = Lasso()\n",
    "scores = cross_val_score(model, features, target, cv=10)\n",
    "boxplot(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Tried different combinations, but cannot find any interesting regression (02/02/2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questionnaire and RedMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can the biology level of a player be predicted using the game data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove id\n",
    "anonymousData = gameAndCorrectedAfterDataClassif.drop(\"anonymousID\", axis = 1)\n",
    "\n",
    "# Get features and target\n",
    "# Only select rows where scoreafter is not negative\n",
    "features = anonymousData[anonymousData[\"scoreafter\"] >= 0]\n",
    "features = features.loc[:,\"sessionsCount\":\"completionTime\"]\n",
    "target = anonymousData[anonymousData[\"scoreafter\"] >= 0][\"biologyStudy\"]\n",
    "\n",
    "# Add polynomial features\n",
    "secondDegreeFeatures = preprocessing.PolynomialFeatures(degree=2, interaction_only=False, include_bias=True)\n",
    "features = secondDegreeFeatures.fit_transform(features)\n",
    "\n",
    "# Center and scale data\n",
    "features = preprocessing.scale(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso regression with cross-validation\n",
    "model = Lasso()\n",
    "scores = cross_val_score(model, features, target, cv=10)\n",
    "boxplot(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Conclusion: No (30/01/2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can the gaming profile of a player be predicted using the game data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove id\n",
    "anonymousData = gameAndCorrectedAfterDataClassif.drop(\"anonymousID\", axis = 1)\n",
    "\n",
    "# Get features and target\n",
    "# Only select rows where scoreafter is not negative\n",
    "features = anonymousData.loc[:,\"sessionsCount\":\"completionTime\"]\n",
    "target = sum(anonymousData[\"gameInterest\"], anonymousData[\"gameFrequency\"])\n",
    "\n",
    "# Add polynomial features\n",
    "secondDegreeFeatures = preprocessing.PolynomialFeatures(degree=2, interaction_only=False, include_bias=True)\n",
    "features = secondDegreeFeatures.fit_transform(features)\n",
    "\n",
    "# Center and scale data\n",
    "features = preprocessing.scale(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso regression with cross-validation\n",
    "model = Lasso()\n",
    "scores = cross_val_score(model, features, target, cv=10)\n",
    "boxplot(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Conclusion: No (30/01/2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Can the completion time of each chapter be used to predict if a player is going to answer a specific scientific question correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a question tag, plot scores of cross-validated model\n",
    "def tryClassification(data, scientificQuestion):\n",
    "    # Remove id\n",
    "    anonymousData = data.drop(\"anonymousID\", axis = 1)\n",
    "\n",
    "    # Get features and target\n",
    "    # Only select rows where scoreafter is not negative\n",
    "    features = anonymousData[anonymousData[\"scoreafter\"] >= 0]\n",
    "    features = features.iloc[:,24:37]\n",
    "    target = anonymousData[anonymousData[\"scoreafter\"] >= 0].loc[:,scientificQuestion].astype('int')\n",
    "\n",
    "    # Add polynomial features\n",
    "    secondDegreeFeatures = preprocessing.PolynomialFeatures(degree=2, interaction_only=False, include_bias=True)\n",
    "    features = secondDegreeFeatures.fit_transform(features)\n",
    "\n",
    "    # Center and scale data\n",
    "    features = preprocessing.scale(features)\n",
    "    \n",
    "    # Classify using extra tree classifiers, more random than random forest methods\n",
    "    clf = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0, bootstrap=True)\n",
    "    scores = cross_val_score(clf, features, target, cv=5)\n",
    "    \n",
    "    # Display plot\n",
    "    fig, ax = plt.subplots()\n",
    "    boxplot(scores)\n",
    "    \n",
    "    return [scores.mean(), scores.std()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allScores = pd.DataFrame(index = [\"Mean\", \"Var\"])\n",
    "for questionNb in range(27):\n",
    "    questionTag = \"Q\" + str(questionNb + 1)\n",
    "    scores = tryClassification(gameAndCorrectedAfterDataClassif, questionTag)\n",
    "    allScores[questionTag] = scores\n",
    "allScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Redmetrics can be used to predict answers to certain scientific questions (30/01/2018)\n",
    "TODO Raphael: Check which questions you want additional analysis for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can the game data be used to predict the performance on a sub-group of scientific questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard questions Q17-Q21-Q23-Q24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove id\n",
    "anonymousData = gameAndCorrectedAfterDataClassif.drop(\"anonymousID\", axis = 1)\n",
    "\n",
    "# Get features and target\n",
    "features = pd.concat([anonymousData.loc[:,\"sessionsCount\":\"completionTime\"], anonymousData.loc[:,\"gameInterest\":\"androidPlay\"]], axis=1)\n",
    "target = anonymousData.loc[:,[\"Q17\", \"Q21\", \"Q23\", \"Q24\"]].astype(int).sum(axis=1)\n",
    "target = target.apply(lambda x: 0 if x < 3 else 1)\n",
    "\n",
    "# Add polynomial features\n",
    "secondDegreeFeatures = preprocessing.PolynomialFeatures(degree=2, interaction_only=False, include_bias=True)\n",
    "features = secondDegreeFeatures.fit_transform(features)\n",
    "\n",
    "# Center and scale data\n",
    "features = preprocessing.scale(features)\n",
    "    \n",
    "# Classify using extra tree classifiers, more random than random forest methods\n",
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0, bootstrap=True)\n",
    "scores = cross_val_score(clf, features, target, cv=10)\n",
    "    \n",
    "# Display plot\n",
    "boxplot(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify using random forests -accounts for the small size of the dataset and the categorical nature of the features, limit overfitting\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0, bootstrap=True)\n",
    "scores = cross_val_score(clf, features, target)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Low quality prediction (1/02/2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biobrick symbol recognition Q3 -> Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove id\n",
    "anonymousData = gameAndCorrectedAfterDataClassif.drop(\"anonymousID\", axis = 1)\n",
    "\n",
    "# Get features and target\n",
    "# Only select rows where scoreafter is not negative\n",
    "features = pd.concat([anonymousData.loc[:,\"sessionsCount\":\"completionTime\"], anonymousData.loc[:,\"gameInterest\":\"androidPlay\"]], axis=1)\n",
    "target = anonymousData.loc[:,\"Q3\":\"Q10\"].astype(int).sum(axis=1)\n",
    "\n",
    "# Add polynomial features\n",
    "secondDegreeFeatures = preprocessing.PolynomialFeatures(degree=2, interaction_only=False, include_bias=True)\n",
    "features = secondDegreeFeatures.fit_transform(features)\n",
    "\n",
    "# Center and scale data\n",
    "features = preprocessing.scale(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso regression with cross-validation\n",
    "model = Lasso()\n",
    "scores = cross_val_score(model, features, target, cv=10)\n",
    "boxplot(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: No apparent possible prediction (1/02/2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy questions Q1->Q7-Q9-Q10-Q15-Q16-Q19-Q20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove id\n",
    "anonymousData = gameAndCorrectedAfterDataClassif.drop(\"anonymousID\", axis = 1)\n",
    "\n",
    "# Get features and target\n",
    "features = pd.concat([anonymousData.loc[:,\"sessionsCount\":\"completionTime\"], anonymousData.loc[:,\"gameInterest\":\"androidPlay\"]], axis=1)\n",
    "target = anonymousData.loc[:,[\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\", \"Q6\", \"Q7\", \"Q9\", \"Q10\", \"Q15\", \"Q16\", \"Q19\", \"Q20\"]].astype(int).sum(axis=1)\n",
    "\n",
    "# Add polynomial features\n",
    "secondDegreeFeatures = preprocessing.PolynomialFeatures(degree=2, interaction_only=False, include_bias=True)\n",
    "features = secondDegreeFeatures.fit_transform(features)\n",
    "\n",
    "# Center and scale data\n",
    "features = preprocessing.scale(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso regression with cross-validation\n",
    "model = Lasso()\n",
    "scores = cross_val_score(model, features, target, cv=10)\n",
    "boxplot(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(target, bins = range(14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Inconclusive (01/02/2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can the completion time be predicted from questionnaire answers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the before questionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove id\n",
    "anonymousData = gameAndCorrectedBeforeDataClassif.drop(\"anonymousID\", axis = 1)\n",
    "\n",
    "# Get features and target\n",
    "features = anonymousData.loc[:,\"gameInterest\":\"gender_Prefer not to say\"]\n",
    "target = anonymousData.loc[:,\"completionTime\"]\n",
    "\n",
    "# Add polynomial features\n",
    "secondDegreeFeatures = preprocessing.PolynomialFeatures(degree=2, interaction_only=False, include_bias=True)\n",
    "features = secondDegreeFeatures.fit_transform(features)\n",
    "\n",
    "# Center and scale data\n",
    "features = preprocessing.scale(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso regression with cross-validation\n",
    "model = Lasso(max_iter=10000, alpha=10)\n",
    "scores = cross_val_score(model, features, target, cv=10)\n",
    "boxplot(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try classification\n",
    "target = target.apply(lambda x: 0 if x < 7200 else 1) #0 if short, 1 if long\n",
    "\n",
    "# Classify using extra tree classifiers, more random than random forest methods\n",
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0, bootstrap=True)\n",
    "scores = cross_val_score(clf, features, target, cv=10)\n",
    "    \n",
    "# Display plot\n",
    "boxplot(scores)\n",
    "scores.mean()\n",
    "sum(target)/len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: No (01/02/2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the after questionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove id\n",
    "anonymousData = gameAndCorrectedAfterDataClassif.drop(\"anonymousID\", axis = 1)\n",
    "\n",
    "# Get features and target\n",
    "features = anonymousData.loc[:,\"gameInterest\":\"gender_Prefer not to say\"]\n",
    "target = anonymousData.loc[:,\"completionTime\"]\n",
    "\n",
    "# Add polynomial features\n",
    "secondDegreeFeatures = preprocessing.PolynomialFeatures(degree=2, interaction_only=False, include_bias=True)\n",
    "features = secondDegreeFeatures.fit_transform(features)\n",
    "\n",
    "# Center and scale data\n",
    "features = preprocessing.scale(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso regression with cross-validation\n",
    "model = Lasso(max_iter=1000000)\n",
    "scores = cross_val_score(model, features, target, cv=10)\n",
    "boxplot(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try classification\n",
    "target = target.apply(lambda x: 0 if x < 7200 else 1) #0 if short, 1 if long\n",
    "\n",
    "# Classify using extra tree classifiers, more random than random forest methods\n",
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0, bootstrap=True)\n",
    "scores = cross_val_score(clf, features, target, cv=10)\n",
    "    \n",
    "# Display plot\n",
    "boxplot(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: No (01/02/2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
