{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google form analysis visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "\n",
    "['Google form analysis' functions checks](#funcchecks)\n",
    "\n",
    "['Google form analysis' functions tinkering](#functinkering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../Functions/2. Google form analysis.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Google form analysis' functions checks\n",
    "<a id=funcchecks />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Google form analysis' functions tinkering\n",
    "<a id=functinkering />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "binarizedAnswers = plotBasicStats(getSurveysOfBiologists(gform), 'non biologists', includeUndefined = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gform.loc[:, [localplayerguidkey, QTemporality]].groupby(QTemporality).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sample = gform.copy()\n",
    "samples = [\n",
    "            [gform.copy(), 'complete set'],\n",
    "            [gform[gform[QLanguage] == enLanguageID], 'English'],\n",
    "            [gform[gform[QLanguage] == frLanguageID], 'French'],\n",
    "            [gform[gform[QGender] == 'Female'], 'female'],\n",
    "            [gform[gform[QGender] == 'Male'], 'male'],\n",
    "            [getSurveysOfUsersWhoAnsweredBoth(gform), 'answered both'],\n",
    "            [getSurveysOfUsersWhoAnsweredBoth(gform[gform[QLanguage] == enLanguageID]), 'answered both, en'],\n",
    "            [getSurveysOfUsersWhoAnsweredBoth(gform[gform[QLanguage] == frLanguageID]), 'answered both, fr'],\n",
    "            [getSurveysOfUsersWhoAnsweredBoth(gform[gform[QGender] == 'Female']), 'answered both, female'],\n",
    "            [getSurveysOfUsersWhoAnsweredBoth(gform[gform[QGender] == 'Male']), 'answered both, male'],\n",
    "        ]\n",
    "\n",
    "_progress = FloatProgress(min=0, max=len(samples))\n",
    "display(_progress)\n",
    "\n",
    "includeAll = False\n",
    "includeBefore = True\n",
    "includeAfter = True\n",
    "includeUndefined = False\n",
    "includeProgress = True\n",
    "includeRelativeProgress = False\n",
    "\n",
    "for sample, title in samples:\n",
    "\n",
    "    ## basic stats:\n",
    "    ### mean score\n",
    "    ### median score\n",
    "    ### std\n",
    "    ## sample can be: all, those who answered both before and after,\n",
    "    ## those who played between date1 and date2, ...\n",
    "    #def plotBasicStats(sample, title, includeAll, includeBefore, includeAfter, includeUndefined, includeProgress, includeRelativeProgress):\n",
    "\n",
    "    \n",
    "    stepsPerInclude = 2\n",
    "    includeCount = np.sum([includeAll, includeBefore, includeAfter, includeUndefined, includeProgress])\n",
    "    stepsCount = stepsPerInclude*includeCount + 3\n",
    "    \n",
    "    #print(\"stepsPerInclude=\" + str(stepsPerInclude))\n",
    "    #print(\"includeCount=\" + str(includeCount))\n",
    "    #print(\"stepsCount=\" + str(stepsCount))\n",
    "    \n",
    "    __progress = FloatProgress(min=0, max=stepsCount)\n",
    "    display(__progress)\n",
    "    \n",
    "    sampleBefore = sample[sample[QTemporality] == answerTemporalities[0]]\n",
    "    sampleAfter = sample[sample[QTemporality] == answerTemporalities[1]]\n",
    "    sampleUndefined = sample[sample[QTemporality] == answerTemporalities[2]]\n",
    "\n",
    "    #uniqueBefore = sampleBefore[localplayerguidkey]\n",
    "    #uniqueAfter = \n",
    "    #uniqueUndefined =\n",
    "\n",
    "    scientificQuestionsSource = correctAnswers.copy()\n",
    "    allQuestions = correctAnswers + demographicAnswers\n",
    "    \n",
    "    categories = ['all', answerTemporalities[0], answerTemporalities[1], answerTemporalities[2], 'progress', 'rel. progress']\n",
    "    data = {}\n",
    "    \n",
    "    sciBinarized = pd.DataFrame()\n",
    "    allBinarized = pd.DataFrame()\n",
    "    scoresAll = pd.DataFrame()\n",
    "    \n",
    "    sciBinarizedBefore = pd.DataFrame()\n",
    "    allBinarizedBefore = pd.DataFrame()\n",
    "    scoresBefore = pd.DataFrame()\n",
    "    \n",
    "    sciBinarizedAfter = pd.DataFrame()\n",
    "    allBinarizedAfter = pd.DataFrame()\n",
    "    scoresAfter = pd.DataFrame()\n",
    "    \n",
    "    sciBinarizedUndefined = pd.DataFrame()\n",
    "    allBinarizedUndefined = pd.DataFrame()\n",
    "    scoresUndefined = pd.DataFrame()\n",
    "\n",
    "    scoresProgress = pd.DataFrame()\n",
    "\n",
    "    ## basic stats:\n",
    "    ### mean score\n",
    "    ### median score\n",
    "    ### std\n",
    "    if includeAll:\n",
    "        sciBinarized = getAllBinarized( _source = scientificQuestionsSource, _form = sample)\n",
    "        __progress.value += 1\n",
    "        allBinarized = getAllBinarized( _source = allQuestions, _form = sample)\n",
    "        __progress.value += 1\n",
    "        scoresAll = pd.Series(np.dot(sciBinarized, np.ones(sciBinarized.shape[1])))\n",
    "        \n",
    "        data[categories[0]] = createStatSet(scoresAll, sample[localplayerguidkey])\n",
    "        \n",
    "    if includeBefore or includeProgress:\n",
    "        sciBinarizedBefore = getAllBinarized( _source = scientificQuestionsSource, _form = sampleBefore)\n",
    "        __progress.value += 1\n",
    "        allBinarizedBefore = getAllBinarized( _source = allQuestions, _form = sampleBefore)\n",
    "        __progress.value += 1\n",
    "        scoresBefore = pd.Series(np.dot(sciBinarizedBefore, np.ones(sciBinarizedBefore.shape[1])))\n",
    "        temporaryStatSetBefore = createStatSet(scoresBefore, sampleBefore[localplayerguidkey])\n",
    "    if includeBefore:\n",
    "        data[categories[1]] = temporaryStatSetBefore\n",
    "        \n",
    "    if includeAfter or includeProgress:\n",
    "        sciBinarizedAfter = getAllBinarized( _source = scientificQuestionsSource, _form = sampleAfter)\n",
    "        __progress.value += 1\n",
    "        allBinarizedAfter = getAllBinarized( _source = allQuestions, _form = sampleAfter)\n",
    "        __progress.value += 1\n",
    "        scoresAfter = pd.Series(np.dot(sciBinarizedAfter, np.ones(sciBinarizedAfter.shape[1])))\n",
    "        temporaryStatSetAfter = createStatSet(scoresAfter, sampleAfter[localplayerguidkey])\n",
    "    if includeAfter:\n",
    "        data[categories[2]] = temporaryStatSetAfter\n",
    "        \n",
    "    if includeUndefined:\n",
    "        sciBinarizedUndefined = getAllBinarized( _source = scientificQuestionsSource, _form = sampleUndefined)\n",
    "        __progress.value += 1\n",
    "        allBinarizedUndefined = getAllBinarized( _source = allQuestions, _form = sampleUndefined)\n",
    "        __progress.value += 1\n",
    "        scoresUndefined = pd.Series(np.dot(sciBinarizedUndefined, np.ones(sciBinarizedUndefined.shape[1])))\n",
    "        \n",
    "        data[categories[3]] = createStatSet(scoresUndefined, sampleUndefined[localplayerguidkey])\n",
    "\n",
    "    if includeProgress:\n",
    "        data[categories[4]] = {\n",
    "            'count' : min(temporaryStatSetAfter['count'], temporaryStatSetBefore['count']),\n",
    "            'unique' : min(temporaryStatSetAfter['unique'], temporaryStatSetBefore['unique']),\n",
    "            'median' : temporaryStatSetAfter['median']-temporaryStatSetBefore['median'],\n",
    "            'mean' : temporaryStatSetAfter['mean']-temporaryStatSetBefore['mean'],\n",
    "            'std' : temporaryStatSetAfter['std']-temporaryStatSetBefore['std'],\n",
    "        }\n",
    "        __progress.value += 2\n",
    "    \n",
    "    \n",
    "    result = pd.DataFrame(data)\n",
    "    __progress.value += 1\n",
    "\n",
    "    print(title)\n",
    "    print(result)\n",
    "    if (includeBefore and includeAfter) or includeProgress:\n",
    "        if (len(scoresBefore) > 2 and len(scoresAfter) > 2):\n",
    "            ttest = ttest_ind(scoresBefore, scoresAfter)\n",
    "            print(\"t test: statistic=\" + repr(ttest.statistic) + \" pvalue=\" + repr(ttest.pvalue))\n",
    "    print()\n",
    "\n",
    "    ## percentage correct\n",
    "    ### percentage correct - max 5 columns\n",
    "    percentagePerQuestionAll = pd.DataFrame()\n",
    "    percentagePerQuestionBefore = pd.DataFrame()\n",
    "    percentagePerQuestionAfter = pd.DataFrame()\n",
    "    percentagePerQuestionUndefined = pd.DataFrame()\n",
    "    percentagePerQuestionProgress = pd.DataFrame()\n",
    "    \n",
    "    tables = []\n",
    "\n",
    "    if includeAll:\n",
    "        percentagePerQuestionAll = getPercentagePerQuestion(allBinarized)\n",
    "        tables.append([percentagePerQuestionAll, categories[0]])\n",
    "        \n",
    "    if includeBefore or includeProgress:\n",
    "        percentagePerQuestionBefore = getPercentagePerQuestion(allBinarizedBefore)\n",
    "    if includeBefore:\n",
    "        tables.append([percentagePerQuestionBefore, categories[1]])\n",
    "        \n",
    "    if includeAfter or includeProgress:\n",
    "        percentagePerQuestionAfter = getPercentagePerQuestion(allBinarizedAfter)\n",
    "    if includeAfter:\n",
    "        tables.append([percentagePerQuestionAfter, categories[2]])\n",
    "        \n",
    "    if includeUndefined:\n",
    "        percentagePerQuestionUndefined = getPercentagePerQuestion(allBinarizedUndefined)\n",
    "        tables.append([percentagePerQuestionUndefined, categories[3]])\n",
    "        \n",
    "    if includeProgress or includeRelativeProgress:\n",
    "        percentagePerQuestionProgress = percentagePerQuestionAfter - percentagePerQuestionBefore\n",
    "        \n",
    "        if includeProgress:\n",
    "            tables.append([percentagePerQuestionProgress, categories[4]])\n",
    "            \n",
    "        if includeRelativeProgress:\n",
    "            # use temporaryStatSetAfter['count'], temporaryStatSetBefore['count']?\n",
    "            percentagePerQuestionProgress2 = percentagePerQuestionProgress.copy()\n",
    "            for index in range(0,len(percentagePerQuestionProgress.index)):\n",
    "                if (0 == percentagePerQuestionBefore.iloc[index,0]):\n",
    "                    percentagePerQuestionProgress2.iloc[index,0] = 0\n",
    "                else:\n",
    "                    percentagePerQuestionProgress2.iloc[index,0] = \\\n",
    "                    percentagePerQuestionProgress.iloc[index,0]/percentagePerQuestionBefore.iloc[index,0]\n",
    "            tables.append([percentagePerQuestionProgress2, categories[5]])\n",
    "    \n",
    "    __progress.value += 1\n",
    "\n",
    "    graphTitle = '% correct: '\n",
    "    toConcat = []\n",
    "    \n",
    "    for table,category in tables:\n",
    "        concat = (len(table.values) > 0)\n",
    "        for elt in table.iloc[:,0].values:\n",
    "            if np.isnan(elt):\n",
    "                concat = False\n",
    "                break\n",
    "        if(concat):\n",
    "            graphTitle = graphTitle + category + ' '\n",
    "            toConcat.append(table)\n",
    "\n",
    "    if (len(toConcat) > 0):\n",
    "        percentagePerQuestionConcatenated = pd.concat(\n",
    "            toConcat\n",
    "            , axis=1)\n",
    "\n",
    "        if(len(title) > 0):\n",
    "            graphTitle = graphTitle + ' - ' + title\n",
    "\n",
    "        _fig = plt.figure(figsize=(20,20))\n",
    "        _ax1 = plt.subplot(111)\n",
    "        _ax1.set_title(graphTitle)\n",
    "        sns.heatmap(percentagePerQuestionConcatenated.round().astype(int),ax=_ax1,cmap=plt.cm.jet,square=True,annot=True,fmt='d')\n",
    "    __progress.value += 1\n",
    "    \n",
    "    ### percentage cross correct\n",
    "    ### percentage cross correct, conditionnally\n",
    "    \n",
    "    if(__progress.value != stepsCount):\n",
    "        print(\"__progress.value=\" + str(__progress.value) + \" != stepsCount=\" + str(stepsCount))\n",
    "    \n",
    "    _progress.value += 1\n",
    "\n",
    "if(_progress.value != len(samples)):\n",
    "    print(\"__progress.value=\" + str(__progress.value) + \" != len(samples)=\" + str(len(samples)))\n",
    "\n",
    "#    sciBinarized, sciBinarizedBefore, sciBinarizedAfter, sciBinarizedUndefined, \\\n",
    "#            allBinarized, allBinarizedBefore, allBinarizedAfter, allBinarizedUndefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest = ttest_ind(scoresBefore, scoresAfter)\n",
    "type(scoresBefore), len(scoresBefore),\\\n",
    "type(scoresAfter), len(scoresAfter),\\\n",
    "ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sciBinarized = getAllBinarized( _source = scientificQuestionsSource, _form = sample)\n",
    "series = pd.Series(np.dot(sciBinarized, np.ones(sciBinarized.shape[1])))\n",
    "#ids = pd.Series()\n",
    "ids = sample[localplayerguidkey]\n",
    "\n",
    "#def createStatSet(series, ids):\n",
    "if(0 == len(ids)):\n",
    "    ids = series.index\n",
    "result = {\n",
    "    'count' : len(ids),\n",
    "    'unique' : len(ids.unique()),\n",
    "    'median' : series.median(),\n",
    "    'mean' : series.mean(),\n",
    "    'std' : series.std()}\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## percentage correct\n",
    "### percentage correct - 3 columns\n",
    "### percentage cross correct\n",
    "### percentage cross correct, conditionnally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_binarized = allBinarized\n",
    "#_binarized = allBinarizedUndefined\n",
    "_binarized = allBinarizedBefore\n",
    "#def getPercentagePerQuestion(_binarized):\n",
    "totalPerQuestionDF = pd.DataFrame(data=np.dot(np.ones(_binarized.shape[0]), _binarized), index=_binarized.columns)\n",
    "percentagePerQuestion = totalPerQuestionDF*100 / _binarized.shape[0]\n",
    "percentagePerQuestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#totalPerQuestion = np.dot(np.ones(allSciBinarized.shape[0]), allSciBinarized)\n",
    "#totalPerQuestion.shape\n",
    "totalPerQuestionSci = np.dot(np.ones(sciBinarized.shape[0]), sciBinarized)\n",
    "totalPerQuestionAll = np.dot(np.ones(allBinarized.shape[0]), allBinarized)\n",
    "\n",
    "percentagePerQuestionAll = getPercentagePerQuestion(allBinarized)\n",
    "percentagePerQuestionBefore = getPercentagePerQuestion(allBinarizedBefore)\n",
    "percentagePerQuestionAfter = getPercentagePerQuestion(allBinarizedAfter)\n",
    "percentagePerQuestionUndefined = getPercentagePerQuestion(allBinarizedUndefined)\n",
    "\n",
    "percentagePerQuestionConcatenated = pd.concat(\n",
    "    [\n",
    "        percentagePerQuestionAll,\n",
    "        percentagePerQuestionBefore,\n",
    "        percentagePerQuestionAfter,\n",
    "        percentagePerQuestionUndefined,\n",
    "    ]\n",
    "    , axis=1)\n",
    "_fig = plt.figure(figsize=(20,20))\n",
    "_ax1 = plt.subplot(111)\n",
    "_ax1.set_title('percentage correct per question: all, before, after, undefined')\n",
    "sns.heatmap(percentagePerQuestionConcatenated.round().astype(int),ax=_ax1,cmap=plt.cm.jet,square=True,annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samples = [gform, gform[gform[QLanguage] == enLanguageID], gform[gform[QLanguage] == frLanguageID],\n",
    "           getSurveysOfUsersWhoAnsweredBoth(gform),\n",
    "           getSurveysOfUsersWhoAnsweredBoth(gform[gform[QLanguage] == enLanguageID]),\n",
    "           getSurveysOfUsersWhoAnsweredBoth(gform[gform[QLanguage] == frLanguageID])]\n",
    "\n",
    "for sample in samples:\n",
    "    sciBinarized, sciBinarizedBefore, sciBinarizedAfter, sciBinarizedUndefined, \\\n",
    "            allBinarized, allBinarizedBefore, allBinarizedAfter, allBinarizedUndefined = plotBasicStats(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abandoned algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#totalPerQuestion = np.dot(np.ones(sciBinarized.shape[0]), sciBinarized)\n",
    "#totalPerQuestion.shape\n",
    "totalPerQuestionSci = np.dot(np.ones(sciBinarized.shape[0]), sciBinarized)\n",
    "totalPerQuestionAll = np.dot(np.ones(allBinarized.shape[0]), allBinarized)\n",
    "totalPerQuestionDFAll = pd.DataFrame(data=np.dot(np.ones(allBinarized.shape[0]), allBinarized), index=allBinarized.columns)\n",
    "percentagePerQuestionAll = totalPerQuestionDFAll*100 / allBinarized.shape[0]\n",
    "#totalPerQuestionDF\n",
    "#percentagePerQuestion\n",
    "\n",
    "#before\n",
    "totalPerQuestionDFBefore = pd.DataFrame(\n",
    "    data=np.dot(np.ones(allBinarizedBefore.shape[0]), allBinarizedBefore), index=allBinarizedBefore.columns\n",
    ")\n",
    "percentagePerQuestionBefore = totalPerQuestionDFBefore*100 / allBinarizedBefore.shape[0]\n",
    "\n",
    "#after\n",
    "totalPerQuestionDFAfter = pd.DataFrame(\n",
    "    data=np.dot(np.ones(allBinarizedAfter.shape[0]), allBinarizedAfter), index=allBinarizedAfter.columns\n",
    ")\n",
    "percentagePerQuestionAfter = totalPerQuestionDFAfter*100 / allBinarizedAfter.shape[0]\n",
    "\n",
    "_fig = plt.figure(figsize=(20,20))\n",
    "ax1 = plt.subplot(131)\n",
    "ax2 = plt.subplot(132)\n",
    "ax3 = plt.subplot(133)\n",
    "ax2.get_yaxis().set_visible(False)\n",
    "ax3.get_yaxis().set_visible(False)\n",
    "sns.heatmap(percentagePerQuestionAll.round().astype(int),ax=ax1,cmap=plt.cm.jet,square=True,annot=True,fmt='d', cbar=False)\n",
    "sns.heatmap(percentagePerQuestionBefore.round().astype(int),ax=ax2,cmap=plt.cm.jet,square=True,annot=True,fmt='d', cbar=False)\n",
    "sns.heatmap(percentagePerQuestionAfter.round().astype(int),ax=ax3,cmap=plt.cm.jet,square=True,annot=True,fmt='d', cbar=True)\n",
    "ax1.set_title('percentage correct per question - all')\n",
    "ax2.set_title('percentage correct per question - before')\n",
    "ax3.set_title('percentage correct per question - after')\n",
    "# Fine-tune figure; make subplots close to each other and hide x ticks for\n",
    "# all but bottom plot.\n",
    "_fig.tight_layout()\n",
    "\n",
    "_fig = plt.figure(figsize=(20,20))\n",
    "ax1 = plt.subplot(131)\n",
    "ax2 = plt.subplot(132)\n",
    "ax3 = plt.subplot(133)\n",
    "ax2.get_yaxis().set_visible(False)\n",
    "ax3.get_yaxis().set_visible(False)\n",
    "sns.heatmap(percentagePerQuestionAll.round().astype(int),ax=ax1,cmap=plt.cm.jet,square=True,annot=True,fmt='d', cbar=False)\n",
    "sns.heatmap(percentagePerQuestionBefore.round().astype(int),ax=ax2,cmap=plt.cm.jet,square=True,annot=True,fmt='d', cbar=False)\n",
    "sns.heatmap(percentagePerQuestionAfter.round().astype(int),ax=ax3,cmap=plt.cm.jet,square=True,annot=True,fmt='d', cbar=True)\n",
    "ax1.set_title('percentage correct per question - all')\n",
    "ax2.set_title('percentage correct per question - before')\n",
    "ax3.set_title('percentage correct per question - after')\n",
    "# Fine-tune figure; make subplots close to each other and hide x ticks for\n",
    "# all but bottom plot.\n",
    "_fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_fig = plt.figure(figsize=(20,20))\n",
    "ax1 = plt.subplot(131)\n",
    "ax2 = plt.subplot(132)\n",
    "ax3 = plt.subplot(133)\n",
    "ax2.get_yaxis().set_visible(False)\n",
    "ax3.get_yaxis().set_visible(False)\n",
    "sns.heatmap(percentagePerQuestionAll.round().astype(int),ax=ax1,cmap=plt.cm.jet,square=True,annot=True,fmt='d', cbar=False)\n",
    "sns.heatmap(percentagePerQuestionBefore.round().astype(int),ax=ax2,cmap=plt.cm.jet,square=True,annot=True,fmt='d', cbar=False)\n",
    "sns.heatmap(percentagePerQuestionAfter.round().astype(int),ax=ax3,cmap=plt.cm.jet,square=True,annot=True,fmt='d', cbar=True)\n",
    "ax1.set_title('percentage correct per question - all')\n",
    "ax2.set_title('percentage correct per question - before')\n",
    "ax3.set_title('percentage correct per question - after')\n",
    "# Fine-tune figure; make subplots close to each other and hide x ticks for\n",
    "# all but bottom plot.\n",
    "_fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentagePerQuestionConcatenated = pd.concat([\n",
    "    percentagePerQuestionAll,\n",
    "    percentagePerQuestionBefore,\n",
    "    percentagePerQuestionAfter]\n",
    "    , axis=1)\n",
    "_fig = plt.figure(figsize=(20,20))\n",
    "_ax1 = plt.subplot(111)\n",
    "_ax1.set_title('percentage correct per question: all, before, after')\n",
    "sns.heatmap(percentagePerQuestionConcatenated.round().astype(int),ax=_ax1,cmap=plt.cm.jet,square=True,annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample getters tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### getRMAfter / Before tinkering\n",
    "#def getRMAfters(sample):\n",
    "afters = sample[sample[QTemporality] == answerTemporalities[1]]\n",
    "#def getRMBefores(sample):\n",
    "befores = sample[sample[QTemporality] == answerTemporalities[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# equality tests\n",
    "#(sample1.columns == sample2.columns).all()\n",
    "#sample1.columns.duplicated().any() or sample2.columns.duplicated().any()\n",
    "#pd.concat([sample1, sample2], axis=1).columns.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### getUnionQuestionnaires tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = befores\n",
    "sample2 = afters\n",
    "\n",
    "#def getUnionQuestionnaires(sample1, sample2):\n",
    "if (not (sample1.columns == sample2.columns).all()):\n",
    "    print(\"warning: parameter columns are not the same\")\n",
    "result = pd.concat([sample1, sample2]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### getIntersectionQuestionnaires tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = befores[:15]\n",
    "sample2 = befores[10:]\n",
    "\n",
    "#def getIntersectionQuestionnaires(sample1, sample2):\n",
    "if (not (sample1.columns == sample2.columns).all()):\n",
    "    print(\"warning: parameter columns are not the same\")\n",
    "result = pd.merge(sample1, sample2, how = 'inner').drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### getIntersectionUsersSurveys tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = befores\n",
    "sample2 = afters\n",
    "\n",
    "# get sample1 and sample2 rows where users are common to sample1 and sample2\n",
    "#def getIntersectionUsersSurveys(sample1, sample2):\n",
    "result1 = sample1[sample1[localplayerguidkey].isin(sample2[localplayerguidkey])]\n",
    "result2 = sample2[sample2[localplayerguidkey].isin(sample1[localplayerguidkey])]\n",
    "result = getUnionQuestionnaires(result1,result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample1), len(sample2), len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### getGFormBefores tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = gform\n",
    "\n",
    "\n",
    "# returns users who declared that they have never played the game, whatever platform\n",
    "#  previousPlayPositives is defined in '../Static data/English localization.ipynb'\n",
    "#def getGFormBefores(sample):\n",
    "befores = sample[\n",
    "      ~sample[QPlayed1].isin(previousPlayPositives)\n",
    "    & ~sample[QPlayed2].isin(previousPlayPositives)\n",
    "    & ~sample[QPlayed3].isin(previousPlayPositives)\n",
    "    & ~sample[QPlayed4].isin(previousPlayPositives)\n",
    "                ]\n",
    "len(befores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### getGFormAfters tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = gform\n",
    "\n",
    "# returns users who declared that they have already played the game, whatever platform\n",
    "#  previousPlayPositives is defined in '../Static data/English localization.ipynb'\n",
    "#def getGFormAfters(sample):\n",
    "afters = sample[\n",
    "      sample[QPlayed1].isin(previousPlayPositives)\n",
    "    | sample[QPlayed2].isin(previousPlayPositives)\n",
    "    | sample[QPlayed3].isin(previousPlayPositives)\n",
    "    | sample[QPlayed4].isin(previousPlayPositives)\n",
    "                ]\n",
    "len(afters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### getGFormTemporality tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_GFUserId = getSurveysOfBiologists(gform)[localplayerguidkey].iloc[3]\n",
    "_gformRow = gform[gform[localplayerguidkey] == _GFUserId].iloc[0]\n",
    "sample = gform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerTemporalities[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#while result != answerTemporalities[1]:\n",
    "_GFUserId = getRandomGFormGUID()\n",
    "_gformRow = gform[gform[localplayerguidkey] == _GFUserId].iloc[0]\n",
    "\n",
    "# returns an element of answerTemporalities\n",
    "#  previousPlayPositives is defined in '../Static data/English localization.ipynb'\n",
    "#def getGFormRowGFormTemporality(_gformRow):\n",
    "result = answerTemporalities[2]\n",
    "if (_gformRow[QPlayed1] in previousPlayPositives)\\\n",
    "    or (_gformRow[QPlayed2] in previousPlayPositives)\\\n",
    "    or (_gformRow[QPlayed3] in previousPlayPositives)\\\n",
    "    or (_gformRow[QPlayed4] in previousPlayPositives):\n",
    "    result = answerTemporalities[1]\n",
    "else:\n",
    "    result = answerTemporalities[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getSurveysOfUsersWhoAnsweredBoth tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = gform\n",
    "gfMode = True\n",
    "rmMode = False\n",
    "\n",
    "#def getSurveysOfUsersWhoAnsweredBoth(sample, gfMode = True, rmMode = False):\n",
    "\n",
    "befores = sample\n",
    "afters = sample\n",
    "\n",
    "if gfMode:\n",
    "    befores = getGFormBefores(befores)\n",
    "    afters = getGFormAfters(afters)\n",
    "\n",
    "if rmMode:\n",
    "    befores = getRMBefores(befores)\n",
    "    afters = getRMAfters(afters)\n",
    "\n",
    "result = getIntersectionUsersSurveys(befores, afters)\n",
    "\n",
    "((len(getGFormBefores(sample)),\\\n",
    "len(getRMBefores(sample)),\\\n",
    "len(befores)),\\\n",
    "(len(getGFormAfters(sample)),\\\n",
    "len(getRMAfters(sample)),\\\n",
    "len(afters)),\\\n",
    "len(result)),\\\n",
    "\\\n",
    "((getUniqueUserCount(getGFormBefores(sample)),\\\n",
    "getUniqueUserCount(getRMBefores(sample)),\\\n",
    "getUniqueUserCount(befores)),\\\n",
    "(getUniqueUserCount(getGFormAfters(sample)),\\\n",
    "getUniqueUserCount(getRMAfters(sample)),\\\n",
    "getUniqueUserCount(afters)),\\\n",
    "getUniqueUserCount(result))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(getSurveysOfUsersWhoAnsweredBoth(gform, gfMode = True, rmMode = True)[localplayerguidkey])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getSurveysThatAnswered tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = gform\n",
    "\n",
    "#_GFUserId = getSurveysOfBiologists(gform)[localplayerguidkey].iloc[1]\n",
    "#sample = gform[gform[localplayerguidkey] == _GFUserId]\n",
    "\n",
    "hardPolicy = True\n",
    "questionsAndPositiveAnswers = [[QStudiedBiology, biologyStudyPositives],\n",
    "                               [QHeardSynBioOrBioBricks, heardAboutBioBricksPositives],\n",
    "\n",
    "#def getSurveysThatAnswered(sample, questionsAndPositiveAnswers, hardPolicy = True):\n",
    "filterSeries = []\n",
    "if hardPolicy:\n",
    "    filterSeries = pd.Series(True, sample.index)\n",
    "    for question, positiveAnswers in questionsAndPositiveAnswers:\n",
    "        filterSeries = filterSeries & (sample[question].isin(positiveAnswers))\n",
    "else:\n",
    "    filterSeries = pd.Series(False, sample.index)\n",
    "    for question, positiveAnswers in questionsAndPositiveAnswers:\n",
    "        filterSeries = filterSeries | (sample[question].isin(positiveAnswers))\n",
    "result = sample[filterSeries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getSurveysOfBiologists tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = gform\n",
    "hardPolicy = True\n",
    "\n",
    "#def getSurveysOfBiologists(sample, hardPolicy = True):\n",
    "#QStudiedBiology biologyStudyPositives\n",
    "#irrelevant QInterestBiology biologyInterestPositives\n",
    "#QHeardSynBioOrBioBricks heardAboutBioBricksPositives\n",
    "\n",
    "questionsAndPositiveAnswers = [[QStudiedBiology, biologyStudyPositives],\n",
    "                           [QHeardSynBioOrBioBricks, heardAboutBioBricksPositives]],\n",
    "\n",
    "result = getSurveysThatAnswered(sample, questionsAndPositiveAnswers, hardPolicy)\n",
    "print(len(result) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gform.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_GFUserId = getSurveysOfBiologists(gform)[localplayerguidkey].iloc[0]\n",
    "sample = gform[gform[localplayerguidkey] == _GFUserId]\n",
    "len(getSurveysOfBiologists(sample)) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getSurveysOfGamers tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = gform\n",
    "hardPolicy = True\n",
    "\n",
    "#def getSurveysOfGamers(sample, hardPolicy = True):\n",
    "#QInterestVideoGames #interestPositives\n",
    "#QPlayVideoGames #frequencyPositives\n",
    "\n",
    "questionsAndPositiveAnswers = [[QInterestVideoGames, interestPositives], [QPlayVideoGames, frequencyPositives]]\n",
    "\n",
    "result = getSurveysThatAnswered(sample, questionsAndPositiveAnswers, hardPolicy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(filterSeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(afters[afters[QPlayed1].isin(previousPlayPositives)\n",
    "           | afters[QPlayed2].isin(previousPlayPositives)\n",
    "           | afters[QPlayed3].isin(previousPlayPositives)\n",
    "           | afters[QPlayed4].isin(previousPlayPositives)\n",
    "          ]),\\\n",
    "len(afters[afters[QPlayed1].isin(previousPlayPositives)]),\\\n",
    "len(afters[afters[QPlayed2].isin(previousPlayPositives)]),\\\n",
    "len(afters[afters[QPlayed3].isin(previousPlayPositives)]),\\\n",
    "len(afters[afters[QPlayed4].isin(previousPlayPositives)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getSurveysWithMatchingAnswers tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_GFUserId = getSurveysOfBiologists(gform)[localplayerguidkey].iloc[2]\n",
    "_gformRow = gform[gform[localplayerguidkey] == _GFUserId].iloc[0]\n",
    "sample = gform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = gform\n",
    "_gformRow = gform[gform[localplayerguidkey] == _GFUserId].iloc[0]\n",
    "hardPolicy = False\n",
    "#QAge\n",
    "#QGender\n",
    "#QInterestVideoGames\n",
    "#QPlayVideoGames\n",
    "#QStudiedBiology\n",
    "#QInterestBiology\n",
    "#QHeardSynBioOrBioBricks\n",
    "#QLanguage\n",
    "strictList = [QAge, QGender]\n",
    "extendedList = [QInterestVideoGames, QPlayVideoGames, QStudiedBiology, QHeardSynBioOrBioBricks, QLanguage]\n",
    "\n",
    "\n",
    "\n",
    "#def getSurveysWithMatchingAnswers(sample, _gformRow, strictList, extendedList = [], hardPolicy = False):\n",
    "questions = strictList\n",
    "\n",
    "if (hardPolicy):\n",
    "    questions += extendedList\n",
    "\n",
    "questionsAndPositiveAnswers = []\n",
    "for q in questions:\n",
    "    questionsAndPositiveAnswers.append([q, [_gformRow[q]]])\n",
    "\n",
    "getSurveysThatAnswered(sample, questionsAndPositiveAnswers, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getMatchingDemographics tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = gform\n",
    "_gformRow = gform[gform[localplayerguidkey] == _GFUserId].iloc[0]\n",
    "hardPolicy = True\n",
    "\n",
    "#def getMatchingDemographics(sample, _gformRow, hardPolicy = False):\n",
    "# age and gender\n",
    "#QAge\n",
    "#QGender\n",
    "\n",
    "# interests, hobbies, and knowledge - evaluation may vary after playing\n",
    "#QInterestVideoGames\n",
    "#QPlayVideoGames\n",
    "#QStudiedBiology\n",
    "#QInterestBiology\n",
    "#QHeardSynBioOrBioBricks\n",
    "\n",
    "# language may vary: players may have missed the opportunity to set it, or may want to try and change it\n",
    "#QLanguage\n",
    "\n",
    "getSurveysWithMatchingAnswers(\n",
    "    sample, \n",
    "    _gformRow, [QAge, QGender], \n",
    "    extendedList = [QInterestVideoGames, QPlayVideoGames, QStudiedBiology, QHeardSynBioOrBioBricks, QLanguage], \n",
    "    hardPolicy = hardPolicy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionsAndPositiveAnswers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getGFormRowCorrection tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gformRow = gform[gform[localplayerguidkey] == _GFUserId].iloc[0]\n",
    "_source = correctAnswers\n",
    "\n",
    "#def getGFormRowCorrection( _gformRow, _source = correctAnswers):\n",
    "result = _gformRow.copy()\n",
    "\n",
    "if(len(_gformRow) == 0):\n",
    "    print(\"this gform row is empty\")\n",
    "\n",
    "else:\n",
    "    result = pd.Series(index = _gformRow.index, data = np.full(len(_gformRow), np.nan))\n",
    "\n",
    "    for question in result.index:\n",
    "        _correctAnswers = _source.loc[question]\n",
    "\n",
    "        if(len(_correctAnswers) > 0):\n",
    "            result.loc[question] = False\n",
    "            for _correctAnswer in _correctAnswers:\n",
    "                if str(_gformRow.loc[question]).startswith(str(_correctAnswer)):\n",
    "                    result.loc[question] = True\n",
    "                    break\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getGFormRowScore tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_gformRow = gform[gform[localplayerguidkey] == _GFUserId].iloc[0]\n",
    "_source = correctAnswers\n",
    "\n",
    "\n",
    "#def getGFormRowScore( _gformRow, _source = correctAnswers):\n",
    "correction = getGFormRowCorrection( _gformRow, _source = _source)\n",
    "_counts = correction.value_counts()\n",
    "_thisScore = 0\n",
    "if(True in _counts):\n",
    "    _thisScore = _counts[True]\n",
    "_thisScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getGFormDataPreview tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_GFUserId = getSurveysOfBiologists(gform)[localplayerguidkey].iloc[2]\n",
    "sample = gform\n",
    "\n",
    "\n",
    "# for per-gform, manual analysis\n",
    "#def getGFormDataPreview(_GFUserId, sample):\n",
    "gforms = gform[gform[localplayerguidkey] == _GFUserId]\n",
    "result = {}\n",
    "for _ilocIndex in range(0, len(gforms)):\n",
    "    gformsIndex = gforms.index[_ilocIndex]\n",
    "    currentGForm = gforms.iloc[_ilocIndex]\n",
    "    \n",
    "    subresult = {}\n",
    "    subresult['date'] = currentGForm[QTimestamp]\n",
    "    subresult['temporality RM'] = currentGForm[QTemporality]\n",
    "    subresult['temporality GF'] = getGFormRowGFormTemporality(currentGForm)\n",
    "    subresult['score'] = getGFormRowScore(currentGForm)\n",
    "    subresult['genderAge'] = [currentGForm[QGender], currentGForm[QAge]]\n",
    "    \n",
    "    # search for other users with similar demographics\n",
    "    matchingDemographics = getMatchingDemographics(sample, currentGForm)\n",
    "    matchingDemographicsIds = []\n",
    "    #print(type(matchingDemographics))\n",
    "    #print(matchingDemographics.index)\n",
    "    for matchesIndex in matchingDemographics.index:\n",
    "        matchingDemographicsIds.append([matchesIndex, matchingDemographics.loc[matchesIndex, localplayerguidkey]])\n",
    "    \n",
    "    subresult['demographic matches'] = matchingDemographicsIds\n",
    "    \n",
    "    result['survey' + str(_ilocIndex)] = subresult\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for match in result['survey0']['demographic matches']:\n",
    "    print(match[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
