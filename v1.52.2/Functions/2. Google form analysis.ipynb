{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google form analysis\n",
    "\n",
    "Analysis of results extracted from Google forms in csv format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "\n",
    "[Preparation](#preparation)\n",
    "\n",
    "[Constants](#constants)\n",
    "\n",
    "[Functions](#functions)\n",
    "   \n",
    "   - [general purpose](#genpurpose)\n",
    "   \n",
    "   - [sessions and temporalities](#sessions)\n",
    "   \n",
    "   - [score](#score)\n",
    "   \n",
    "   - [visualizations](#visualizations)\n",
    "   \n",
    "   - [sample getters](#samples)\n",
    "   \n",
    "   - [checkpoint validation](#checkvalidation)\n",
    "   \n",
    "   - [p(answered question N | answered question P)](#condproba)\n",
    "   \n",
    "   - [Filtering users](#filteringusers)\n",
    "   \n",
    "[Initialization of gform](#gforminit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "<a id=preparation />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run \"../Functions/2. Game sessions.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants\n",
    "<a id=constants />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special user ids\n",
    "userIDThatDidNotAnswer = '001c95c6-8207-43dc-a51b-adf0c6e005d7'\n",
    "\n",
    "userID1AnswerEN = '00dbbdca-d86c-4bc9-803c-0602e0153f68'\n",
    "userIDAnswersEN = '5977184a-1be2-4725-9b48-f2782dc03efb'\n",
    "userID1ScoreEN = '6b5d392d-b737-49ef-99af-e8c445ff6379'\n",
    "userIDScoresEN = '5ecf601d-4eac-433e-8056-3a5b9eda0555'\n",
    "\n",
    "userID1AnswerFR = '2734a37d-4ba5-454f-bf85-1f7b767138f6'\n",
    "userIDAnswersFR = '01e85778-2903-447b-bbab-dd750564ee2d'\n",
    "userID1ScoreFR = '3d733347-0313-441a-b77c-3e4046042a53'\n",
    "userIDScoresFR = '58d22690-8604-41cf-a5b7-d71fb3b9ad5b'\n",
    "\n",
    "userIDAnswersENFR = 'a7936587-8b71-43b6-9c61-17b2c2b55de3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#localplayerguidkey = 'Ne pas modifier - identifiant anonyme pr√©rempli'\n",
    "localplayerguidkey = 'Do not edit -  pre-filled anonymous ID'\n",
    "localplayerguidindex = gform.columns.get_loc(localplayerguidkey)\n",
    "localplayerguidindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstEvaluationQuestionKey = 'In order to modify the abilities of the bacterium, you have to...'\n",
    "firstEvaluationQuestionIndex = gform.columns.get_loc(firstEvaluationQuestionKey)\n",
    "firstEvaluationQuestionIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answersColumnNameStem = \"answers\"\n",
    "correctionsColumnNameStem = \"corrections\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "<a id=functions />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general purpose\n",
    "<a id=genpurpose />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUniqueUserCount(sample):\n",
    "    return sample[localplayerguidkey].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllResponders( _form = gform ):\n",
    "    userIds = _form[localplayerguidkey].unique()\n",
    "    return userIds\n",
    "\n",
    "def getRandomGFormGUID():\n",
    "    _uniqueUsers = getAllResponders()\n",
    "    _userCount = len(_uniqueUsers)\n",
    "    _guid = '0'\n",
    "    while (not isGUIDFormat(_guid)):\n",
    "        _userIndex = randint(0,_userCount-1)\n",
    "        _guid = _uniqueUsers[_userIndex]\n",
    "    return _guid\n",
    "\n",
    "def hasAnswered( userId, _form = gform ):\n",
    "    return userId in _form[localplayerguidkey].values\n",
    "\n",
    "def getAnswers( userId, _form = gform ):\n",
    "    answers = _form[_form[localplayerguidkey]==userId]\n",
    "    _columnAnswers = answers.T\n",
    "    \n",
    "    if 0 != len(answers):\n",
    "        _newColumns = []\n",
    "        for column in _columnAnswers.columns:\n",
    "            _newColumns.append(answersColumnNameStem + str(column))\n",
    "        _columnAnswers.columns = _newColumns\n",
    "    else:\n",
    "        # user has never answered\n",
    "        print(\"user \" + str(userId) + \" has never answered\")\n",
    "        \n",
    "    return _columnAnswers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sessions and temporalities\n",
    "<a id=sessions />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setAnswerTemporalities( _gformDF = gform ):\n",
    "    # check whether temporalities have already been set\n",
    "    if(len(_gformDF['Temporality'].unique()) == 1):\n",
    "        # format : key = _userId, value = [_firstEventDate, 0 or _gformDF.index of before, 0 or _gformDF.index of after]\n",
    "        temporalities = {}\n",
    "\n",
    "        for _index in _gformDF.index:\n",
    "            _userId = _gformDF.loc[_index,localplayerguidkey]\n",
    "            _firstEventDate, beforeIndex, afterIndex = [0,0,0]\n",
    "\n",
    "            if _userId in temporalities:\n",
    "                _firstEventDate, beforeIndex, afterIndex = temporalities[_userId]\n",
    "            else:\n",
    "                _firstEventDate = getFirstEventDate(_userId)\n",
    "\n",
    "            temporality = getTemporality(_gformDF.loc[_index,'Timestamp'],_firstEventDate)\n",
    "\n",
    "            if temporality == answerTemporalities[0] and beforeIndex != 0 :\n",
    "                if _gformDF.loc[_index,'Timestamp'] > _gformDF.loc[beforeIndex,'Timestamp']:\n",
    "                    _gformDF.loc[beforeIndex,'Temporality'] = answerTemporalities[2]\n",
    "                else:\n",
    "                    temporality = answerTemporalities[2]\n",
    "            elif temporality == answerTemporalities[1] and afterIndex != 0 :\n",
    "                if _gformDF.loc[_index,'Timestamp'] < _gformDF.loc[afterIndex,'Timestamp']:\n",
    "                    _gformDF.loc[afterIndex,'Temporality'] = answerTemporalities[2]\n",
    "                else:\n",
    "                    temporality = answerTemporalities[2]\n",
    "\n",
    "            _gformDF.loc[_index,'Temporality'] = temporality\n",
    "            if temporality == answerTemporalities[0]:\n",
    "                beforeIndex = _index\n",
    "            elif temporality == answerTemporalities[1]:\n",
    "                afterIndex = _index\n",
    "\n",
    "            temporalities[_userId] = [_firstEventDate, beforeIndex, afterIndex]\n",
    "        print(\"temporalities set\")\n",
    "\n",
    "# when did the user answer the questionnaire? \n",
    "# After gameEventDate, before gameEventDate, undefined?\n",
    "# answerDate is assumed to be the gform Timestamp, UTC\n",
    "# gameEventDate is assumed to be of type pandas._libs.tslib.Timestamp, UTC, from RedMetrics\n",
    "def getTemporality( answerDate, gameEventDate ):\n",
    "    result = answerTemporalities[2]\n",
    "    if(gameEventDate != pd.Timestamp.max.tz_localize('utc')):\n",
    "        if(answerDate <= gameEventDate):\n",
    "            result = answerTemporalities[0]\n",
    "        elif (answerDate > gameEventDate):\n",
    "            result = answerTemporalities[1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score\n",
    "<a id=score />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorrections( _userId, _source = correctAnswers, _form = gform, _columnAnswers = [] ):\n",
    "    if(len(_columnAnswers) == 0):\n",
    "        _columnAnswers = getAnswers( _userId, _form = _form )\n",
    "\n",
    "    if 0 != len(_columnAnswers.columns):\n",
    "\n",
    "        _questionsCount = len(_columnAnswers.values)\n",
    "\n",
    "        for _columnName in _columnAnswers.columns:\n",
    "            if answersColumnNameStem in _columnName:\n",
    "                _answerNumber = _columnName.replace(answersColumnNameStem,\"\")\n",
    "                newCorrectionsColumnName = correctionsColumnNameStem + _answerNumber\n",
    "\n",
    "                #_columnAnswers[newCorrectionsColumnName] = _columnAnswers[_columnName]\n",
    "                _columnAnswers[newCorrectionsColumnName] = pd.Series(np.full(_questionsCount, np.nan))\n",
    "\n",
    "                for question in _columnAnswers[_columnName].index:\n",
    "                    _correctAnswers = _source.loc[question]\n",
    "                    \n",
    "                    if(len(_correctAnswers) > 0):\n",
    "                        _columnAnswers.loc[question,newCorrectionsColumnName] = False\n",
    "                        for _correctAnswer in _correctAnswers:\n",
    "                            if str(_columnAnswers.loc[question,_columnName])\\\n",
    "                            .startswith(str(_correctAnswer)):\n",
    "                                _columnAnswers.loc[question,newCorrectionsColumnName] = True\n",
    "                                break\n",
    "                        \n",
    "\n",
    "    else:\n",
    "        # user has never answered\n",
    "        print(\"can't give correct answers\")\n",
    "    return _columnAnswers\n",
    "    \n",
    "\n",
    "# edits in-place\n",
    "# _corrections must be a dataframe full of corrections as produced above\n",
    "def getBinarizedCorrections( _corrections ):\n",
    "    for _columnName in _corrections.columns:\n",
    "        for _index in _corrections[_columnName].index:\n",
    "            if(True==_corrections.loc[_index,_columnName]):\n",
    "                _corrections.loc[_index,_columnName] = 1.0\n",
    "            elif (False==_corrections.loc[_index,_columnName]):\n",
    "                _corrections.loc[_index,_columnName] = 0.0\n",
    "    return _corrections\n",
    "\n",
    "# only for one line in the gform\n",
    "def getBinarized(_gformLine, _source = correctAnswers):\n",
    "    _notEmptyIndexes = []\n",
    "    for _index in _source.index:\n",
    "        if(len(_source.loc[_index]) > 0):\n",
    "            _notEmptyIndexes.append(_index)\n",
    "\n",
    "    _binarized = pd.Series(np.full(len(_gformLine.index), np.nan), index = _gformLine.index)\n",
    "\n",
    "    for question in _gformLine.index:\n",
    "        _correctAnswers = _source.loc[question]\n",
    "\n",
    "        if(len(_correctAnswers) > 0):\n",
    "            _binarized[question] = 0\n",
    "            for _correctAnswer in _correctAnswers:\n",
    "                if str(_gformLine.loc[question])\\\n",
    "                .startswith(str(_correctAnswer)):\n",
    "                    _binarized.loc[question] = 1\n",
    "                    break\n",
    "\n",
    "    _slicedBinarized = _binarized.loc[_notEmptyIndexes]\n",
    "    return _slicedBinarized\n",
    "\n",
    "def getAllBinarized(_source = correctAnswers, _form = gform ):\n",
    "    _notEmptyIndexes = []\n",
    "    for _index in _source.index:\n",
    "        if(len(_source.loc[_index]) > 0):\n",
    "            _notEmptyIndexes.append(_index)\n",
    "\n",
    "    _result = pd.DataFrame(index = _notEmptyIndexes)\n",
    "    for _userId in getAllResponders( _form = _form ):\n",
    "        _corrections = getCorrections(_userId, _source=_source, _form = _form)\n",
    "        _binarized = getBinarizedCorrections(_corrections)\n",
    "        _slicedBinarized =\\\n",
    "    _binarized.loc[_notEmptyIndexes][_binarized.columns[\\\n",
    "    _binarized.columns.to_series().str.contains(correctionsColumnNameStem)\\\n",
    "                                       ]]\n",
    "\n",
    "        _result = pd.concat([_result, _slicedBinarized], axis=1)\n",
    "\n",
    "    _result = _result.T\n",
    "        \n",
    "    return _result\n",
    "    \n",
    "\n",
    "# CCA.iloc[i,j] is the number of users who correctly answered questions number i and j\n",
    "# CCA[i,j] = Sum(A[u,i] * A[u,j], u in users) = Sum(tA[i,u] * A[u,j], u in users) = tA.A[i,j]\n",
    "# CCA[i,j] is an int\n",
    "def getCrossCorrectAnswers( _binarizedAnswers ):\n",
    "    return _binarizedAnswers.T.dot(_binarizedAnswers)\n",
    "\n",
    "#function that returns the score from user id\n",
    "scoreLabel = 'score'\n",
    "def getScore( _userId, _form = gform, _source = correctAnswers ):\n",
    "    _score = pd.DataFrame({}, columns = answerTemporalities)\n",
    "    _score.loc[scoreLabel,:] = np.nan\n",
    "    for _column in _score.columns:\n",
    "        _score.loc[scoreLabel, _column] = []\n",
    "\n",
    "    if hasAnswered( _userId, _form = _form ):\n",
    "        _columnAnswers = getCorrections(_userId, _form = _form, _source = _source)\n",
    "        for _columnName in _columnAnswers.columns:\n",
    "            # only work on corrected columns\n",
    "            if correctionsColumnNameStem in _columnName:\n",
    "                _answerColumnName = _columnName.replace(correctionsColumnNameStem,\\\n",
    "                                                      answersColumnNameStem)\n",
    "                _temporality = _columnAnswers.loc['Temporality',_answerColumnName]\n",
    "\n",
    "                _counts = (_columnAnswers[_columnName]).value_counts()\n",
    "                _thisScore = 0\n",
    "                if(True in _counts):\n",
    "                    _thisScore = _counts[True]\n",
    "                _score.loc[scoreLabel,_temporality].append(_thisScore)\n",
    "    else:\n",
    "        print(\"user \" + str(_userId) + \" has never answered\")\n",
    "\n",
    "    return _score\n",
    "\n",
    "\n",
    "def getGFormRowCorrection( _gformRow, _source = correctAnswers):\n",
    "    result = _gformRow.copy()\n",
    "\n",
    "    if(len(_gformRow) == 0):\n",
    "        print(\"this gform row is empty\")\n",
    "\n",
    "    else:\n",
    "        result = pd.Series(index = _gformRow.index, data = np.full(len(_gformRow), np.nan))\n",
    "\n",
    "        for question in result.index:\n",
    "            _correctAnswers = _source.loc[question]\n",
    "\n",
    "            if(len(_correctAnswers) > 0):\n",
    "                result.loc[question] = False\n",
    "                for _correctAnswer in _correctAnswers:\n",
    "                    if str(_gformRow.loc[question]).startswith(str(_correctAnswer)):\n",
    "                        result.loc[question] = True\n",
    "                        break\n",
    "    return result\n",
    "\n",
    "def getGFormRowScore( _gformRow, _source = correctAnswers):\n",
    "    correction = getGFormRowCorrection( _gformRow, _source = _source)\n",
    "    _counts = correction.value_counts()\n",
    "    _thisScore = 0\n",
    "    if(True in _counts):\n",
    "        _thisScore = _counts[True]\n",
    "    return _thisScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualizations\n",
    "<a id=visualizations />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createStatSet(series, ids = pd.Series()):\n",
    "    if(0 == len(ids)):\n",
    "        ids = series.index\n",
    "    result = {\n",
    "        'count' : len(ids),\n",
    "        'unique' : len(ids.unique()),\n",
    "        'median' : series.median(),\n",
    "        'mean' : series.mean(),\n",
    "        'std' : series.std(),\n",
    "    }\n",
    "    return result\n",
    "\n",
    "# _binarized must be well-formed, similarly to getAllBinarized's output\n",
    "def getPercentagePerQuestion(_binarized):\n",
    "    totalPerQuestionDF = pd.DataFrame(data=np.dot(np.ones(_binarized.shape[0]), _binarized), index=_binarized.columns)\n",
    "    percentagePerQuestion = totalPerQuestionDF*100 / _binarized.shape[0]\n",
    "    return percentagePerQuestion\n",
    "\n",
    "## sample can be: all, those who answered both before and after,\n",
    "## those who played between date1 and date2, ...\n",
    "from scipy.stats import ttest_ind\n",
    "def plotBasicStats(\n",
    "    sample,\n",
    "    title = '',\n",
    "    includeAll = False,\n",
    "    includeBefore = True,\n",
    "    includeAfter = True,\n",
    "    includeUndefined = False,\n",
    "    includeProgress = True,\n",
    "    includeRelativeProgress = False,\n",
    "):\n",
    "    \n",
    "    stepsPerInclude = 2\n",
    "    includeCount = np.sum([includeAll, includeBefore, includeAfter, includeUndefined, includeProgress])\n",
    "    stepsCount = stepsPerInclude*includeCount + 3\n",
    "    \n",
    "    #print(\"stepsPerInclude=\" + str(stepsPerInclude))\n",
    "    #print(\"includeCount=\" + str(includeCount))\n",
    "    #print(\"stepsCount=\" + str(stepsCount))\n",
    "    \n",
    "    __progress = FloatProgress(min=0, max=stepsCount)\n",
    "    display(__progress)\n",
    "    \n",
    "    sampleBefore = sample[sample['Temporality'] == 'before']\n",
    "    sampleAfter = sample[sample['Temporality'] == 'after']\n",
    "    sampleUndefined = sample[sample['Temporality'] == 'undefined']\n",
    "\n",
    "    #uniqueBefore = sampleBefore[localplayerguidkey]\n",
    "    #uniqueAfter = \n",
    "    #uniqueUndefined =\n",
    "\n",
    "    scientificQuestions = correctAnswers.copy()\n",
    "    allQuestions = correctAnswers + demographicAnswers\n",
    "    \n",
    "    categories = ['all', 'before', 'after', 'undefined', 'progress', 'rel. progress']\n",
    "    data = {}\n",
    "    \n",
    "    sciBinarized = pd.DataFrame()\n",
    "    allBinarized = pd.DataFrame()\n",
    "    scoresAll = pd.DataFrame()\n",
    "    \n",
    "    sciBinarizedBefore = pd.DataFrame()\n",
    "    allBinarizedBefore = pd.DataFrame()\n",
    "    scoresBefore = pd.DataFrame()\n",
    "    \n",
    "    sciBinarizedAfter = pd.DataFrame()\n",
    "    allBinarizedAfter = pd.DataFrame()\n",
    "    scoresAfter = pd.DataFrame()\n",
    "    \n",
    "    sciBinarizedUndefined = pd.DataFrame()\n",
    "    allBinarizedUndefined = pd.DataFrame()\n",
    "    scoresUndefined = pd.DataFrame()\n",
    "\n",
    "    scoresProgress = pd.DataFrame()\n",
    "\n",
    "    ## basic stats:\n",
    "    ### mean score\n",
    "    ### median score\n",
    "    ### std\n",
    "    if includeAll:\n",
    "        sciBinarized = getAllBinarized( _source = scientificQuestions, _form = sample)\n",
    "        __progress.value += 1\n",
    "        allBinarized = getAllBinarized( _source = allQuestions, _form = sample)\n",
    "        __progress.value += 1\n",
    "        scoresAll = pd.Series(np.dot(sciBinarized, np.ones(sciBinarized.shape[1])))\n",
    "        \n",
    "        data[categories[0]] = createStatSet(scoresAll, sample[localplayerguidkey])\n",
    "        \n",
    "    if includeBefore or includeProgress:\n",
    "        sciBinarizedBefore = getAllBinarized( _source = scientificQuestions, _form = sampleBefore)\n",
    "        __progress.value += 1\n",
    "        allBinarizedBefore = getAllBinarized( _source = allQuestions, _form = sampleBefore)\n",
    "        __progress.value += 1\n",
    "        scoresBefore = pd.Series(np.dot(sciBinarizedBefore, np.ones(sciBinarizedBefore.shape[1])))\n",
    "        temporaryStatSetBefore = createStatSet(scoresBefore, sampleBefore[localplayerguidkey])\n",
    "    if includeBefore:\n",
    "        data[categories[1]] = temporaryStatSetBefore\n",
    "        \n",
    "    if includeAfter or includeProgress:\n",
    "        sciBinarizedAfter = getAllBinarized( _source = scientificQuestions, _form = sampleAfter)\n",
    "        __progress.value += 1\n",
    "        allBinarizedAfter = getAllBinarized( _source = allQuestions, _form = sampleAfter)\n",
    "        __progress.value += 1\n",
    "        scoresAfter = pd.Series(np.dot(sciBinarizedAfter, np.ones(sciBinarizedAfter.shape[1])))\n",
    "        temporaryStatSetAfter = createStatSet(scoresAfter, sampleAfter[localplayerguidkey])\n",
    "    if includeAfter:\n",
    "        data[categories[2]] = temporaryStatSetAfter\n",
    "        \n",
    "    if includeUndefined:\n",
    "        sciBinarizedUndefined = getAllBinarized( _source = scientificQuestions, _form = sampleUndefined)\n",
    "        __progress.value += 1\n",
    "        allBinarizedUndefined = getAllBinarized( _source = allQuestions, _form = sampleUndefined)\n",
    "        __progress.value += 1\n",
    "        scoresUndefined = pd.Series(np.dot(sciBinarizedUndefined, np.ones(sciBinarizedUndefined.shape[1])))\n",
    "        \n",
    "        data[categories[3]] = createStatSet(scoresUndefined, sampleUndefined[localplayerguidkey])\n",
    "\n",
    "    if includeProgress:\n",
    "        data[categories[4]] = {\n",
    "            'count' : min(temporaryStatSetAfter['count'], temporaryStatSetBefore['count']),\n",
    "            'unique' : min(temporaryStatSetAfter['unique'], temporaryStatSetBefore['unique']),\n",
    "            'median' : temporaryStatSetAfter['median']-temporaryStatSetBefore['median'],\n",
    "            'mean' : temporaryStatSetAfter['mean']-temporaryStatSetBefore['mean'],\n",
    "            'std' : temporaryStatSetAfter['std']-temporaryStatSetBefore['std'],\n",
    "        }\n",
    "        __progress.value += 2\n",
    "    \n",
    "    \n",
    "    result = pd.DataFrame(data)\n",
    "    __progress.value += 1\n",
    "\n",
    "    print(title)\n",
    "    print(result)\n",
    "    if (includeBefore and includeAfter) or includeProgress:\n",
    "        if (len(scoresBefore) > 2 and len(scoresAfter) > 2):\n",
    "            ttest = ttest_ind(scoresBefore, scoresAfter)\n",
    "            print(\"t test: statistic=\" + repr(ttest.statistic) + \" pvalue=\" + repr(ttest.pvalue))\n",
    "    print()\n",
    "\n",
    "    ## percentage correct\n",
    "    ### percentage correct - max 5 columns\n",
    "    percentagePerQuestionAll = pd.DataFrame()\n",
    "    percentagePerQuestionBefore = pd.DataFrame()\n",
    "    percentagePerQuestionAfter = pd.DataFrame()\n",
    "    percentagePerQuestionUndefined = pd.DataFrame()\n",
    "    percentagePerQuestionProgress = pd.DataFrame()\n",
    "    \n",
    "    tables = []\n",
    "\n",
    "    if includeAll:\n",
    "        percentagePerQuestionAll = getPercentagePerQuestion(allBinarized)\n",
    "        tables.append([percentagePerQuestionAll, categories[0]])\n",
    "        \n",
    "    if includeBefore or includeProgress:\n",
    "        percentagePerQuestionBefore = getPercentagePerQuestion(allBinarizedBefore)\n",
    "    if includeBefore:\n",
    "        tables.append([percentagePerQuestionBefore, categories[1]])\n",
    "        \n",
    "    if includeAfter or includeProgress:\n",
    "        percentagePerQuestionAfter = getPercentagePerQuestion(allBinarizedAfter)\n",
    "    if includeAfter:\n",
    "        tables.append([percentagePerQuestionAfter, categories[2]])\n",
    "        \n",
    "    if includeUndefined:\n",
    "        percentagePerQuestionUndefined = getPercentagePerQuestion(allBinarizedUndefined)\n",
    "        tables.append([percentagePerQuestionUndefined, categories[3]])\n",
    "        \n",
    "    if includeProgress or includeRelativeProgress:\n",
    "        percentagePerQuestionProgress = percentagePerQuestionAfter - percentagePerQuestionBefore\n",
    "        \n",
    "        if includeProgress:\n",
    "            tables.append([percentagePerQuestionProgress, categories[4]])\n",
    "            \n",
    "        if includeRelativeProgress:\n",
    "            # use temporaryStatSetAfter['count'], temporaryStatSetBefore['count']?\n",
    "            percentagePerQuestionProgress2 = percentagePerQuestionProgress.copy()\n",
    "            for index in range(0,len(percentagePerQuestionProgress.index)):\n",
    "                if (0 == percentagePerQuestionBefore.iloc[index,0]):\n",
    "                    percentagePerQuestionProgress2.iloc[index,0] = 0\n",
    "                else:\n",
    "                    percentagePerQuestionProgress2.iloc[index,0] = \\\n",
    "                    percentagePerQuestionProgress.iloc[index,0]/percentagePerQuestionBefore.iloc[index,0]\n",
    "            tables.append([percentagePerQuestionProgress2, categories[5]])\n",
    "    \n",
    "    __progress.value += 1\n",
    "\n",
    "    graphTitle = '% correct: '\n",
    "    toConcat = []\n",
    "    \n",
    "    for table,category in tables:\n",
    "        concat = (len(table.values) > 0)\n",
    "        for elt in table.iloc[:,0].values:\n",
    "            if np.isnan(elt):\n",
    "                concat = False\n",
    "                break\n",
    "        if(concat):\n",
    "            graphTitle = graphTitle + category + ' '\n",
    "            toConcat.append(table)\n",
    "\n",
    "    if (len(toConcat) > 0):\n",
    "        percentagePerQuestionConcatenated = pd.concat(\n",
    "            toConcat\n",
    "            , axis=1)\n",
    "\n",
    "        if(len(title) > 0):\n",
    "            graphTitle = graphTitle + ' - ' + title\n",
    "\n",
    "        _fig = plt.figure(figsize=(20,20))\n",
    "        _ax1 = plt.subplot(111)\n",
    "        _ax1.set_title(graphTitle)\n",
    "        sns.heatmap(percentagePerQuestionConcatenated.round().astype(int),ax=_ax1,cmap=plt.cm.jet,square=True,annot=True,fmt='d')\n",
    "    __progress.value += 1\n",
    "    \n",
    "    ### percentage cross correct\n",
    "    ### percentage cross correct, conditionnally\n",
    "    \n",
    "    if(__progress.value != stepsCount):\n",
    "        print(\"__progress.value=\" + str(__progress.value) + \" != stepsCount=\" + str(stepsCount))\n",
    "\n",
    "    return sciBinarized, sciBinarizedBefore, sciBinarizedAfter, sciBinarizedUndefined, \\\n",
    "            allBinarized, allBinarizedBefore, allBinarizedAfter, allBinarizedUndefined\n",
    "\n",
    "    \n",
    "    \n",
    "def plotCorrelationMatrices(\n",
    "    allBinarized = [],\n",
    "    beforeBinarized = [],\n",
    "    afterBinarized = [],\n",
    "    undefinedBinarized = [],\n",
    "    titleAll = 'Correlation of pre- & post-test answers',\n",
    "    titleBefore = 'Correlation of pre-test answers',\n",
    "    titleAfter = 'Correlation of post-test answers',\n",
    "    titleUndefined = 'Correlation of undefined answers',\n",
    "    titleSuffix = '',\n",
    "):\n",
    "    dataBinarized = [allBinarized, beforeBinarized, afterBinarized, undefinedBinarized]\n",
    "    titles = [titleAll + titleSuffix, titleBefore + titleSuffix, titleAfter + titleSuffix, titleUndefined + titleSuffix]\n",
    "    \n",
    "    for index in range(0, len(dataBinarized)):\n",
    "        if(len(dataBinarized[index]) > 0):\n",
    "            plotCorrelationMatrix(\n",
    "                dataBinarized[index],\n",
    "                _abs=True,\n",
    "                _clustered=False,\n",
    "                _questionNumbers=True,\n",
    "                _annot = True,\n",
    "                _figsize = (20,20),\n",
    "                _title=titles[index],\n",
    "            )\n",
    "    \n",
    "##correlation\n",
    "### simple heatmap\n",
    "### clustermap\n",
    "methods = ['pearson', 'kendall', 'spearman']\n",
    "def plotCorrelationMatrix( \n",
    "    _binarizedMatrix, \n",
    "    _method = methods[0], \n",
    "    _title='Questions\\' Correlations', \n",
    "    _abs=False, \n",
    "    _clustered=False, \n",
    "    _questionNumbers=False,\n",
    "    _annot = False,\n",
    "    _figsize = (10,10),\n",
    "    _metric='euclidean'\n",
    "):\n",
    "    \n",
    "    _progress = FloatProgress(min=0, max=7)\n",
    "    display(_progress)\n",
    "    \n",
    "    _overlay = False\n",
    "\n",
    "    _progress.value += 1\n",
    "    \n",
    "    # computation of correlation matrix\n",
    "    _m = _method\n",
    "    if(not (_method in methods)):\n",
    "        _m = methods[0]\n",
    "    _correlation = _binarizedMatrix.astype(float).corr(_m)\n",
    "    _progress.value += 1\n",
    "    if(_abs):\n",
    "        _correlation = _correlation.abs()\n",
    "    _progress.value += 1\n",
    "    \n",
    "    if(_clustered):\n",
    "    # removing NaNs\n",
    "    # can't cluster NaN lines in _correlation\n",
    "        _notNaNsIndices = []\n",
    "        _notNaNsColumns = []\n",
    "        for index in _correlation.index:\n",
    "            if(~np.isnan(_correlation.loc[index,:]).all()):\n",
    "                _notNaNsIndices.append(index)\n",
    "        #for column in _correlation.columns:\n",
    "        #    if(~np.isnan(_correlation.loc[:,column]).all()):\n",
    "        #        _notNaNsColumns.append(column)\n",
    "        \n",
    "        _binarizedMatrix = _binarizedMatrix.loc[:,_notNaNsIndices]\n",
    "        _correlation = _correlation.loc[_notNaNsIndices,_notNaNsIndices]\n",
    "    _progress.value += 1\n",
    "        \n",
    "        \n",
    "    # optional computation of overlay\n",
    "    if(_annot):\n",
    "        _overlay = getCrossCorrectAnswers(_binarizedMatrix).astype(int)\n",
    "    _progress.value += 1\n",
    "    \n",
    "    # preparation of plot labels\n",
    "    if(_questionNumbers):\n",
    "        _correlation.columns = pd.Series(_correlation.columns).apply(\\\n",
    "                lambda x: x + ' #' + str(_correlation.columns.get_loc(x) + 1))\n",
    "        if(_clustered):\n",
    "            _correlation.index = pd.Series(_correlation.columns).apply(\\\n",
    "                lambda x: '#' + str(_correlation.columns.get_loc(x) + 1) + ' ' + x)\n",
    "        else:\n",
    "            _correlation.index = _correlation.columns\n",
    "    _progress.value += 1\n",
    "    \n",
    "    # plot\n",
    "    if(_clustered):\n",
    "        result = sns.clustermap(\\\n",
    "            _correlation,\\\n",
    "            metric=_metric,\\\n",
    "            cmap=plt.cm.jet,\\\n",
    "            square=True,\\\n",
    "            figsize=_figsize,\\\n",
    "            annot=_overlay,\\\n",
    "            fmt='d')\n",
    "        return result, _overlay\n",
    "    \n",
    "#        if(_annot):\n",
    "            # reorder columns using clustergrid.dendrogram_col.reordered_ind\n",
    "\n",
    "            #_overlay1 = _overlay.copy()            \n",
    "\n",
    "#            reorderedCols = result.dendrogram_col.reordered_ind\n",
    "#            _overlay = _overlay\n",
    "\n",
    "            #_overlay2 = _overlay.copy().iloc[reorderedCols,reorderedCols]\n",
    "\n",
    "#            result = sns.clustermap(_correlation,metric=_metric,cmap=plt.cm.jet,square=True,figsize=_figsize,annot=_overlay, fmt='d')\n",
    "            \n",
    "            #print(_overlay1.columns == _overlay2.columns)\n",
    "            #print(_overlay1 == _overlay2)\n",
    "\n",
    "            #print(_overlay1.columns)\n",
    "            #print(_overlay1.columns)\n",
    "            #print(_overlay1)\n",
    "            #print(_overlay2)\n",
    "            \n",
    "            #return _overlay1, _overlay2\n",
    "#            return result, _overlay\n",
    "            \n",
    "    else:\n",
    "        _fig = plt.figure(figsize=_figsize)\n",
    "        _ax = plt.subplot(111)\n",
    "        _ax.set_title(_title)\n",
    "        sns.heatmap(_correlation,ax=_ax,cmap=plt.cm.jet,square=True,annot=_overlay, fmt='d')\n",
    "    _progress.value += 1\n",
    "    \n",
    "#def plotAll():\n",
    "    # loop on question types\n",
    "    # loop on temporalities\n",
    "    # loop on representations\n",
    "    ## basic stats:\n",
    "    ### mean score\n",
    "    ### median score\n",
    "    ### std\n",
    "    ## percentage correct\n",
    "    ### percentage correct - 3 columns\n",
    "    ### percentage cross correct\n",
    "    ### percentage cross correct, conditionnally\n",
    "    ##correlation\n",
    "    ### simple heatmap\n",
    "#    plotCorrelationMatrix\n",
    "    ### clustermap\n",
    "#    plotCorrelationMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plotSamples(samples):\n",
    "    _progress = FloatProgress(min=0, max=len(samples))\n",
    "    display(_progress)\n",
    "\n",
    "    for sample, title in samples:\n",
    "        plotBasicStats(sample, title)\n",
    "        _progress.value += 1\n",
    "\n",
    "    if(_progress.value != len(samples)):\n",
    "        print(\"__progress.value=\" + str(__progress.value) + \" != len(samples)=\" + str(len(samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for per-gform, manual analysis\n",
    "def getGFormDataPreview(_GFUserId, sample):\n",
    "    gforms = gform[gform[localplayerguidkey] == _GFUserId]\n",
    "    result = {}\n",
    "    \n",
    "    for _ilocIndex in range(0, len(gforms)):\n",
    "        gformsIndex = gforms.index[_ilocIndex]\n",
    "        currentGForm = gforms.iloc[_ilocIndex]\n",
    "\n",
    "        subresult = {}\n",
    "        subresult['date'] = currentGForm['Timestamp']\n",
    "        subresult['temporality RM'] = currentGForm['Temporality']\n",
    "        subresult['temporality GF'] = getGFormRowGFormTemporality(currentGForm)\n",
    "        subresult['score'] = getGFormRowScore(currentGForm)\n",
    "        subresult['genderAge'] = [currentGForm['What is your gender?'], currentGForm['How old are you?']]\n",
    "\n",
    "        # search for other users with similar demographics\n",
    "        matchingDemographics = getMatchingDemographics(sample, currentGForm)\n",
    "        matchingDemographicsIds = []\n",
    "        #print(type(matchingDemographics))\n",
    "        #print(matchingDemographics.index)\n",
    "        for matchesIndex in matchingDemographics.index:\n",
    "            matchingDemographicsIds.append([matchesIndex, matchingDemographics.loc[matchesIndex, localplayerguidkey]])\n",
    "\n",
    "        subresult['demographic matches'] = matchingDemographicsIds\n",
    "\n",
    "        result['survey' + str(_ilocIndex)] = subresult\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample getters\n",
    "<a id=samples />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices do not need to be reset as they all come from gform\n",
    "def getUnionQuestionnaires(sample1, sample2):\n",
    "    if (not (sample1.columns == sample2.columns).all()):\n",
    "        print(\"warning: parameter columns are not the same\")\n",
    "    return pd.concat([sample1, sample2]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices do not need to be reset as they all come from gform\n",
    "def getIntersectionQuestionnaires(sample1, sample2):\n",
    "    if (not (sample1.columns == sample2.columns).all()):\n",
    "        print(\"warning: parameter columns are not the same\")\n",
    "    return pd.merge(sample1, sample2, how = 'inner').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample1 and sample2 rows where users are common to sample1 and sample2\n",
    "def getIntersectionUsersSurveys(sample1, sample2):\n",
    "    result1 = sample1[sample1[localplayerguidkey].isin(sample2[localplayerguidkey])]\n",
    "    result2 = sample2[sample2[localplayerguidkey].isin(sample1[localplayerguidkey])]\n",
    "    return getUnionQuestionnaires(result1,result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users who answered either before or after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QPlayed1 = 'Have you ever played an older version of Hero.Coli before?'\n",
    "QPlayed2 = 'Have you played the current version of Hero.Coli?'\n",
    "QPlayed3 = 'Have you played the arcade cabinet version of Hero.Coli?'\n",
    "QPlayed4 = 'Have you played the Android version of Hero.Coli?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRMBefores(sample):\n",
    "    return sample[sample['Temporality'] == 'before']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRMAfters(sample):\n",
    "    return sample[sample['Temporality'] == 'after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns users who declared that they have never played the game, whatever platform\n",
    "#  previousPlayPositives is defined in '../Static data/English localization.ipynb'\n",
    "def getGFormBefores(sample):\n",
    "    return sample[\n",
    "      ~sample[QPlayed1].isin(previousPlayPositives)\n",
    "    & ~sample[QPlayed2].isin(previousPlayPositives)\n",
    "    & ~sample[QPlayed3].isin(previousPlayPositives)\n",
    "    & ~sample[QPlayed4].isin(previousPlayPositives)\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isGFormBefore(surveyAnswerIndex, _gform):\n",
    "    return (len(getGFormBefores(_gform.loc[surveyAnswerIndex:surveyAnswerIndex, :])) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns users who declared that they have already played the game, whatever platform\n",
    "#  previousPlayPositives is defined in '../Static data/English localization.ipynb'\n",
    "def getGFormAfters(sample):\n",
    "    return sample[\n",
    "      sample[QPlayed1].isin(previousPlayPositives)\n",
    "    | sample[QPlayed2].isin(previousPlayPositives)\n",
    "    | sample[QPlayed3].isin(previousPlayPositives)\n",
    "    | sample[QPlayed4].isin(previousPlayPositives)\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isGFormAfter(surveyAnswerIndex, _gform):\n",
    "    return (len(getGFormAfters(_gform.loc[surveyAnswerIndex:surveyAnswerIndex, :])) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns an element of answerTemporalities\n",
    "#  previousPlayPositives is defined in '../Static data/English localization.ipynb'\n",
    "def getGFormRowGFormTemporality(_gformRow):\n",
    "    if (_gformRow[QPlayed1] in previousPlayPositives)\\\n",
    "        or (_gformRow[QPlayed2] in previousPlayPositives)\\\n",
    "        or (_gformRow[QPlayed3] in previousPlayPositives)\\\n",
    "        or (_gformRow[QPlayed4] in previousPlayPositives):\n",
    "        return answerTemporalities[1]\n",
    "    else:\n",
    "        return answerTemporalities[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users who answered both before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSurveysOfUsersWhoAnsweredBoth(sample, gfMode = True, rmMode = False):\n",
    "    befores = sample\n",
    "    afters = sample\n",
    "\n",
    "    if gfMode:\n",
    "        befores = getGFormBefores(befores)\n",
    "        afters = getGFormAfters(afters)\n",
    "\n",
    "    if rmMode:\n",
    "        befores = getRMBefores(befores)\n",
    "        afters = getRMAfters(afters)\n",
    "\n",
    "    return getIntersectionUsersSurveys(befores, afters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSurveysThatAnswered(sample, questionsAndPositiveAnswers, hardPolicy = True):\n",
    "    filterSeries = []\n",
    "    if hardPolicy:\n",
    "        filterSeries = pd.Series(True, sample.index)\n",
    "        for question, positiveAnswers in questionsAndPositiveAnswers:\n",
    "            filterSeries = filterSeries & (sample[question].isin(positiveAnswers))\n",
    "    else:\n",
    "        filterSeries = pd.Series(False, range(len(sample.index)))\n",
    "        for question, positiveAnswers in questionsAndPositiveAnswers:\n",
    "            filterSeries = filterSeries | (sample[question].isin(positiveAnswers))\n",
    "    return sample[filterSeries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surveys of people who have studied biology, and/or know about synthetic biology, and/or about BioBricks\n",
    "def getSurveysOfBiologists(sample, hardPolicy = True):\n",
    "    Q6BioEdu = 'How long have you studied biology?' #biologyStudyPositives\n",
    "    #irrelevant QInterest 'Are you interested in biology?' #biologyInterestPositives\n",
    "    Q8SynBio = 'Before playing Hero.Coli, had you ever heard about synthetic biology?' #yesNoIdontknowPositives\n",
    "    Q9BioBricks = 'Before playing Hero.Coli, had you ever heard about BioBricks?' #yesNoIdontknowPositives\n",
    "\n",
    "    questionsAndPositiveAnswers = [[Q6BioEdu, biologyStudyPositives],\n",
    "                               [Q8SynBio, yesNoIdontknowPositives],\n",
    "                               [Q9BioBricks, yesNoIdontknowPositives]]\n",
    "    \n",
    "    return getSurveysThatAnswered(sample, questionsAndPositiveAnswers, hardPolicy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surveys of people who play video games and/or are interested in them\n",
    "def getSurveysOfGamers(sample, hardPolicy = True):\n",
    "    Q2Interest = 'Are you interested in video games?' #interestPositives\n",
    "    Q3Play = 'Do you play video games?' #frequencyPositives\n",
    "\n",
    "    questionsAndPositiveAnswers = [[Q2Interest, interestPositives], [Q3Play, frequencyPositives]]\n",
    "    \n",
    "    return getSurveysThatAnswered(sample, questionsAndPositiveAnswers, hardPolicy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSurveysWithMatchingAnswers(sample, _gformRow, strictList, extendedList = [], hardPolicy = False):\n",
    "    questions = strictList\n",
    "\n",
    "    if (hardPolicy):\n",
    "        questions += extendedList\n",
    "\n",
    "    questionsAndPositiveAnswers = []\n",
    "    for q in questions:\n",
    "        questionsAndPositiveAnswers.append([q, [_gformRow[q]]])\n",
    "\n",
    "    return getSurveysThatAnswered(sample, questionsAndPositiveAnswers, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatchingDemographics(sample, _gformRow, hardPolicy = False):\n",
    "    # age and gender\n",
    "    Q4 = 'How old are you?'\n",
    "    Q5 = 'What is your gender?'\n",
    "\n",
    "    # interests, hobbies, and knowledge - evaluation may vary after playing\n",
    "    Q2Interest = 'Are you interested in video games?'\n",
    "    Q3Play = 'Do you play video games?'\n",
    "    Q6BioEdu = 'How long have you studied biology?'\n",
    "    Q7BioInterest = 'Are you interested in biology?'\n",
    "    Q8SynBio = 'Before playing Hero.Coli, had you ever heard about synthetic biology?'\n",
    "    Q9BioBricks = 'Before playing Hero.Coli, had you ever heard about BioBricks?'\n",
    "\n",
    "    # language may vary: players may have missed the opportunity to set it, or may want to try and change it\n",
    "    Q42 = 'Language'\n",
    "\n",
    "    return getSurveysWithMatchingAnswers(\n",
    "    sample, \n",
    "    _gformRow, [Q4, Q5], \n",
    "    extendedList = [Q2Interest, Q3Play, Q6BioEdu, Q8SynBio, Q9BioBricks, Q42], \n",
    "    hardPolicy = hardPolicy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions to sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDemographicSamples(rootSample):\n",
    "    samples = [\n",
    "                [rootSample, 'root sample'],\n",
    "                [rootSample[rootSample['Language'] == 'en'], 'English'],\n",
    "                [rootSample[rootSample['Language'] == 'fr'], 'French'],\n",
    "                [rootSample[rootSample['What is your gender?'] == 'Female'], 'female'],\n",
    "                [rootSample[rootSample['What is your gender?'] == 'Male'], 'male'],\n",
    "                [getSurveysOfBiologists(rootSample), 'biologists - strict'],\n",
    "                [getSurveysOfBiologists(rootSample, False), 'biologists - broad'],\n",
    "                [getSurveysOfGamers(rootSample), 'gamers - strict'],\n",
    "                [getSurveysOfGamers(rootSample, False), 'gamers - broad'],\n",
    "            ]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTemporalitySamples(rootSample):\n",
    "    samples = [\n",
    "                [rootSample, 'root sample'],\n",
    "        \n",
    "                [getRMBefores(rootSample), 'RedMetrics befores'],\n",
    "                [getGFormBefores(rootSample), 'Google form befores'],\n",
    "                [getRMBefores(getGFormBefores(rootSample)), 'GF & RedMetrics befores'],\n",
    "        \n",
    "                [getRMAfters(rootSample), 'RedMetrics afters'],\n",
    "                [getGFormAfters(rootSample), 'Google form afters'],\n",
    "                [getRMAfters(getGFormAfters(rootSample)), 'GF & RedMetrics afters'],\n",
    "        \n",
    "                [getSurveysOfUsersWhoAnsweredBoth(rootSample, gfMode = True, rmMode = False), 'GF both before and after'],\n",
    "                [getSurveysOfUsersWhoAnsweredBoth(rootSample, gfMode = False, rmMode = True), 'RM both before and after'],\n",
    "                [getSurveysOfUsersWhoAnsweredBoth(rootSample, gfMode = True, rmMode = True), 'GF & RM both before and after'],\n",
    "            ]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checkpoint validation\n",
    "<a id=checkvalidation />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that returns the list of checkpoints from user id\n",
    "def getValidatedCheckpoints( userId, _form = gform ):\n",
    "    _validatedCheckpoints = []\n",
    "    \n",
    "    if hasAnswered( userId, _form = _form ):\n",
    "        _columnAnswers = getCorrections( userId, _form = _form)\n",
    "        \n",
    "        for _columnName in _columnAnswers.columns:\n",
    "            # only work on corrected columns\n",
    "            if correctionsColumnNameStem in _columnName:        \n",
    "                _questionnaireValidatedCheckpointsPerQuestion = pd.Series(np.nan, index=range(len(checkpointQuestionMatching)))\n",
    "\n",
    "                for _index in range(0, len(_questionnaireValidatedCheckpointsPerQuestion)):\n",
    "                    if _columnAnswers[_columnName][_index]==True:\n",
    "                        _questionnaireValidatedCheckpointsPerQuestion[_index] = checkpointQuestionMatching['checkpoint'][_index]\n",
    "                    else:\n",
    "                        _questionnaireValidatedCheckpointsPerQuestion[_index] = ''\n",
    "\n",
    "                _questionnaireValidatedCheckpoints = _questionnaireValidatedCheckpointsPerQuestion.unique()\n",
    "                _questionnaireValidatedCheckpoints = _questionnaireValidatedCheckpoints[_questionnaireValidatedCheckpoints!='']\n",
    "                _questionnaireValidatedCheckpoints = pd.Series(_questionnaireValidatedCheckpoints)\n",
    "                _questionnaireValidatedCheckpoints = _questionnaireValidatedCheckpoints.sort_values()\n",
    "                _questionnaireValidatedCheckpoints.index = range(0, len(_questionnaireValidatedCheckpoints))\n",
    "                \n",
    "                _validatedCheckpoints.append(_questionnaireValidatedCheckpoints) \n",
    "    else:\n",
    "        print(\"user \" + str(userId) + \" has never answered\")\n",
    "    return pd.Series(_validatedCheckpoints)\n",
    "\n",
    "def getValidatedCheckpointsCounts( _userId, _form = gform ):\n",
    "    _validatedCheckpoints = getValidatedCheckpoints(_userId, _form = _form)\n",
    "    _counts = []\n",
    "    for checkpointsList in _validatedCheckpoints:\n",
    "        _counts.append(len(checkpointsList))\n",
    "    return _counts\n",
    "\n",
    "def getNonValidated( checkpoints ):\n",
    "    _validationLists = []\n",
    "    \n",
    "    if 0!=len(checkpoints):\n",
    "        for _validation in checkpoints:\n",
    "            _result = pd.Series(np.setdiff1d(validableCheckpoints.values, _validation.values))\n",
    "            _result = _result[_result != '']\n",
    "            _result.index = range(0, len(_result))\n",
    "            _validationLists.append(_result)\n",
    "        return pd.Series(_validationLists)\n",
    "    else:\n",
    "        return validableCheckpoints\n",
    "\n",
    "def getNonValidatedCheckpoints( userId, _form = gform ):\n",
    "    validated = getValidatedCheckpoints( userId, _form = _form )\n",
    "    return getNonValidated(validated)\n",
    "\n",
    "def getNonValidatedCheckpointsCounts( userId, _form = gform ):\n",
    "    _nonValidatedCheckpoints = getNonValidatedCheckpoints(userId, _form = _form)\n",
    "    _counts = []\n",
    "    for checkpointsList in _nonValidatedCheckpoints:\n",
    "        _counts.append(len(checkpointsList))\n",
    "    return _counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p(answered question N | answered question P)\n",
    "<a id=condproba />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns all rows of Google form's answers that contain an element \n",
    "#   of the array 'choice' for question number 'questionIndex'\n",
    "def getAllAnswerRows(questionIndex, choice, _form = gform ):\n",
    "    return _form[_form.iloc[:, questionIndex].isin(choice)]\n",
    "\n",
    "def getPercentCorrectPerColumn(_df):\n",
    "    _count = len(_df)\n",
    "    _percents = pd.Series(np.full(len(_df.columns), np.nan), index=_df.columns)\n",
    "    for _rowIndex in _df.index:\n",
    "        for _columnName in _df.columns:\n",
    "            _columnIndex = _df.columns.get_loc(_columnName)\n",
    "            if ((_columnIndex >= firstEvaluationQuestionIndex) \\\n",
    "                and (_columnIndex < len(_df.columns)-3)):\n",
    "                if(str(_df[_columnName][_rowIndex]).startswith(str(correctAnswers[_columnIndex]))):\n",
    "                    if (np.isnan(_percents[_columnName])):\n",
    "                        _percents[_columnName] = 1;\n",
    "                    else:\n",
    "                        _percents[_columnName] = _percents[_columnName]+1\n",
    "                else:\n",
    "                    if (np.isnan(_percents[_columnName])):\n",
    "                        _percents[_columnName] = 0;\n",
    "                \n",
    "    _percents = _percents/_count\n",
    "    _percents['Count'] = _count\n",
    "    return _percents\n",
    "\n",
    "def getPercentCorrectKnowingAnswer(questionIndex, choice, _form = gform):\n",
    "    _answerRows = getAllAnswerRows(questionIndex, choice, _form = _form);\n",
    "    return getPercentCorrectPerColumn(_answerRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering users\n",
    "<a id=filteringusers />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTestAnswers( _form = gform, _rmDF = rmdf1522, _rmTestDF = normalizedRMDFTest, includeAndroid = True):\n",
    "    return _form[_form[localplayerguidkey].isin(testUsers.values.flatten())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization of gform\n",
    "<a id=gforminit />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setAnswerTemporalities()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
