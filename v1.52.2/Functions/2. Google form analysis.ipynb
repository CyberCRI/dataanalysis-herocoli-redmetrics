{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google form analysis\n",
    "\n",
    "Analysis of results extracted from Google forms in csv format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "\n",
    "[Preparation](#preparation)\n",
    "\n",
    "[Constants](#constants)\n",
    "\n",
    "[Functions](#functions)\n",
    "   \n",
    "   - [general purpose](#genpurpose)\n",
    "   \n",
    "   - [sessions and temporalities](#sessions)\n",
    "   \n",
    "   - [score](#score)\n",
    "   \n",
    "   - [visualizations](#visualizations)\n",
    "   \n",
    "   - [sample getters](#samples)\n",
    "   \n",
    "   - [checkpoint validation](#checkvalidation)\n",
    "   \n",
    "   - [p(answered question N | answered question P)](#condproba)\n",
    "   \n",
    "   - [Filtering users](#filteringusers)\n",
    "   \n",
    "[Initialization of gform](#gforminit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "<a id=preparation />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run \"../Functions/1. Game sessions.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants\n",
    "<a id=constants />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special user ids\n",
    "# 1.52\n",
    "userIdThatDidNotAnswer = '001c95c6-8207-43dc-a51b-adf0c6e005d7'\n",
    "\n",
    "userId1AnswerEN = '00dbbdca-d86c-4bc9-803c-0602e0153f68'\n",
    "userIdAnswersEN = '5977184a-1be2-4725-9b48-f2782dc03efb'\n",
    "userId1ScoreEN = '6b5d392d-b737-49ef-99af-e8c445ff6379'\n",
    "userIdScoresEN = '5ecf601d-4eac-433e-8056-3a5b9eda0555'\n",
    "\n",
    "userId1AnswerFR = '2734a37d-4ba5-454f-bf85-1f7b767138f6'\n",
    "userIdAnswersFR = '01e85778-2903-447b-bbab-dd750564ee2d'\n",
    "userId1ScoreFR = '3d733347-0313-441a-b77c-3e4046042a53'\n",
    "userIdScoresFR = '58d22690-8604-41cf-a5b7-d71fb3b9ad5b'\n",
    "\n",
    "userIdAnswersENFR = 'a7936587-8b71-43b6-9c61-17b2c2b55de3'\n",
    "\n",
    "# 1.52.2\n",
    "userIdThatDidNotAnswer = '6919aa9a-f18e-4fc5-8435-c26b869ba571'\n",
    "userIdAnswersFR = '0135e29b-678d-4188-a935-1d0bfec9450b'\n",
    "userIdScoresFR = '0135e29b-678d-4188-a935-1d0bfec9450b'\n",
    "userId1AnswerFR = '01cc303e-d7c1-4c84-8e17-182b410da343'\n",
    "userId1ScoreFR = '01cc303e-d7c1-4c84-8e17-182b410da343'\n",
    "userId1AnswerEN = '027fb5ca-c40a-4977-852a-e448538061f2'\n",
    "userId1ScoreEN = '027fb5ca-c40a-4977-852a-e448538061f2'\n",
    "userIdAnswersEN = '1e94b693-df8f-4ad0-9f02-4aac6929bdaa'\n",
    "userIdScoresEN = '1e94b693-df8f-4ad0-9f02-4aac6929bdaa'\n",
    "userIdAnswersENFR = '2ad10897-b143-45f4-9a78-60ee4bcecc80'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#localplayerguidkey = 'Ne pas modifier - identifiant anonyme pr√©rempli'\n",
    "localplayerguidkey = 'userId'\n",
    "localplayerguidindex = gform.columns.get_loc(localplayerguidkey)\n",
    "localplayerguidindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstEvaluationQuestionKey = QGenotypePhenotype\n",
    "firstEvaluationQuestionIndex = gform.columns.get_loc(firstEvaluationQuestionKey)\n",
    "firstEvaluationQuestionIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answersColumnNameStem = \"answers\"\n",
    "correctionsColumnNameStem = \"corrections\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "<a id=functions />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general purpose\n",
    "<a id=genpurpose />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUniqueUserCount(sample):\n",
    "    return sample[localplayerguidkey].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllResponders( _form = gform ):\n",
    "    userIds = _form[localplayerguidkey].unique()\n",
    "    return userIds\n",
    "\n",
    "def getRandomGFormGUID():\n",
    "    _uniqueUsers = getAllResponders()\n",
    "    _userCount = len(_uniqueUsers)\n",
    "    _guid = '0'\n",
    "    while (not isGUIDFormat(_guid)):\n",
    "        _userIndex = randint(0,_userCount-1)\n",
    "        _guid = _uniqueUsers[_userIndex]\n",
    "    return _guid\n",
    "\n",
    "def hasAnswered( userId, _form = gform ):\n",
    "    return userId in _form[localplayerguidkey].values\n",
    "\n",
    "def getAnswers( userId, _form = gform ):\n",
    "    answers = _form[_form[localplayerguidkey]==userId]\n",
    "    _columnAnswers = answers.T\n",
    "    \n",
    "    if 0 != len(answers):\n",
    "        _newColumns = []\n",
    "        for column in _columnAnswers.columns:\n",
    "            _newColumns.append(answersColumnNameStem + str(column))\n",
    "        _columnAnswers.columns = _newColumns\n",
    "    else:\n",
    "        # user has never answered\n",
    "        print(\"user \" + str(userId) + \" has never answered\")\n",
    "        \n",
    "    return _columnAnswers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sessions and temporalities\n",
    "<a id=sessions />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetTemporalities(_gformDF = gform):\n",
    "    _gformDF[QTemporality] = answerTemporalities[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gform[QPlayed].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers that show that this survey was a pretest\n",
    "alreadyPlayedPretestAnswers = [\n",
    "    'No / not yet', \n",
    "#    'I just played for the first time',\n",
    "    'I played it some time ago', # certainly an older version of the game\n",
    "#    'I played it multiple times recently',\n",
    "#    'I played recently on an other computer', # has to fill in profile questions again\n",
    "#    'I played it multiple times recently on this computer'\n",
    "]\n",
    "\n",
    "alreadyPlayedPosttestAnswers = [\n",
    "#    'No / not yet', \n",
    "    'I just played for the first time',\n",
    "#    'I played it some time ago',\n",
    "    'I played it multiple times recently',\n",
    "    'I played recently on an other computer',\n",
    "    'I played it multiple times recently on this computer'\n",
    "]\n",
    "\n",
    "# based only on user answer\n",
    "APlayedButProfileAgain = 'I played recently on an other computer'\n",
    "\n",
    "def setAnswerTemporalitiesSimple( _gformDF = gform ):\n",
    "    # check whether temporalities have already been set\n",
    "    if(len(_gformDF[QTemporality].unique()) == 1):\n",
    "        for _index in _gformDF.index:\n",
    "            if _gformDF.loc[_index, QPlayed] in alreadyPlayedPretestAnswers:\n",
    "                _gformDF.loc[_index,QTemporality] = answerTemporalities[0]\n",
    "            else:\n",
    "                _gformDF.loc[_index,QTemporality] = answerTemporalities[1]\n",
    "        print(\"temporalities set (user answer method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based only on first meaningful game event\n",
    "def setAnswerTemporalities( _gformDF = gform ):\n",
    "    # check whether temporalities have already been set\n",
    "    if(len(_gformDF[QTemporality].unique()) == 1):\n",
    "        # format : key = _userId, value = [_firstEventDate, 0 or _gformDF.index of before, 0 or _gformDF.index of after]\n",
    "        temporalities = {}\n",
    "\n",
    "        for _index in _gformDF.index:\n",
    "            _userId = _gformDF.loc[_index,localplayerguidkey]\n",
    "            _firstEventDate, beforeIndex, afterIndex = [0,0,0]\n",
    "\n",
    "            if _userId in temporalities:\n",
    "                _firstEventDate, beforeIndex, afterIndex = temporalities[_userId]\n",
    "            else:\n",
    "                _firstEventDate = getFirstEventDate(_userId)\n",
    "\n",
    "            temporality = getTemporality(_gformDF.loc[_index,QTimestamp],_firstEventDate)\n",
    "\n",
    "            if temporality == answerTemporalities[0] and beforeIndex != 0 :\n",
    "                if _gformDF.loc[_index,QTimestamp] > _gformDF.loc[beforeIndex,QTimestamp]:\n",
    "                    _gformDF.loc[beforeIndex,QTemporality] = answerTemporalities[2]\n",
    "                else:\n",
    "                    temporality = answerTemporalities[2]\n",
    "            elif temporality == answerTemporalities[1] and afterIndex != 0 :\n",
    "                if _gformDF.loc[_index,QTimestamp] < _gformDF.loc[afterIndex,QTimestamp]:\n",
    "                    _gformDF.loc[afterIndex,QTemporality] = answerTemporalities[2]\n",
    "                else:\n",
    "                    temporality = answerTemporalities[2]\n",
    "\n",
    "            _gformDF.loc[_index,QTemporality] = temporality\n",
    "            if temporality == answerTemporalities[0]:\n",
    "                beforeIndex = _index\n",
    "            elif temporality == answerTemporalities[1]:\n",
    "                afterIndex = _index\n",
    "\n",
    "            temporalities[_userId] = [_firstEventDate, beforeIndex, afterIndex]\n",
    "        print(\"temporalities set (first event method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when did the user answer the questionnaire? \n",
    "# After gameEventDate, before gameEventDate, undefined?\n",
    "# answerDate is assumed to be the gform Timestamp, UTC\n",
    "# gameEventDate is assumed to be of type pandas._libs.tslib.Timestamp, UTC, from RedMetrics\n",
    "def getTemporality( answerDate, gameEventDate ):\n",
    "    result = answerTemporalities[2]\n",
    "    if(gameEventDate != pd.Timestamp.max.tz_localize('utc')):\n",
    "        if(answerDate <= gameEventDate):\n",
    "            result = answerTemporalities[0]\n",
    "        elif (answerDate > gameEventDate):\n",
    "            result = answerTemporalities[1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be based on events on a 24h window\n",
    "def setAnswerTemporalities2( _gformDF = gform, _rmDF = rmdf1522 ):\n",
    "    # check whether temporalities have already been set\n",
    "    if(len(_gformDF[QTemporality].unique()) == 1):\n",
    "        # format : key = _userId, value = [pretestBeforeRatio, posttestAfterRatio, 0 or pretestIndex, 0 or posttestIndex]\n",
    "        temporalities = {}\n",
    "\n",
    "        for _index in _gformDF.index:\n",
    "            _userId = _gformDF.loc[_index,localplayerguidkey]\n",
    "            pretestBeforeRatio, posttestAfterRatio, pretestIndex, posttestIndex = [1.0, 1.0, 0, 0]\n",
    "\n",
    "            answerDate = _gformDF.loc[_index,QTimestamp]\n",
    "            [eventsBeforeRatio, eventsAfterRatio] = getEventCountRatios(answerDate, _userId, _rmDF, _gformDF)\n",
    "            \n",
    "            if _userId in temporalities:\n",
    "                pretestBeforeRatio, posttestAfterRatio, pretestIndex, posttestIndex = temporalities[_userId]\n",
    "                \n",
    "            if ((eventsBeforeRatio == eventsAfterRatio) and (0 != eventsBeforeRatio)):\n",
    "                print(\"anomaly for userId=\" + _userId + \": eventsBeforeRatio == eventsAfterRatio != 0\")\n",
    "                \n",
    "            # update posttest if there are less events afterwards?\n",
    "            # keep the oldest anyways?\n",
    "            if (posttestIndex == 0) and (eventsBeforeRatio >= eventsAfterRatio) and (0 != eventsBeforeRatio):\n",
    "            # improvement idea:\n",
    "            #if (eventsBeforeRatio > eventsAfterRatio) :\n",
    "            #    if (posttestIndex == 0) or (_gformDF.loc[posttestIndex,localplayerguidkey]):\n",
    "            # if _gformDF.loc[_index,QTimestamp] > _gformDF.loc[beforeIndex,QTimestamp]:\n",
    "            # if _gformDF.loc[_index,QTimestamp] < _gformDF.loc[afterIndex,QTimestamp]:\n",
    "                posttestAfterRatio = eventsAfterRatio\n",
    "                posttestIndex = _index\n",
    "                _gformDF.loc[_index,QTemporality] = answerTemporalities[1]\n",
    "            # update pretest if there are more events before?\n",
    "            # keep the oldest anyways?\n",
    "            elif (pretestIndex == 0) and (eventsBeforeRatio <= eventsAfterRatio) and (0 != eventsAfterRatio):\n",
    "                pretestBeforeRatio = eventsBeforeRatio\n",
    "                pretestIndex = _index\n",
    "                _gformDF.loc[_index,QTemporality] = answerTemporalities[0]\n",
    "\n",
    "            temporalities[_userId] = [pretestBeforeRatio, posttestAfterRatio, pretestIndex, posttestIndex]\n",
    "        print(\"temporalities set (ratio method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEventCountRatios(answerDate, userId, _rmDF = rmdf1522, _gformDF = gform):\n",
    "    result = [0,0]\n",
    "    allEvents = _rmDF[_rmDF['userId']==userId]\n",
    "    allEventsCount = len(allEvents)\n",
    "    if 0 != allEventsCount:\n",
    "        eventsBeforeRatio = len(allEvents[allEvents['userTime'] < answerDate])/allEventsCount\n",
    "        eventsAfterRatio = len(allEvents[allEvents['userTime'] > answerDate])/allEventsCount\n",
    "        result = [eventsBeforeRatio, eventsAfterRatio]\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score\n",
    "<a id=score />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorrections( _userId, _source = correctAnswers, _form = gform, _columnAnswers = [] ):\n",
    "    if(len(_columnAnswers) == 0):\n",
    "        _columnAnswers = getAnswers( _userId, _form = _form )\n",
    "\n",
    "    if 0 != len(_columnAnswers.columns):\n",
    "\n",
    "        _questionsCount = len(_columnAnswers.values)\n",
    "\n",
    "        for _columnName in _columnAnswers.columns:\n",
    "            if answersColumnNameStem in _columnName:\n",
    "                _answerNumber = _columnName.replace(answersColumnNameStem,\"\")\n",
    "                newCorrectionsColumnName = correctionsColumnNameStem + _answerNumber\n",
    "\n",
    "                #_columnAnswers[newCorrectionsColumnName] = _columnAnswers[_columnName]\n",
    "                _columnAnswers[newCorrectionsColumnName] = pd.Series(np.full(_questionsCount, np.nan))\n",
    "\n",
    "                for question in _columnAnswers[_columnName].index:\n",
    "                    _correctAnswers = _source.loc[question]\n",
    "                    \n",
    "                    if(len(_correctAnswers) > 0):\n",
    "                        _columnAnswers.loc[question,newCorrectionsColumnName] = False\n",
    "                        for _correctAnswer in _correctAnswers:\n",
    "                            if str(_columnAnswers.loc[question,_columnName])\\\n",
    "                            .startswith(str(_correctAnswer)):\n",
    "                                _columnAnswers.loc[question,newCorrectionsColumnName] = True\n",
    "                                break\n",
    "                        \n",
    "\n",
    "    else:\n",
    "        # user has never answered\n",
    "        print(\"can't give correct answers\")\n",
    "    return _columnAnswers\n",
    "    \n",
    "\n",
    "# edits in-place\n",
    "# _corrections must be a dataframe full of corrections as produced above\n",
    "def getBinarizedCorrections( _corrections ):\n",
    "    for _columnName in _corrections.columns:\n",
    "        for _index in _corrections[_columnName].index:\n",
    "            if(True==_corrections.loc[_index,_columnName]):\n",
    "                _corrections.loc[_index,_columnName] = 1.0\n",
    "            elif (False==_corrections.loc[_index,_columnName]):\n",
    "                _corrections.loc[_index,_columnName] = 0.0\n",
    "    return _corrections\n",
    "\n",
    "# only for one line in the gform\n",
    "def getBinarized(_gformLine, _source = correctAnswers):\n",
    "    _notEmptyIndexes = []\n",
    "    for _index in _source.index:\n",
    "        if(len(_source.loc[_index]) > 0):\n",
    "            _notEmptyIndexes.append(_index)\n",
    "\n",
    "    _binarized = pd.Series(np.full(len(_gformLine.index), np.nan), index = _gformLine.index)\n",
    "\n",
    "    for question in _gformLine.index:\n",
    "        _correctAnswers = _source.loc[question]\n",
    "\n",
    "        if(len(_correctAnswers) > 0):\n",
    "            _binarized[question] = 0\n",
    "            for _correctAnswer in _correctAnswers:\n",
    "                if str(_gformLine.loc[question])\\\n",
    "                .startswith(str(_correctAnswer)):\n",
    "                    _binarized.loc[question] = 1\n",
    "                    break\n",
    "\n",
    "    _slicedBinarized = _binarized.loc[_notEmptyIndexes]\n",
    "    return _slicedBinarized\n",
    "\n",
    "def getAllBinarized(_source = correctAnswers, _form = gform ):\n",
    "    _notEmptyIndexes = []\n",
    "    for _index in _source.index:\n",
    "        if(len(_source.loc[_index]) > 0):\n",
    "            _notEmptyIndexes.append(_index)\n",
    "\n",
    "    _result = pd.DataFrame(index = _notEmptyIndexes)\n",
    "    for _userId in getAllResponders( _form = _form ):\n",
    "        _corrections = getCorrections(_userId, _source=_source, _form = _form)\n",
    "        _binarized = getBinarizedCorrections(_corrections)\n",
    "        _slicedBinarized =\\\n",
    "    _binarized.loc[_notEmptyIndexes][_binarized.columns[\\\n",
    "    _binarized.columns.to_series().str.contains(correctionsColumnNameStem)\\\n",
    "                                       ]]\n",
    "\n",
    "        _result = pd.concat([_result, _slicedBinarized], axis=1)\n",
    "\n",
    "    _result = _result.T\n",
    "        \n",
    "    return _result\n",
    "    \n",
    "\n",
    "# CCA.iloc[i,j] is the number of users who correctly answered questions number i and j\n",
    "# CCA[i,j] = Sum(A[u,i] * A[u,j], u in users) = Sum(tA[i,u] * A[u,j], u in users) = tA.A[i,j]\n",
    "# CCA[i,j] is an int\n",
    "def getCrossCorrectAnswers( _binarizedAnswers ):\n",
    "    return _binarizedAnswers.T.dot(_binarizedAnswers)\n",
    "\n",
    "#function that returns the score from user id\n",
    "scoreLabel = 'score'\n",
    "def getScore( _userId, _form = gform, _source = correctAnswers ):\n",
    "    _score = pd.DataFrame({}, columns = answerTemporalities)\n",
    "    _score.loc[scoreLabel,:] = np.nan\n",
    "    for _column in _score.columns:\n",
    "        _score.loc[scoreLabel, _column] = []\n",
    "\n",
    "    if hasAnswered( _userId, _form = _form ):\n",
    "        _columnAnswers = getCorrections(_userId, _form = _form, _source = _source)\n",
    "        for _columnName in _columnAnswers.columns:\n",
    "            # only work on corrected columns\n",
    "            if correctionsColumnNameStem in _columnName:\n",
    "                _answerColumnName = _columnName.replace(correctionsColumnNameStem,\\\n",
    "                                                      answersColumnNameStem)\n",
    "                _temporality = _columnAnswers.loc[QTemporality,_answerColumnName]\n",
    "\n",
    "                _counts = (_columnAnswers[_columnName]).value_counts()\n",
    "                _thisScore = 0\n",
    "                if(True in _counts):\n",
    "                    _thisScore = _counts[True]\n",
    "                _score.loc[scoreLabel,_temporality].append(_thisScore)\n",
    "    else:\n",
    "        print(\"user \" + str(_userId) + \" has never answered\")\n",
    "\n",
    "    return _score\n",
    "\n",
    "\n",
    "def getGFormRowCorrection( _gformRow, _source = correctAnswers):\n",
    "    result = _gformRow.copy()\n",
    "\n",
    "    if(len(_gformRow) == 0):\n",
    "        print(\"this gform row is empty\")\n",
    "\n",
    "    else:\n",
    "        result = pd.Series(index = _gformRow.index, data = np.full(len(_gformRow), np.nan))\n",
    "\n",
    "        for question in result.index:\n",
    "            _correctAnswers = _source.loc[question]\n",
    "\n",
    "            if(len(_correctAnswers) > 0):\n",
    "                result.loc[question] = False\n",
    "                for _correctAnswer in _correctAnswers:\n",
    "                    if str(_gformRow.loc[question]).startswith(str(_correctAnswer)):\n",
    "                        result.loc[question] = True\n",
    "                        break\n",
    "    return result\n",
    "\n",
    "def getGFormRowScore( _gformRow, _source = correctAnswers):\n",
    "    correction = getGFormRowCorrection( _gformRow, _source = _source)\n",
    "    _counts = correction.value_counts()\n",
    "    _thisScore = 0\n",
    "    if(True in _counts):\n",
    "        _thisScore = _counts[True]\n",
    "    return _thisScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualizations\n",
    "<a id=visualizations />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createStatSet(series, ids = pd.Series()):\n",
    "    if(0 == len(ids)):\n",
    "        ids = series.index\n",
    "    result = {\n",
    "        'count' : len(ids),\n",
    "        'unique' : len(ids.unique()),\n",
    "        'median' : series.median(),\n",
    "        'mean' : series.mean(),\n",
    "        'std' : series.std(),\n",
    "    }\n",
    "    return result\n",
    "\n",
    "# _binarized must be well-formed, similarly to getAllBinarized's output\n",
    "def getPercentagePerQuestion(_binarized):\n",
    "    totalPerQuestionDF = pd.DataFrame(data=np.dot(np.ones(_binarized.shape[0]), _binarized), index=_binarized.columns)\n",
    "    percentagePerQuestion = totalPerQuestionDF*100 / _binarized.shape[0]\n",
    "    return percentagePerQuestion\n",
    "\n",
    "## sample can be: all, those who answered both before and after,\n",
    "## those who played between date1 and date2, ...\n",
    "from scipy.stats import ttest_ind\n",
    "def plotBasicStats(\n",
    "    sample,\n",
    "    title = '',\n",
    "    includeAll = False,\n",
    "    includeBefore = True,\n",
    "    includeAfter = True,\n",
    "    includeUndefined = False,\n",
    "    includeProgress = True,\n",
    "    includeRelativeProgress = False,\n",
    "    horizontalPlot = True,\n",
    "    sortedAlong = '', # in [\"pretest\", \"posttest\", \"progression\"]\n",
    "    figsize=(20,4)\n",
    "):\n",
    "    \n",
    "    stepsPerInclude = 2\n",
    "    includeCount = np.sum([includeAll, includeBefore, includeAfter, includeUndefined, includeProgress])\n",
    "    stepsCount = stepsPerInclude*includeCount + 3\n",
    "    \n",
    "    #print(\"stepsPerInclude=\" + str(stepsPerInclude))\n",
    "    #print(\"includeCount=\" + str(includeCount))\n",
    "    #print(\"stepsCount=\" + str(stepsCount))\n",
    "    \n",
    "    __progress = FloatProgress(min=0, max=stepsCount)\n",
    "    display(__progress)\n",
    "    \n",
    "    sampleBefore = sample[sample[QTemporality] == answerTemporalities[0]]\n",
    "    sampleAfter = sample[sample[QTemporality] == answerTemporalities[1]]\n",
    "    sampleUndefined = sample[sample[QTemporality] == answerTemporalities[2]]\n",
    "\n",
    "    #uniqueBefore = sampleBefore[localplayerguidkey]\n",
    "    #uniqueAfter = \n",
    "    #uniqueUndefined =\n",
    "\n",
    "    scientificQuestions = correctAnswers.copy()\n",
    "    allQuestions = correctAnswers + demographicAnswers\n",
    "    \n",
    "    categories = ['all', answerTemporalities[0], answerTemporalities[1], answerTemporalities[2],\\\n",
    "                  'progress', 'rel. progress']\n",
    "    data = {}\n",
    "    \n",
    "    sciBinarized = pd.DataFrame()\n",
    "    allBinarized = pd.DataFrame()\n",
    "    scoresAll = pd.DataFrame()\n",
    "    \n",
    "    sciBinarizedBefore = pd.DataFrame()\n",
    "    allBinarizedBefore = pd.DataFrame()\n",
    "    scoresBefore = pd.DataFrame()\n",
    "    \n",
    "    sciBinarizedAfter = pd.DataFrame()\n",
    "    allBinarizedAfter = pd.DataFrame()\n",
    "    scoresAfter = pd.DataFrame()\n",
    "    \n",
    "    sciBinarizedUndefined = pd.DataFrame()\n",
    "    allBinarizedUndefined = pd.DataFrame()\n",
    "    scoresUndefined = pd.DataFrame()\n",
    "\n",
    "    scoresProgress = pd.DataFrame()\n",
    "\n",
    "    ## basic stats:\n",
    "    ### mean score\n",
    "    ### median score\n",
    "    ### std\n",
    "    if includeAll:\n",
    "        sciBinarized = getAllBinarized( _source = scientificQuestions, _form = sample)\n",
    "        __progress.value += 1\n",
    "        allBinarized = getAllBinarized( _source = allQuestions, _form = sample)\n",
    "        __progress.value += 1\n",
    "        scoresAll = pd.Series(np.dot(sciBinarized, np.ones(sciBinarized.shape[1])))\n",
    "        \n",
    "        data[categories[0]] = createStatSet(scoresAll, sample[localplayerguidkey])\n",
    "        \n",
    "    if includeBefore or includeProgress:\n",
    "        sciBinarizedBefore = getAllBinarized( _source = scientificQuestions, _form = sampleBefore)\n",
    "        __progress.value += 1\n",
    "        allBinarizedBefore = getAllBinarized( _source = allQuestions, _form = sampleBefore)\n",
    "        __progress.value += 1\n",
    "        scoresBefore = pd.Series(np.dot(sciBinarizedBefore, np.ones(sciBinarizedBefore.shape[1])))\n",
    "        temporaryStatSetBefore = createStatSet(scoresBefore, sampleBefore[localplayerguidkey])\n",
    "    if includeBefore:\n",
    "        data[categories[1]] = temporaryStatSetBefore\n",
    "        \n",
    "    if includeAfter or includeProgress:\n",
    "        sciBinarizedAfter = getAllBinarized( _source = scientificQuestions, _form = sampleAfter)\n",
    "        __progress.value += 1\n",
    "        allBinarizedAfter = getAllBinarized( _source = allQuestions, _form = sampleAfter)\n",
    "        __progress.value += 1\n",
    "        scoresAfter = pd.Series(np.dot(sciBinarizedAfter, np.ones(sciBinarizedAfter.shape[1])))\n",
    "        temporaryStatSetAfter = createStatSet(scoresAfter, sampleAfter[localplayerguidkey])\n",
    "    if includeAfter:\n",
    "        data[categories[2]] = temporaryStatSetAfter\n",
    "        \n",
    "    if includeUndefined:\n",
    "        sciBinarizedUndefined = getAllBinarized( _source = scientificQuestions, _form = sampleUndefined)\n",
    "        __progress.value += 1\n",
    "        allBinarizedUndefined = getAllBinarized( _source = allQuestions, _form = sampleUndefined)\n",
    "        __progress.value += 1\n",
    "        scoresUndefined = pd.Series(np.dot(sciBinarizedUndefined, np.ones(sciBinarizedUndefined.shape[1])))\n",
    "        \n",
    "        data[categories[3]] = createStatSet(scoresUndefined, sampleUndefined[localplayerguidkey])\n",
    "\n",
    "    if includeProgress:\n",
    "        data[categories[4]] = {\n",
    "            'count' : min(temporaryStatSetAfter['count'], temporaryStatSetBefore['count']),\n",
    "            'unique' : min(temporaryStatSetAfter['unique'], temporaryStatSetBefore['unique']),\n",
    "            'median' : temporaryStatSetAfter['median']-temporaryStatSetBefore['median'],\n",
    "            'mean' : temporaryStatSetAfter['mean']-temporaryStatSetBefore['mean'],\n",
    "            'std' : temporaryStatSetAfter['std']-temporaryStatSetBefore['std'],\n",
    "        }\n",
    "        __progress.value += 2\n",
    "    \n",
    "    \n",
    "    result = pd.DataFrame(data)\n",
    "    __progress.value += 1\n",
    "\n",
    "    print(title)\n",
    "    print(result)\n",
    "    if (includeBefore and includeAfter) or includeProgress:\n",
    "        if (len(scoresBefore) > 2 and len(scoresAfter) > 2):\n",
    "            ttest = ttest_ind(scoresBefore, scoresAfter)\n",
    "            print(\"t test: statistic=\" + repr(ttest.statistic) + \" pvalue=\" + repr(ttest.pvalue))\n",
    "    print()\n",
    "\n",
    "    ## percentage correct\n",
    "    ### percentage correct - max 5 columns\n",
    "    percentagePerQuestionAll = pd.DataFrame()\n",
    "    percentagePerQuestionBefore = pd.DataFrame()\n",
    "    percentagePerQuestionAfter = pd.DataFrame()\n",
    "    percentagePerQuestionUndefined = pd.DataFrame()\n",
    "    percentagePerQuestionProgress = pd.DataFrame()\n",
    "    \n",
    "    tables = []\n",
    "\n",
    "    if includeAll:\n",
    "        percentagePerQuestionAll = getPercentagePerQuestion(allBinarized)\n",
    "        tables.append([percentagePerQuestionAll, categories[0]])\n",
    "        \n",
    "    if includeBefore or includeProgress:\n",
    "        percentagePerQuestionBefore = getPercentagePerQuestion(allBinarizedBefore)\n",
    "    if includeBefore:\n",
    "        tables.append([percentagePerQuestionBefore, categories[1]])\n",
    "        \n",
    "    if includeAfter or includeProgress:\n",
    "        percentagePerQuestionAfter = getPercentagePerQuestion(allBinarizedAfter)\n",
    "    if includeAfter:\n",
    "        tables.append([percentagePerQuestionAfter, categories[2]])\n",
    "        \n",
    "    if includeUndefined:\n",
    "        percentagePerQuestionUndefined = getPercentagePerQuestion(allBinarizedUndefined)\n",
    "        tables.append([percentagePerQuestionUndefined, categories[3]])\n",
    "        \n",
    "    if includeProgress or includeRelativeProgress:\n",
    "        percentagePerQuestionProgress = percentagePerQuestionAfter - percentagePerQuestionBefore\n",
    "        \n",
    "        if includeProgress:\n",
    "            tables.append([percentagePerQuestionProgress, categories[4]])\n",
    "            \n",
    "        if includeRelativeProgress:\n",
    "            # use temporaryStatSetAfter['count'], temporaryStatSetBefore['count']?\n",
    "            percentagePerQuestionProgress2 = percentagePerQuestionProgress.copy()\n",
    "            for index in range(0,len(percentagePerQuestionProgress.index)):\n",
    "                if (0 == percentagePerQuestionBefore.iloc[index,0]):\n",
    "                    percentagePerQuestionProgress2.iloc[index,0] = 0\n",
    "                else:\n",
    "                    percentagePerQuestionProgress2.iloc[index,0] = \\\n",
    "                    percentagePerQuestionProgress.iloc[index,0]/percentagePerQuestionBefore.iloc[index,0]\n",
    "            tables.append([percentagePerQuestionProgress2, categories[5]])\n",
    "    \n",
    "    __progress.value += 1\n",
    "\n",
    "    graphTitle = '% correct: '\n",
    "    toConcat = []\n",
    "    \n",
    "    for table,category in tables:\n",
    "        concat = (len(table.values) > 0)\n",
    "        for elt in table.iloc[:,0].values:\n",
    "            if np.isnan(elt):\n",
    "                concat = False\n",
    "                break\n",
    "        if(concat):\n",
    "            graphTitle = graphTitle + category + ' '\n",
    "            toConcat.append(table)\n",
    "\n",
    "    if (len(toConcat) > 0):\n",
    "        percentagePerQuestionConcatenated = pd.concat(\n",
    "            toConcat\n",
    "            , axis=1)\n",
    "\n",
    "        if(len(title) > 0):\n",
    "            graphTitle = graphTitle + ' - ' + title\n",
    "\n",
    "        _fig = plt.figure(figsize=figsize)\n",
    "        _ax1 = plt.subplot(111)\n",
    "        _ax1.set_title(graphTitle)\n",
    "        matrixToDisplay = percentagePerQuestionConcatenated.round().astype(int)\n",
    "        \n",
    "        if horizontalPlot:\n",
    "            matrixToDisplay.columns = [\"pretest\", \"posttest\", \"progression\"]\n",
    "            if sortedAlong in matrixToDisplay.columns:\n",
    "                scientificQuestions = correctAnswers[correctAnswers.apply(len) > 0].index\n",
    "                demographicQuestions = demographicAnswers[demographicAnswers.apply(len) > 0].index\n",
    "                sciSorted = matrixToDisplay.loc[scientificQuestions, :].sort_values(by = \"progression\", ascending = True)\n",
    "                demoSorted = matrixToDisplay.loc[demographicQuestions, :].sort_values(by = \"progression\", ascending = True)\n",
    "                matrixToDisplay = pd.concat([sciSorted, demoSorted])\n",
    "            matrixToDisplay = matrixToDisplay.T\n",
    "            \n",
    "        sns.heatmap(matrixToDisplay\n",
    "                    ,ax=_ax1,cmap=plt.cm.jet,square=True,annot=True,fmt='d')\n",
    "        \n",
    "        #if horizontalPlot:\n",
    "        # both fail\n",
    "        #heatmap.set_xticklabels(_ax1.get_xticklabels(),rotation=45)\n",
    "        #plt.xticks(rotation=45)\n",
    "        \n",
    "    __progress.value += 1\n",
    "    \n",
    "    ### percentage cross correct\n",
    "    ### percentage cross correct, conditionnally\n",
    "    \n",
    "    if(__progress.value != stepsCount):\n",
    "        print(\"__progress.value=\" + str(__progress.value) + \" != stepsCount=\" + str(stepsCount))\n",
    "\n",
    "#    return sciBinarized, sciBinarizedBefore, sciBinarizedAfter, sciBinarizedUndefined, \\\n",
    "#           allBinarized, allBinarizedBefore, allBinarizedAfter, allBinarizedUndefined\n",
    "    return matrixToDisplay\n",
    "\n",
    "    \n",
    "    \n",
    "def plotCorrelationMatrices(\n",
    "    allBinarized = [],\n",
    "    beforeBinarized = [],\n",
    "    afterBinarized = [],\n",
    "    undefinedBinarized = [],\n",
    "    titleAll = 'Correlation of pre- & post-test answers',\n",
    "    titleBefore = 'Correlation of pre-test answers',\n",
    "    titleAfter = 'Correlation of post-test answers',\n",
    "    titleUndefined = 'Correlation of undefined answers',\n",
    "    titleSuffix = '',\n",
    "):\n",
    "    dataBinarized = [allBinarized, beforeBinarized, afterBinarized, undefinedBinarized]\n",
    "    titles = [titleAll + titleSuffix, titleBefore + titleSuffix, titleAfter + titleSuffix, titleUndefined + titleSuffix]\n",
    "    \n",
    "    for index in range(0, len(dataBinarized)):\n",
    "        if(len(dataBinarized[index]) > 0):\n",
    "            plotCorrelationMatrix(\n",
    "                dataBinarized[index],\n",
    "                _abs=True,\n",
    "                _clustered=False,\n",
    "                _questionNumbers=True,\n",
    "                _annot = True,\n",
    "                _figsize = (20,20),\n",
    "                _title=titles[index],\n",
    "            )\n",
    "    \n",
    "##correlation\n",
    "### simple heatmap\n",
    "### clustermap\n",
    "methods = ['pearson', 'kendall', 'spearman']\n",
    "def plotCorrelationMatrix( \n",
    "    _binarizedMatrix, \n",
    "    _method = methods[0], \n",
    "    _title='Questions\\' Correlations', \n",
    "    _abs=False, \n",
    "    _clustered=False, \n",
    "    _questionNumbers=False,\n",
    "    _annot = False,\n",
    "    _figsize = (10,10),\n",
    "    _metric='euclidean'\n",
    "):\n",
    "    \n",
    "    _progress = FloatProgress(min=0, max=7)\n",
    "    display(_progress)\n",
    "    \n",
    "    _overlay = False\n",
    "\n",
    "    _progress.value += 1\n",
    "    \n",
    "    # computation of correlation matrix\n",
    "    _m = _method\n",
    "    if(not (_method in methods)):\n",
    "        _m = methods[0]\n",
    "    _correlation = _binarizedMatrix.astype(float).corr(_m)\n",
    "    _progress.value += 1\n",
    "    if(_abs):\n",
    "        _correlation = _correlation.abs()\n",
    "    _progress.value += 1\n",
    "    \n",
    "    if(_clustered):\n",
    "    # removing NaNs\n",
    "    # can't cluster NaN lines in _correlation\n",
    "        _notNaNsIndices = []\n",
    "        _notNaNsColumns = []\n",
    "        for index in _correlation.index:\n",
    "            #if(pd.notnull(_correlation.loc[index,:]).all()): # if no element is nan\n",
    "            if(~pd.isnull(_correlation.loc[index,:]).all()): # if at least one element is not nan\n",
    "                _notNaNsIndices.append(index)\n",
    "        #for column in _correlation.columns:\n",
    "        #    if(~np.isnan(_correlation.loc[:,column]).all()):\n",
    "        #        _notNaNsColumns.append(column)\n",
    "        \n",
    "        _binarizedMatrix = _binarizedMatrix.loc[:,_notNaNsIndices]\n",
    "        _correlation = _correlation.loc[_notNaNsIndices,_notNaNsIndices]\n",
    "    _progress.value += 1\n",
    "        \n",
    "        \n",
    "    # optional computation of overlay\n",
    "    if(_annot):\n",
    "        _overlay = getCrossCorrectAnswers(_binarizedMatrix).astype(int)\n",
    "    _progress.value += 1\n",
    "    \n",
    "    # preparation of plot labels\n",
    "    if(_questionNumbers):\n",
    "        _correlation.columns = pd.Series(_correlation.columns).apply(\\\n",
    "                lambda x: x + ' #' + str(_correlation.columns.get_loc(x) + 1))\n",
    "        if(_clustered):\n",
    "            _correlation.index = pd.Series(_correlation.columns).apply(\\\n",
    "                lambda x: '#' + str(_correlation.columns.get_loc(x) + 1) + ' ' + x)\n",
    "        else:\n",
    "            _correlation.index = _correlation.columns\n",
    "    _progress.value += 1\n",
    "    \n",
    "    # plot\n",
    "    if(_clustered):\n",
    "        result = sns.clustermap(\\\n",
    "            _correlation,\\\n",
    "            metric=_metric,\\\n",
    "            cmap=plt.cm.jet,\\\n",
    "            square=True,\\\n",
    "            figsize=_figsize,\\\n",
    "            annot=_overlay,\\\n",
    "            fmt='d')\n",
    "        return result, _overlay\n",
    "    \n",
    "#        if(_annot):\n",
    "            # reorder columns using clustergrid.dendrogram_col.reordered_ind\n",
    "\n",
    "            #_overlay1 = _overlay.copy()            \n",
    "\n",
    "#            reorderedCols = result.dendrogram_col.reordered_ind\n",
    "#            _overlay = _overlay\n",
    "\n",
    "            #_overlay2 = _overlay.copy().iloc[reorderedCols,reorderedCols]\n",
    "\n",
    "#            result = sns.clustermap(_correlation,metric=_metric,cmap=plt.cm.jet,square=True,figsize=_figsize,annot=_overlay, fmt='d')\n",
    "            \n",
    "            #print(_overlay1.columns == _overlay2.columns)\n",
    "            #print(_overlay1 == _overlay2)\n",
    "\n",
    "            #print(_overlay1.columns)\n",
    "            #print(_overlay1.columns)\n",
    "            #print(_overlay1)\n",
    "            #print(_overlay2)\n",
    "            \n",
    "            #return _overlay1, _overlay2\n",
    "#            return result, _overlay\n",
    "            \n",
    "    else:\n",
    "        _fig = plt.figure(figsize=_figsize)\n",
    "        _ax = plt.subplot(111)\n",
    "        _ax.set_title(_title)\n",
    "        sns.heatmap(_correlation,ax=_ax,cmap=plt.cm.jet,square=True,annot=_overlay, fmt='d')\n",
    "    _progress.value += 1\n",
    "    \n",
    "#def plotAll():\n",
    "    # loop on question types\n",
    "    # loop on temporalities\n",
    "    # loop on representations\n",
    "    ## basic stats:\n",
    "    ### mean score\n",
    "    ### median score\n",
    "    ### std\n",
    "    ## percentage correct\n",
    "    ### percentage correct - 3 columns\n",
    "    ### percentage cross correct\n",
    "    ### percentage cross correct, conditionnally\n",
    "    ##correlation\n",
    "    ### simple heatmap\n",
    "#    plotCorrelationMatrix\n",
    "    ### clustermap\n",
    "#    plotCorrelationMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plotSamples(samples):\n",
    "    _progress = FloatProgress(min=0, max=len(samples))\n",
    "    display(_progress)\n",
    "\n",
    "    for sample, title in samples:\n",
    "        plotBasicStats(sample, title)\n",
    "        _progress.value += 1\n",
    "\n",
    "    if(_progress.value != len(samples)):\n",
    "        print(\"__progress.value=\" + str(__progress.value) + \" != len(samples)=\" + str(len(samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for per-gform, manual analysis\n",
    "def getGFormDataPreview(_GFUserId, sample):\n",
    "    gforms = gform[gform[localplayerguidkey] == _GFUserId]\n",
    "    result = {}\n",
    "    \n",
    "    for _ilocIndex in range(0, len(gforms)):\n",
    "        gformsIndex = gforms.index[_ilocIndex]\n",
    "        currentGForm = gforms.iloc[_ilocIndex]\n",
    "\n",
    "        subresult = {}\n",
    "        subresult['date'] = currentGForm[QTimestamp]\n",
    "        subresult['temporality RM'] = currentGForm[QTemporality]\n",
    "        subresult['temporality GF'] = getGFormRowGFormTemporality(currentGForm)\n",
    "        subresult['score'] = getGFormRowScore(currentGForm)\n",
    "        subresult['genderAge'] = [currentGForm[QGender], currentGForm[QAge]]\n",
    "\n",
    "        # search for other users with similar demographics\n",
    "        matchingDemographics = getMatchingDemographics(sample, currentGForm)\n",
    "        matchingDemographicsIds = []\n",
    "        #print(type(matchingDemographics))\n",
    "        #print(matchingDemographics.index)\n",
    "        for matchesIndex in matchingDemographics.index:\n",
    "            matchingDemographicsIds.append([matchesIndex, matchingDemographics.loc[matchesIndex, localplayerguidkey]])\n",
    "\n",
    "        subresult['demographic matches'] = matchingDemographicsIds\n",
    "\n",
    "        result['survey' + str(_ilocIndex)] = subresult\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample getters\n",
    "<a id=samples />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices do not need to be reset as they all come from gform\n",
    "def getUnionQuestionnaires(sample1, sample2):\n",
    "    if (not (sample1.columns == sample2.columns).all()):\n",
    "        print(\"warning: parameter columns are not the same\")\n",
    "    return pd.concat([sample1, sample2]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices do not need to be reset as they all come from gform\n",
    "def getIntersectionQuestionnaires(sample1, sample2):\n",
    "    if (not (sample1.columns == sample2.columns).all()):\n",
    "        print(\"warning: parameter columns are not the same\")\n",
    "    return pd.merge(sample1, sample2, how = 'inner').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample1 and sample2 rows where users are common to sample1 and sample2\n",
    "def getIntersectionUsersSurveys(sample1, sample2):\n",
    "    result1 = sample1[sample1[localplayerguidkey].isin(sample2[localplayerguidkey])]\n",
    "    result2 = sample2[sample2[localplayerguidkey].isin(sample1[localplayerguidkey])]\n",
    "    return getUnionQuestionnaires(result1,result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users who answered either before or after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gform[QPlayed].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRMBefores(sample):\n",
    "    return sample[sample[QTemporality] == answerTemporalities[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRMAfters(sample):\n",
    "    return sample[sample[QTemporality] == answerTemporalities[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns users who declared that they have never played the game, whatever platform\n",
    "#  everPlayedPositives is defined in \"../Functions/0.1 GF English localization.ipynb\"\n",
    "def getGFormBefores(sample):\n",
    "    return sample[\n",
    "      ~sample[QPlayed].isin(everPlayedPositives)\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isGFormBefore(surveyAnswerIndex, _gform):\n",
    "    return (len(getGFormBefores(_gform.loc[surveyAnswerIndex:surveyAnswerIndex, :])) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns users who declared that they have already played the game, whatever platform\n",
    "#  everPlayedPositives is defined in \"../Functions/0.1 GF English localization.ipynb\"\n",
    "def getGFormAfters(sample):\n",
    "    return sample[\n",
    "      sample[QPlayed].isin(everPlayedPositives)\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isGFormAfter(surveyAnswerIndex, _gform):\n",
    "    return (len(getGFormAfters(_gform.loc[surveyAnswerIndex:surveyAnswerIndex, :])) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns an element of answerTemporalities\n",
    "#  everPlayedPositives is defined in '../Static data/English localization.ipynb'\n",
    "def getGFormRowGFormTemporality(_gformRow):\n",
    "    if (_gformRow[QPlayed] in everPlayedPositives):\n",
    "        return answerTemporalities[1]\n",
    "    else:\n",
    "        return answerTemporalities[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users who answered both before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSurveysOfUsersWhoAnsweredBoth(sample, gfMode = True, rmMode = False):\n",
    "    befores = sample\n",
    "    afters = sample\n",
    "\n",
    "    if gfMode:\n",
    "        befores = getGFormBefores(befores)\n",
    "        afters = getGFormAfters(afters)\n",
    "\n",
    "    if rmMode:\n",
    "        befores = getRMBefores(befores)\n",
    "        afters = getRMAfters(afters)\n",
    "\n",
    "    return getIntersectionUsersSurveys(befores, afters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSurveysThatAnswered(sample, questionsAndPositiveAnswers, hardPolicy = True):\n",
    "    filterSeries = []\n",
    "    if hardPolicy:\n",
    "        filterSeries = pd.Series(True, sample.index)\n",
    "        for question, positiveAnswers in questionsAndPositiveAnswers:\n",
    "            filterSeries = filterSeries & (sample[question].isin(positiveAnswers))\n",
    "    else:\n",
    "        filterSeries = pd.Series(False, range(len(sample.index)))\n",
    "        for question, positiveAnswers in questionsAndPositiveAnswers:\n",
    "            filterSeries = filterSeries | (sample[question].isin(positiveAnswers))\n",
    "    return sample[filterSeries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surveys of people who have studied biology, and/or know about synthetic biology, and/or about BioBricks\n",
    "def getSurveysOfBiologists(sample, hardPolicy = True):\n",
    "    #QStudiedBiology biologyStudyPositives\n",
    "    #irrelevant QInterestBiology biologyInterestPositives\n",
    "    #QHeardSynBioOrBioBricks heardAboutBioBricksPositives\n",
    "\n",
    "    questionsAndPositiveAnswers = [[QStudiedBiology, biologyStudyPositives],\n",
    "                               [QHeardSynBioOrBioBricks, heardAboutBioBricksPositives]]\n",
    "    \n",
    "    return getSurveysThatAnswered(sample, questionsAndPositiveAnswers, hardPolicy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surveys of people who play video games and/or are interested in them\n",
    "def getSurveysOfGamers(sample, hardPolicy = True):\n",
    "    #QInterestVideoGames interestPositives\n",
    "    #QPlayVideoGames frequencyPositives\n",
    "\n",
    "    questionsAndPositiveAnswers = [[QInterestVideoGames, interestPositives], [QPlayVideoGames, frequencyPositives]]\n",
    "    \n",
    "    return getSurveysThatAnswered(sample, questionsAndPositiveAnswers, hardPolicy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSurveysWithMatchingAnswers(sample, _gformRow, strictList, extendedList = [], hardPolicy = False):\n",
    "    questions = strictList\n",
    "\n",
    "    if (hardPolicy):\n",
    "        questions += extendedList\n",
    "\n",
    "    questionsAndPositiveAnswers = []\n",
    "    for q in questions:\n",
    "        questionsAndPositiveAnswers.append([q, [_gformRow[q]]])\n",
    "\n",
    "    return getSurveysThatAnswered(sample, questionsAndPositiveAnswers, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QAge\n",
    "#QGender\n",
    "\n",
    "def getMatchingDemographics(sample, _gformRow, hardPolicy = False):\n",
    "    # age and gender, edu should not change\n",
    "    #QGender\n",
    "    #QAge\n",
    "    #QStudiedBiology\n",
    "\n",
    "    # interests, hobbies, and knowledge - evaluation may vary after playing\n",
    "    #QInterestVideoGames\n",
    "    #QPlayVideoGames\n",
    "    #QInterestBiology\n",
    "    #QHeardSynBioOrBioBricks heardAboutBioBricksPositives\n",
    "\n",
    "    # language may vary: players may have missed the opportunity to set it, or may want to try and change it\n",
    "    #QLanguage\n",
    "\n",
    "    return getSurveysWithMatchingAnswers(\n",
    "    sample, \n",
    "    _gformRow, [QAge, QGender, QStudiedBiology], \n",
    "    extendedList = [QInterestVideoGames, QPlayVideoGames, QInterestBiology, QHeardSynBioOrBioBricks, QLanguage], \n",
    "    hardPolicy = hardPolicy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions to sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDemographicSamples(rootSample):\n",
    "    samples = [\n",
    "                [rootSample, 'root sample'],\n",
    "                [rootSample[rootSample[QLanguage] == enLanguageID], 'English'],\n",
    "                [rootSample[rootSample[QLanguage] == frLanguageID], 'French'],\n",
    "                [rootSample[rootSample[QGender] == 'Female'], 'female'],\n",
    "                [rootSample[rootSample[QGender] == 'Male'], 'male'],\n",
    "                [getSurveysOfBiologists(rootSample), 'biologists - strict'],\n",
    "                [getSurveysOfBiologists(rootSample, False), 'biologists - broad'],\n",
    "                [getSurveysOfGamers(rootSample), 'gamers - strict'],\n",
    "                [getSurveysOfGamers(rootSample, False), 'gamers - broad'],\n",
    "            ]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTemporalitySamples(rootSample):\n",
    "    samples = [\n",
    "                [rootSample, 'root sample'],\n",
    "        \n",
    "                [getRMBefores(rootSample), 'RedMetrics befores'],\n",
    "                [getGFormBefores(rootSample), 'Google form befores'],\n",
    "                [getRMBefores(getGFormBefores(rootSample)), 'GF & RedMetrics befores'],\n",
    "        \n",
    "                [getRMAfters(rootSample), 'RedMetrics afters'],\n",
    "                [getGFormAfters(rootSample), 'Google form afters'],\n",
    "                [getRMAfters(getGFormAfters(rootSample)), 'GF & RedMetrics afters'],\n",
    "        \n",
    "                [getSurveysOfUsersWhoAnsweredBoth(rootSample, gfMode = True, rmMode = False), 'GF both before and after'],\n",
    "                [getSurveysOfUsersWhoAnsweredBoth(rootSample, gfMode = False, rmMode = True), 'RM both before and after'],\n",
    "                [getSurveysOfUsersWhoAnsweredBoth(rootSample, gfMode = True, rmMode = True), 'GF & RM both before and after'],\n",
    "            ]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checkpoint validation\n",
    "<a id=checkvalidation />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that returns the list of checkpoints from user id\n",
    "def getValidatedCheckpoints( userId, _form = gform ):\n",
    "    _validatedCheckpoints = []\n",
    "    \n",
    "    if hasAnswered( userId, _form = _form ):\n",
    "        _columnAnswers = getCorrections( userId, _form = _form)\n",
    "        \n",
    "        for _columnName in _columnAnswers.columns:\n",
    "            # only work on corrected columns\n",
    "            if correctionsColumnNameStem in _columnName:        \n",
    "                _questionnaireValidatedCheckpointsPerQuestion = pd.Series(np.nan, index=range(len(checkpointQuestionMatching)))\n",
    "\n",
    "                for _index in range(0, len(_questionnaireValidatedCheckpointsPerQuestion)):\n",
    "                    if _columnAnswers[_columnName][_index]==True:\n",
    "                        _questionnaireValidatedCheckpointsPerQuestion[_index] = checkpointQuestionMatching['checkpoint'][_index]\n",
    "                    else:\n",
    "                        _questionnaireValidatedCheckpointsPerQuestion[_index] = ''\n",
    "\n",
    "                _questionnaireValidatedCheckpoints = _questionnaireValidatedCheckpointsPerQuestion.unique()\n",
    "                _questionnaireValidatedCheckpoints = _questionnaireValidatedCheckpoints[_questionnaireValidatedCheckpoints!='']\n",
    "                _questionnaireValidatedCheckpoints = pd.Series(_questionnaireValidatedCheckpoints)\n",
    "                _questionnaireValidatedCheckpoints = _questionnaireValidatedCheckpoints.sort_values()\n",
    "                _questionnaireValidatedCheckpoints.index = range(0, len(_questionnaireValidatedCheckpoints))\n",
    "                \n",
    "                _validatedCheckpoints.append(_questionnaireValidatedCheckpoints) \n",
    "    else:\n",
    "        print(\"user \" + str(userId) + \" has never answered\")\n",
    "    return pd.Series(_validatedCheckpoints)\n",
    "\n",
    "def getValidatedCheckpointsCounts( _userId, _form = gform ):\n",
    "    _validatedCheckpoints = getValidatedCheckpoints(_userId, _form = _form)\n",
    "    _counts = []\n",
    "    for checkpointsList in _validatedCheckpoints:\n",
    "        _counts.append(len(checkpointsList))\n",
    "    return _counts\n",
    "\n",
    "def getNonValidated( checkpoints ):\n",
    "    _validationLists = []\n",
    "    \n",
    "    if 0!=len(checkpoints):\n",
    "        for _validation in checkpoints:\n",
    "            _result = pd.Series(np.setdiff1d(validableCheckpoints.values, _validation.values))\n",
    "            _result = _result[_result != '']\n",
    "            _result.index = range(0, len(_result))\n",
    "            _validationLists.append(_result)\n",
    "        return pd.Series(_validationLists)\n",
    "    else:\n",
    "        return validableCheckpoints\n",
    "\n",
    "def getNonValidatedCheckpoints( userId, _form = gform ):\n",
    "    validated = getValidatedCheckpoints( userId, _form = _form )\n",
    "    return getNonValidated(validated)\n",
    "\n",
    "def getNonValidatedCheckpointsCounts( userId, _form = gform ):\n",
    "    _nonValidatedCheckpoints = getNonValidatedCheckpoints(userId, _form = _form)\n",
    "    _counts = []\n",
    "    for checkpointsList in _nonValidatedCheckpoints:\n",
    "        _counts.append(len(checkpointsList))\n",
    "    return _counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p(answered question N | answered question P)\n",
    "<a id=condproba />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns all rows of Google form's answers that contain an element \n",
    "#   of the array 'choice' for question number 'questionIndex'\n",
    "def getAllAnswerRows(questionIndex, choice, _form = gform ):\n",
    "    return _form[_form.iloc[:, questionIndex].isin(choice)]\n",
    "\n",
    "def getPercentCorrectPerColumn(_df):\n",
    "    _count = len(_df)\n",
    "    _percents = pd.Series(np.full(len(_df.columns), np.nan), index=_df.columns)\n",
    "    for _rowIndex in _df.index:\n",
    "        for _columnName in _df.columns:\n",
    "            _columnIndex = _df.columns.get_loc(_columnName)\n",
    "            if ((_columnIndex >= firstEvaluationQuestionIndex) \\\n",
    "                and (_columnIndex < len(_df.columns)-3)):\n",
    "                if(str(_df[_columnName][_rowIndex]).startswith(str(correctAnswers[_columnIndex]))):\n",
    "                    if (np.isnan(_percents[_columnName])):\n",
    "                        _percents[_columnName] = 1;\n",
    "                    else:\n",
    "                        _percents[_columnName] = _percents[_columnName]+1\n",
    "                else:\n",
    "                    if (np.isnan(_percents[_columnName])):\n",
    "                        _percents[_columnName] = 0;\n",
    "                \n",
    "    _percents = _percents/_count\n",
    "    _percents['Count'] = _count\n",
    "    return _percents\n",
    "\n",
    "def getPercentCorrectKnowingAnswer(questionIndex, choice, _form = gform):\n",
    "    _answerRows = getAllAnswerRows(questionIndex, choice, _form = _form);\n",
    "    return getPercentCorrectPerColumn(_answerRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering users\n",
    "<a id=filteringusers />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTestAnswers( _form = gform, _rmDF = rmdf1522, _rmTestDF = normalizedRMDFTest, includeAndroid = True):\n",
    "    return _form[_form[localplayerguidkey].isin(testUsers.values.flatten())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ambiguous answer to QPlayed\n",
    "AUnclassifiable = 'I played recently on an other computer'\n",
    "\n",
    "# fill posttests with pretest data\n",
    "def setPosttestsProfileInfo( _gformDF = gform ):\n",
    "    # check whether temporalities have already been set\n",
    "    if(len(_gformDF[QTemporality].unique()) == 1):\n",
    "        print(\"temporalities not set\")\n",
    "    else:\n",
    "\n",
    "        intProgress = IntProgress(min=0, max=len(gform.index))\n",
    "        display(intProgress)\n",
    "\n",
    "        #_gformDF[_gformDF[QTemporality] == answerTemporalities[1]][QAge]\n",
    "\n",
    "        for _index in _gformDF.index:\n",
    "            intProgress.value += 1\n",
    "            if ((_gformDF.loc[_index, QTemporality] == answerTemporalities[0])\n",
    "                    or\n",
    "                    (_gformDF.loc[_index, QTemporality] == answerTemporalities[1]\n",
    "                        and\n",
    "                     _gformDF.loc[_index, QPlayed] == AUnclassifiable\n",
    "                    )\n",
    "               ):\n",
    "                if pd.isnull(_gformDF.loc[_index, survey1522DF[profileColumn]]).any():\n",
    "                    print(\"nan for index \" + str(_index))\n",
    "                else:\n",
    "                    # fix on age loading\n",
    "                    _gformDF.loc[_index, QAge] = int(_gformDF.loc[_index, QAge])\n",
    "\n",
    "                thisUserIdsPostests = _gformDF.loc[\n",
    "                        (_gformDF['userId'] == _gformDF.loc[_index, 'userId'])\n",
    "                        &\n",
    "                        (_gformDF[QTemporality] == answerTemporalities[1])\n",
    "                ]\n",
    "\n",
    "                if(len(thisUserIdsPostests) > 0):\n",
    "                    _gformDF.loc[\n",
    "                        (_gformDF['userId'] == _gformDF.loc[_index, 'userId'])\n",
    "                        &\n",
    "                        (_gformDF[QTemporality] == answerTemporalities[1])\n",
    "                        ,survey1522DF[profileColumn]] = _gformDF.loc[_index, survey1522DF[profileColumn]].values\n",
    "\n",
    "        print(\"profile info set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastAddedColumn = 'lastAdded'\n",
    "profileColumn = 'profile'\n",
    "commonColumn = 'common'\n",
    "compulsoryPretestColumn = 'compulsoryPretest'\n",
    "optionalPretestColumn = 'optionalPretest'\n",
    "compulsoryPosttestColumn = 'compulsoryPosttest'\n",
    "\n",
    "#QVolunteer\n",
    "QContent = QBioBricksDevicesComposition\n",
    "#QRemarks\n",
    "\n",
    "def getQuestionTypes():\n",
    "\n",
    "    intProgress = IntProgress(min=0, max=2*len(gform.index))\n",
    "    display(intProgress)\n",
    "    \n",
    "    survey1522DF = pd.DataFrame(index = gform.columns, data = False,\n",
    "                            columns = [lastAddedColumn, commonColumn, compulsoryPretestColumn,compulsoryPosttestColumn])\n",
    "    \n",
    "    pretestQuestions = pd.Index([])\n",
    "    pretestNotVolunteeredQuestions = pd.Index([])\n",
    "    posttestQuestions = pd.Index([])\n",
    "    lastAddedQuestions = pd.Index([])\n",
    "\n",
    "    for answerIndex in gform.index:\n",
    "        intProgress.value += 1\n",
    "        answer = gform.iloc[answerIndex,:]\n",
    "        \n",
    "        if gform.loc[answerIndex, QTemporality] == answerTemporalities[0]:\n",
    "            # has volunteered?\n",
    "            if gform.loc[answerIndex, QVolunteer] in yesNoPositives:\n",
    "                pretestQuestions = pretestQuestions.union(answer[pd.notnull(answer[:])].index)\n",
    "            else:\n",
    "                pretestNotVolunteeredQuestions = pretestNotVolunteeredQuestions.union(answer[pd.notnull(answer[:])].index)\n",
    "\n",
    "        elif gform.loc[answerIndex, QPlayed] != APlayedButProfileAgain:\n",
    "            posttestQuestions = posttestQuestions.union(answer[pd.notnull(answer[:])].index)\n",
    "\n",
    "    \n",
    "    survey1522DF[compulsoryPretestColumn] = survey1522DF.index.isin(pretestNotVolunteeredQuestions)\n",
    "    survey1522DF[optionalPretestColumn] = survey1522DF.index.isin(pretestQuestions.difference(pretestNotVolunteeredQuestions))\n",
    "    survey1522DF[compulsoryPosttestColumn] = survey1522DF.index.isin(posttestQuestions)\n",
    "    survey1522DF[commonColumn] = (survey1522DF[compulsoryPretestColumn] & survey1522DF[compulsoryPosttestColumn])\n",
    "    \n",
    "    for answerIndex in gform.index:\n",
    "        intProgress.value += 1\n",
    "        answer = gform.iloc[answerIndex,:]\n",
    "        \n",
    "        if gform.loc[answerIndex, QTemporality] == answerTemporalities[0]:\n",
    "            # has volunteered?\n",
    "            if gform.loc[answerIndex, QVolunteer] in yesNoPositives:\n",
    "                lastAddedQuestions = lastAddedQuestions.union(answer[pretestQuestions][pd.isnull(answer[pretestQuestions])].index)\n",
    "            else:\n",
    "                lastAddedQuestions = lastAddedQuestions.union(answer[pretestNotVolunteeredQuestions][pd.isnull(answer[pretestNotVolunteeredQuestions])].index)\n",
    "        elif not pd.isnull(gform.loc[answerIndex, QContent]):\n",
    "            lastAddedQuestions = lastAddedQuestions.union(answer[posttestQuestions][pd.isnull(answer[posttestQuestions])].index)\n",
    "\n",
    "    survey1522DF[lastAddedColumn] = survey1522DF.index.isin(lastAddedQuestions)\n",
    "    # manual override\n",
    "    survey1522DF.loc[QRemarks] = False\n",
    "            \n",
    "    survey1522DF[profileColumn] = survey1522DF[compulsoryPretestColumn] & (~survey1522DF[compulsoryPosttestColumn])\n",
    "        \n",
    "    return survey1522DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove answers that are incomplete\n",
    "e.g. posttests with no content questions or pretests with no profile info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPosttestsWithoutPretests(_gformDF = gform):\n",
    "    pretestIds = _gformDF[_gformDF[QTemporality] == answerTemporalities[0]]['userId']\n",
    "    posttestIds = _gformDF[_gformDF[QTemporality] == answerTemporalities[1]]['userId']\n",
    "    return posttestIds[~posttestIds.isin(pretestIds)].index\n",
    "\n",
    "def getPretestsWithoutPosttests(_gformDF = gform):\n",
    "    pretestIds = _gformDF[_gformDF[QTemporality] == answerTemporalities[0]]['userId']\n",
    "    posttestIds = _gformDF[_gformDF[QTemporality] == answerTemporalities[1]]['userId']\n",
    "    return pretestIds[~pretestIds.isin(posttestIds)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWithoutIncompleteAnswers(_gformDF = gform):\n",
    "    \n",
    "    # remove incomplete profiles\n",
    "    #  coincidentally removes posttests that don't have matching pretests\n",
    "    _gformDF2 = _gformDF.drop(_gformDF.index[pd.isnull(_gformDF[_gformDF.columns[survey1522DF[profileColumn]]].T).any()])\n",
    "    \n",
    "    # defensive check    \n",
    "    _gformDF2 = _gformDF2.drop(getPosttestsWithoutPretests(_gformDF2))\n",
    "    \n",
    "    return _gformDF2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPerfectPretestPostestPairsCount(_gformDF = gform):\n",
    "    pairs = getPerfectPretestPostestPairs(_gformDF)\n",
    "    halfPairsCount = len(pairs)//2\n",
    "    uniqueUserIdsCount = len(pairs['userId'].unique())\n",
    "    if (halfPairsCount != uniqueUserIdsCount):\n",
    "        print('warning: halfPairsCount ('+str(halfPairsCount)+') != uniqueUserIdsCount ('+str(uniqueUserIdsCount)+')')\n",
    "    return uniqueUserIdsCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization of gform\n",
    "<a id=gforminit />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resetTemporalities()\n",
    "#setAnswerTemporalities()\n",
    "#setAnswerTemporalities2()\n",
    "setAnswerTemporalitiesSimple()\n",
    "survey1522DF = getQuestionTypes()\n",
    "setPosttestsProfileInfo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
