{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hero.Coli Data Analysis Summary\n",
    "\n",
    "Interactive list of readworthy results from Hero.Coli data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "[Preparation](#preparation)\n",
    "1. [Google form analysis](#sampledForm)\n",
    "2. [Game sessions](#sessions)\n",
    "3. [Per session and per user analysis](#peruser)\n",
    "4. [User comparison](#usercomp)\n",
    "5. [Game map](#map)\n",
    "    1. [List of questions](#qlist)\n",
    "    2. [English](#enform)\n",
    "    3. [French](#frform)\n",
    "    4. [Language selection](#langsel)\n",
    "3. [Basic operations](#basicops)\n",
    "4. [Checkpoint / Question matching](#checkquestmatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "<a id=preparation />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run \"../Functions/6. Time analysis.ipynb\"\n",
    "%run \"../Functions/Plot.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampledForm = samplePlaytestPretestPosttestUniqueProfilesVolunteersPhase1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmdf = rmdfPlaytestPretestPosttestUniqueProfilesVolunteersPhase1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Google form analysis\n",
    "<a id=sampledForm />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sample:               gform\")\n",
    "print(\"surveys:              %s\" % len(gform))\n",
    "print(\"unique users:         %s\" % getUniqueUserCount(gform))\n",
    "print(\"RM before:            %s\" % len(gform[gform[QTemporality] == answerTemporalities[0]]))\n",
    "print(\"GF before:            %s\" % len(getGFormBefores(gform)))\n",
    "print(\"RM after:             %s\" % len(gform[gform[QTemporality] == answerTemporalities[1]]))\n",
    "print(\"GF after:             %s\" % len(getGFormAfters(gform)))\n",
    "print(\"unique biologists:    %s\" % getUniqueUserCount(getSurveysOfBiologists(gform)))\n",
    "print(\"unique gamers:        %s\" % getUniqueUserCount(getSurveysOfGamers(gform)))\n",
    "print(\"unique perfect users: %s\" % getUniqueUserCount(getSurveysOfUsersWhoAnsweredBoth(gform)))\n",
    "print(\"unique perfect users: %s\" % getPerfectPretestPostestPairsCount(gform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sample:               sampledForm\")\n",
    "print(\"surveys:              %s\" % len(sampledForm))\n",
    "print(\"unique users:         %s\" % getUniqueUserCount(sampledForm))\n",
    "print(\"RM before:            %s\" % len(sampledForm[sampledForm[QTemporality] == answerTemporalities[0]]))\n",
    "print(\"GF before:            %s\" % len(getGFormBefores(sampledForm)))\n",
    "print(\"RM after:             %s\" % len(sampledForm[sampledForm[QTemporality] == answerTemporalities[1]]))\n",
    "print(\"GF after:             %s\" % len(getGFormAfters(sampledForm)))\n",
    "print(\"unique biologists:    %s\" % getUniqueUserCount(getSurveysOfBiologists(sampledForm)))\n",
    "print(\"unique gamers:        %s\" % getUniqueUserCount(getSurveysOfGamers(sampledForm)))\n",
    "print(\"unique perfect users: %s\" % getUniqueUserCount(getSurveysOfUsersWhoAnsweredBoth(sampledForm)))\n",
    "print(\"unique perfect users: %s\" % getPerfectPretestPostestPairsCount(sampledForm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### formatted version for nice display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"category | count\")\n",
    "print(\"--- | ---\")\n",
    "print(\"sample | gform\")\n",
    "print(\"surveys | %s\" % len(gform))\n",
    "print(\"unique users | %s\" % getUniqueUserCount(gform))\n",
    "print(\"RM before | %s\" % len(gform[gform[QTemporality] == answerTemporalities[0]]))\n",
    "print(\"GF before | %s\" % len(getGFormBefores(gform)))\n",
    "print(\"RM after | %s\" % len(gform[gform[QTemporality] == answerTemporalities[1]]))\n",
    "print(\"GF after | %s\" % len(getGFormAfters(gform)))\n",
    "print(\"unique biologists | %s\" % getUniqueUserCount(getSurveysOfBiologists(gform)))\n",
    "print(\"unique gamers | %s\" % getUniqueUserCount(getSurveysOfGamers(gform)))\n",
    "print(\"unique perfect users | %s\" % getUniqueUserCount(getSurveysOfUsersWhoAnsweredBoth(gform)))\n",
    "print(\"unique perfect users | %s\" % getPerfectPretestPostestPairsCount(gform))\n",
    "print()\n",
    "#print(\"(\" + str(pd.to_datetime('today').date()) + \")\")\n",
    "print(\"(\"+dataFilesNamesStem+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"category | count\")\n",
    "print(\"--- | ---\")\n",
    "print(\"sample | sampledForm\")\n",
    "print(\"surveys | %s\" % len(sampledForm))\n",
    "print(\"unique users | %s\" % getUniqueUserCount(sampledForm))\n",
    "print(\"RM before | %s\" % len(sampledForm[sampledForm[QTemporality] == answerTemporalities[0]]))\n",
    "print(\"GF before | %s\" % len(getGFormBefores(sampledForm)))\n",
    "print(\"RM after | %s\" % len(sampledForm[sampledForm[QTemporality] == answerTemporalities[1]]))\n",
    "print(\"GF after | %s\" % len(getGFormAfters(sampledForm)))\n",
    "print(\"unique biologists | %s\" % getUniqueUserCount(getSurveysOfBiologists(sampledForm)))\n",
    "print(\"unique gamers | %s\" % getUniqueUserCount(getSurveysOfGamers(sampledForm)))\n",
    "print(\"unique perfect users | %s\" % getUniqueUserCount(getSurveysOfUsersWhoAnsweredBoth(sampledForm)))\n",
    "print(\"unique perfect users | %s\" % getPerfectPretestPostestPairsCount(sampledForm))\n",
    "print()\n",
    "#print(\"(\" + str(pd.to_datetime('today').date()) + \")\")\n",
    "print(\"(\"+dataFilesNamesStem+\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 complete sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSamples(getDemographicSamples(sampledForm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(sampledForm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Per temporality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 answered only before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_befores = getGFormBefores(sampledForm)\n",
    "rm_befores = getRMBefores(sampledForm)\n",
    "gfrm_befores = getRMBefores(getGFormBefores(sampledForm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gf_befores[QUserId] == rm_befores[QUserId]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotSamples(getDemographicSamples(gf_befores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 answered only after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_afters = getGFormAfters(sampledForm)\n",
    "rm_afters = getRMAfters(sampledForm)\n",
    "gfrm_afters = getRMAfters(getGFormBefores(sampledForm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gf_afters[QUserId] == rm_afters[QUserId]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotSamples(getDemographicSamples(gf_afters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 answered both before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gf_both = getSurveysOfUsersWhoAnsweredBoth(sampledForm, gfMode = True, rmMode = False)\n",
    "rm_both = getSurveysOfUsersWhoAnsweredBoth(sampledForm, gfMode = False, rmMode = True)\n",
    "gfrm_both = getSurveysOfUsersWhoAnsweredBoth(sampledForm, gfMode = True, rmMode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotSamples(getDemographicSamples(gf_both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotSamples(getDemographicSamples(rm_both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotSamples(getDemographicSamples(gfrm_both))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 pretest vs posttest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.4.1 phase1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotBasicStats(sampledForm, horizontalPlot=True, sortedAlong=\"progression\", figsize=(20,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Per demography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 English speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cohortEN = sampledForm[sampledForm[QLanguage] == enLanguageID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(cohortEN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 French speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohortFR = sampledForm[sampledForm[QLanguage] == frLanguageID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(cohortFR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohortF = sampledForm[sampledForm[QGender] == 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(cohortF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.4 Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cohortM = sampledForm[sampledForm[QGender] == 'Male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(cohortM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.5 biologists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### strict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cohortBioS = getSurveysOfBiologists(sampledForm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(cohortBioS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### broad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohortBioB = getSurveysOfBiologists(sampledForm, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(cohortBioB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.6 gamers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### strict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cohortGamS = getSurveysOfGamers(sampledForm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(cohortGamS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### broad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohortGamB = getSurveysOfGamers(sampledForm, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(cohortGamB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 answered only after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 answers to scientific questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sciBinarizedBefore = getAllBinarized(_form = getRMBefores(sampledForm))\n",
    "#sciBinarizedBefore = getAllBinarized(getGFBefores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        sciBinarizedBefore,\n",
    "                        _abs=True,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlations on survey questions before',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "thisClustermap, overlay = plotCorrelationMatrix(\n",
    "                        sciBinarizedBefore,\n",
    "                        _abs=True,\n",
    "                        _clustered=True,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _metric='correlation'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sciBinarizedAfter = getAllBinarized(_form = getRMAfters(sampledForm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        sciBinarizedAfter,\n",
    "                        _abs=True,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlations on survey questions after',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "thisClustermap, overlay = plotCorrelationMatrix(\n",
    "                        sciBinarizedAfter,\n",
    "                        _abs=True,\n",
    "                        _clustered=True,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _metric='correlation'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thisClustermap.ax_heatmap.annotate(overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dir(thisClustermap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dir(thisClustermap.ax_heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vars(thisClustermap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vars(thisClustermap.ax_heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 answers to all questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allQuestions = correctAnswers + demographicAnswers\n",
    "\n",
    "allBinarized = getAllBinarized(_source = allQuestions, _form = sampledForm)\n",
    "allBinarizedBefore = getAllBinarized(_source = allQuestions, _form = getRMBefores(sampledForm))\n",
    "allBinarizedAfter = getAllBinarized(_source = allQuestions, _form = getRMAfters(sampledForm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        allBinarized,\n",
    "                        _abs=True,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlation of all answers',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thisClustermap, overlay = plotCorrelationMatrix(\n",
    "                        allBinarizedAfter,\n",
    "                        _abs=True,\n",
    "                        _clustered=True,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _metric='correlation'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 answers to all questions, only before having played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        allBinarizedBefore,\n",
    "                        _abs=True,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlations on all questions before',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thisClustermap, overlay = plotCorrelationMatrix(\n",
    "                        allBinarizedBefore,\n",
    "                        _abs=True,\n",
    "                        _clustered=True,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _metric='correlation'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 answers to all questions, only after having played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCorrelationMatrix(\n",
    "                        allBinarizedAfter,\n",
    "                        _abs=True,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlation of all answers after',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Game sessions\n",
    "<a id=sessions />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#startDate = minimum152Date\n",
    "#endDate = maximum152Date\n",
    "\n",
    "startDate = rmdf['userTime'].min().date() - datetime.timedelta(days=1)\n",
    "endDate = rmdf['userTime'].max().date() + datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesPerDay = rmdf['userTime'].map(lambda t: t.date()).value_counts().sort_index()\n",
    "plotPerDay(valuesPerDay, title='RedMetrics events', startDate=startDate, endDate=endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesPerDay[pd.to_datetime('2017-09-01', utc=True).date():pd.to_datetime('2017-09-30', utc=True).date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesPerDay = rmdf[rmdf['type'] == 'start']['userTime'].map(lambda t: t.date()).value_counts().sort_index()\n",
    "plotPerDay(valuesPerDay, title='sessions', startDate=startDate, endDate=endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesPerDay[pd.to_datetime('2017-09-01', utc=True).date():pd.to_datetime('2017-09-30', utc=True).date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesPerDay = rmdf.groupby('userId').agg({ \"userTime\": np.min })['userTime'].map(lambda t: t.date()).value_counts().sort_index()\n",
    "plotPerDay(valuesPerDay, title='game users', startDate=startDate, endDate=endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesPerDay[pd.to_datetime('2017-09-01', utc=True).date():pd.to_datetime('2017-09-30', utc=True).date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesPerDay = sampledForm.groupby(localplayerguidkey).agg({ QTimestamp: np.min })[QTimestamp].map(lambda t: t.date()).value_counts().sort_index()\n",
    "plotPerDay(valuesPerDay, title='survey answers', startDate=startDate, endDate=endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valuesPerDay[pd.to_datetime('2017-09-01', utc=True).date():pd.to_datetime('2017-09-30', utc=True).date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beforesPerDay = sampledForm[sampledForm[QTemporality] == answerTemporalities[0]].groupby(localplayerguidkey).agg({ QTimestamp: np.min })[QTimestamp].map(lambda t: t.date()).value_counts().sort_index()\n",
    "aftersPerDay = sampledForm[sampledForm[QTemporality] == answerTemporalities[1]].groupby(localplayerguidkey).agg({ QTimestamp: np.min })[QTimestamp].map(lambda t: t.date()).value_counts().sort_index()\n",
    "undefinedPerDay = sampledForm[sampledForm[QTemporality] == answerTemporalities[2]].groupby(localplayerguidkey).agg({ QTimestamp: np.min })[QTimestamp].map(lambda t: t.date()).value_counts().sort_index()\n",
    "\n",
    "plotPerDay(beforesPerDay, title='survey befores', startDate=startDate, endDate=endDate)\n",
    "plotPerDay(aftersPerDay, title='survey afters', startDate=startDate, endDate=endDate)\n",
    "plotPerDay(undefinedPerDay, title='survey undefined', startDate=startDate, endDate=endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Per session and per user analysis\n",
    "<a id=peruser />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. User comparison\n",
    "<a id=usercomp />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do: transfer part of 1.3's \"'Google form analysis' functions tinkering\" code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## percentagesCrossCorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretests = gform[gform[QTemporality] == answerTemporalities[0]]\n",
    "#pretests[pretests[QBBFunctionPLASMID] == ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized = sciBinarizedBefore\n",
    "intermediaryNumerator = getCrossCorrectAnswers(binarized).round().astype(int)*100\n",
    "percentagesCrossCorrect = (intermediaryNumerator / binarized.shape[0]).round().astype(int)\n",
    "totalPerQuestion = np.dot(np.ones(binarized.shape[0]), binarized)\n",
    "sciBinarizedBefore.columns[totalPerQuestion == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPercentageCrossCorrect(binarized, figsize=(40,100)):\n",
    "    \n",
    "    cbar_kws = dict(orientation= \"horizontal\")\n",
    "    #cbar_kws = dict(orientation= \"horizontal\",location=\"top\")\n",
    "    #cbar_kws = dict(orientation= \"horizontal\", position=\"top\")\n",
    "    \n",
    "    intermediaryNumerator = getCrossCorrectAnswers(binarized).round().astype(int)*100\n",
    "    percentagesCrossCorrect = (intermediaryNumerator / binarized.shape[0]).round().astype(int)\n",
    "    _fig = plt.figure(figsize=figsize)\n",
    "    _ax = plt.subplot(121)\n",
    "    _ax.set_title('percentage correct')\n",
    "    sns.heatmap(percentagesCrossCorrect,ax=_ax,cmap=plt.cm.jet,square=True,annot=True,fmt='d',cbar_kws=cbar_kws)\n",
    "    \n",
    "    totalPerQuestion = np.dot(np.ones(binarized.shape[0]), binarized)\n",
    "    totalPerQuestion[totalPerQuestion == 0] = 1\n",
    "    percentagesConditionalCrossCorrect = (intermediaryNumerator / totalPerQuestion).round().astype(int).fillna(0)\n",
    "    _ax = plt.subplot(122)\n",
    "    _ax.set_title('percentage correct, conditionnally: p(y | x)')\n",
    "    sns.heatmap(percentagesConditionalCrossCorrect,ax=_ax,cmap=plt.cm.jet,square=True,annot=True,fmt='d',cbar_kws=cbar_kws)\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "getPercentageCrossCorrect(sciBinarizedBefore, figsize=(40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getPercentageCrossCorrect(sciBinarizedAfter, figsize=(40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small sample\n",
    "#allData = getAllUserVectorData( getAllUsers( rmdf )[:10] )\n",
    "\n",
    "# complete set\n",
    "#allData = getAllUserVectorData( getAllUsers( rmdf ) )\n",
    "\n",
    "# subjects who answered the sampledForm\n",
    "allData = getAllUserVectorData( getAllResponders(sampledForm), _source = correctAnswers )\n",
    "\n",
    "# 10 subjects who answered the sampledForm\n",
    "#allData = getAllUserVectorData( getAllResponders(sampledForm)[:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pretestData = getAllUserVectorData( sampledForm[sampledForm[QTemporality] == answerTemporalities[0]], _source = correctAnswers )\n",
    "#posttestData = getAllUserVectorData( sampledForm[sampledForm[QTemporality] == answerTemporalities[1]], _source = correctAnswers )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAllUserVectorDataCorrelationMatrix(allData.T, _abs=True, _figsize = (40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allBinarized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Game map\n",
    "<a id=map />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#players = rmdf.loc[:, playerFilteringColumns]\n",
    "players = safeGetNormalizedRedMetricsCSV( rmdf )\n",
    "players.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#players = players.dropna(how='any')\n",
    "#players.head(1)\n",
    "#rmdf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#players = players[~players['userId'].isin(excludedIDs)];\n",
    "#players.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sessions (filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionscount = players[\"sessionId\"].nunique()\n",
    "sessionscount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sessions of dev IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uniqueplayers = players['userId']\n",
    "uniqueplayers = uniqueplayers.unique()\n",
    "uniqueplayers.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#uniqueplayers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uniqueplatforms = players['customData.platform'].unique()\n",
    "uniqueplatforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints passed / furthest checkpoint (unfiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = rmdf.loc[:, ['type', 'section', 'sessionId']]\n",
    "checkpoints = checkpoints[checkpoints['type']=='reach'].loc[:,['section','sessionId']]\n",
    "checkpoints = checkpoints[checkpoints['section'].str.startswith('tutorial', na=False)]\n",
    "checkpoints = checkpoints.groupby(\"sessionId\")\n",
    "checkpoints = checkpoints.max()\n",
    "#len(checkpoints)\n",
    "checkpoints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxCheckpointTable = pd.DataFrame({\"maxCheckpoint\" : checkpoints.values.flatten()})\n",
    "maxCheckpointCounts = maxCheckpointTable[\"maxCheckpoint\"].value_counts()\n",
    "maxCheckpointCounts['Start'] = None\n",
    "maxCheckpointCounts = maxCheckpointCounts.sort_index()\n",
    "print('\\nmaxCheckpointCounts=\\n{0}'.format(str(maxCheckpointCounts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "maxCheckpointCountsTable = pd.DataFrame({\"maxCheckpoint\" : maxCheckpointCounts.values})\n",
    "maxCheckpointCountsTableCount = maxCheckpointCountsTable.sum(0)[0]\n",
    "maxCheckpointCountsTableCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoints.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCheckpointCountsTable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCheckpointCountsTable.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "genericTreatment( maxCheckpointCountsTable, \"best checkpoint reached\", \"game sessions\", 0, maxCheckpointCountsTableCount, False, True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starts = rmdf.loc[:, checkpointsRelevantColumns]\n",
    "#starts = checkpoints[checkpoints['type']=='start'].loc[:,['playerId']]\n",
    "#starts = checkpoints[checkpoints['section'].str.startswith('tutorial', na=False)]\n",
    "#starts = checkpoints.groupby(\"playerId\")\n",
    "#starts = checkpoints.max()\n",
    "#starts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTutorial1Count = sessionscount\n",
    "neverReachedGameSessionCount = startTutorial1Count - maxCheckpointCountsTableCount\n",
    "fullMaxCheckpointCounts = maxCheckpointCounts\n",
    "fullMaxCheckpointCounts['Start'] = neverReachedGameSessionCount\n",
    "fullMaxCheckpointCountsTable = pd.DataFrame({\"fullMaxCheckpoint\" : fullMaxCheckpointCounts.values})\n",
    "\n",
    "genericTreatment( fullMaxCheckpointCountsTable, \"best checkpoint reached\", \"game sessions\", 0, startTutorial1Count, False, True )\n",
    "\n",
    "print('\\nfullMaxCheckpointCountsTable=\\n{0}'.format(fullMaxCheckpointCountsTable))\n",
    "fullMaxCheckpointCountsTable.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration of playing sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "durations = players.groupby(\"sessionId\").agg({ \"serverTime\": [ np.min, np.max  ] })\n",
    "durations[\"duration\"] = pd.to_datetime(durations[\"serverTime\"][\"amax\"]) - pd.to_datetime(durations[\"serverTime\"][\"amin\"])\n",
    "durations[\"duration\"] = durations[\"duration\"].map(lambda x: np.timedelta64(x, 's'))\n",
    "durations = durations.sort_values(by=['duration'], ascending=[False])\n",
    "durations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#durations.loc[:,'duration']\n",
    "#durations = durations[4:]\n",
    "durations[\"duration_seconds\"] = durations[\"duration\"].map(lambda x: pd.Timedelta(x).seconds)\n",
    "maxDuration = np.max(durations[\"duration_seconds\"])\n",
    "durations[\"duration_rank\"] = durations[\"duration_seconds\"].rank(ascending=False)\n",
    "durations.plot(x=\"duration_rank\", y=\"duration_seconds\")\n",
    "plt.xlabel(\"game session\")\n",
    "plt.ylabel(\"time played (s)\")\n",
    "plt.legend('')\n",
    "plt.xlim(0, sessionscount)\n",
    "plt.ylim(0, maxDuration)\n",
    "durations[\"duration_seconds\"].describe()\n",
    "#durations.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
