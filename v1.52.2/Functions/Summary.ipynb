{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hero.Coli Data Analysis Summary\n",
    "\n",
    "Interactive list of readworthy results from Hero.Coli data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "[Preparation](#preparation)\n",
    "1. [Google form analysis](#sampledForm)\n",
    "2. [Game sessions](#sessions)\n",
    "3. [Per session and per user analysis](#peruser)\n",
    "4. [User comparison](#usercomp)\n",
    "5. [Game map](#map)\n",
    "    1. [List of questions](#qlist)\n",
    "    2. [English](#enform)\n",
    "    3. [French](#frform)\n",
    "    4. [Language selection](#langsel)\n",
    "3. [Basic operations](#basicops)\n",
    "4. [Checkpoint / Question matching](#checkquestmatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "<a id=preparation />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run \"../Functions/6. Time analysis.ipynb\"\n",
    "%run \"../Functions/Plot.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the sample here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampledForm = samplePlaytestPretestPosttestUniqueProfilesVolunteers.copy()\n",
    "sampledForm = samplePlaytestPretestPosttestUniqueProfilesVolunteersPhase1.copy()\n",
    "#sampledForm = samplePlaytestPretestPosttestUniqueProfilesVolunteersPhase2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmdf = rmdfPlaytestPretestPosttestUniqueProfilesVolunteers.copy()\n",
    "rmdf = rmdfPlaytestPretestPosttestUniqueProfilesVolunteersPhase1.copy()\n",
    "#rmdf = rmdfPlaytestPretestPosttestUniqueProfilesVolunteersPhase2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# small sample\n",
    "#allData = getAllUserVectorData( getAllUsers( rmdf )[:10] )\n",
    "\n",
    "# complete set\n",
    "#allData = getAllUserVectorData( getAllUsers( rmdf ) )\n",
    "\n",
    "# subjects who answered the sampledForm\n",
    "allData = getAllUserVectorData( getAllResponders(sampledForm), _rmDF = rmdf, _gfDF = sampledForm, _source = correctAnswers + demographicAnswers )\n",
    "\n",
    "# 10 subjects who answered the sampledForm\n",
    "#allData = getAllUserVectorData( getAllResponders(sampledForm)[:10] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Google form analysis\n",
    "<a id=sampledForm />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sample:               gform\")\n",
    "print(\"surveys:              %s\" % len(gform))\n",
    "print(\"unique users:         %s\" % getUniqueUserCount(gform))\n",
    "print(\"RM before:            %s\" % len(gform[gform[QTemporality] == answerTemporalities[0]]))\n",
    "print(\"GF before:            %s\" % len(getGFormBefores(gform)))\n",
    "print(\"RM after:             %s\" % len(gform[gform[QTemporality] == answerTemporalities[1]]))\n",
    "print(\"GF after:             %s\" % len(getGFormAfters(gform)))\n",
    "print(\"unique biologists:    %s\" % getUniqueUserCount(getSurveysOfBiologists(gform)))\n",
    "print(\"unique gamers:        %s\" % getUniqueUserCount(getSurveysOfGamers(gform)))\n",
    "print(\"unique perfect users: %s\" % getUniqueUserCount(getSurveysOfUsersWhoAnsweredBoth(gform)))\n",
    "print(\"unique perfect users: %s\" % getPerfectPretestPostestPairsCount(gform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sample:               sampledForm\")\n",
    "print(\"surveys:              %s\" % len(sampledForm))\n",
    "print(\"unique users:         %s\" % getUniqueUserCount(sampledForm))\n",
    "print(\"RM before:            %s\" % len(sampledForm[sampledForm[QTemporality] == answerTemporalities[0]]))\n",
    "print(\"GF before:            %s\" % len(getGFormBefores(sampledForm)))\n",
    "print(\"RM after:             %s\" % len(sampledForm[sampledForm[QTemporality] == answerTemporalities[1]]))\n",
    "print(\"GF after:             %s\" % len(getGFormAfters(sampledForm)))\n",
    "print(\"unique biologists:    %s\" % getUniqueUserCount(getSurveysOfBiologists(sampledForm)))\n",
    "print(\"unique gamers:        %s\" % getUniqueUserCount(getSurveysOfGamers(sampledForm)))\n",
    "print(\"unique perfect users: %s\" % getUniqueUserCount(getSurveysOfUsersWhoAnsweredBoth(sampledForm)))\n",
    "print(\"unique perfect users: %s\" % getPerfectPretestPostestPairsCount(sampledForm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### formatted version for nice display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"category | count\")\n",
    "print(\"--- | ---\")\n",
    "print(\"sample | gform\")\n",
    "print(\"surveys | %s\" % len(gform))\n",
    "print(\"unique users | %s\" % getUniqueUserCount(gform))\n",
    "print(\"RM before | %s\" % len(gform[gform[QTemporality] == answerTemporalities[0]]))\n",
    "print(\"GF before | %s\" % len(getGFormBefores(gform)))\n",
    "print(\"RM after | %s\" % len(gform[gform[QTemporality] == answerTemporalities[1]]))\n",
    "print(\"GF after | %s\" % len(getGFormAfters(gform)))\n",
    "print(\"unique biologists | %s\" % getUniqueUserCount(getSurveysOfBiologists(gform)))\n",
    "print(\"unique gamers | %s\" % getUniqueUserCount(getSurveysOfGamers(gform)))\n",
    "print(\"unique perfect users | %s\" % getUniqueUserCount(getSurveysOfUsersWhoAnsweredBoth(gform)))\n",
    "print(\"unique perfect users | %s\" % getPerfectPretestPostestPairsCount(gform))\n",
    "print()\n",
    "#print(\"(\" + str(pd.to_datetime('today').date()) + \")\")\n",
    "print(\"(\"+dataFilesNamesStem+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"category | count\")\n",
    "print(\"--- | ---\")\n",
    "print(\"sample | sampledForm\")\n",
    "print(\"surveys | %s\" % len(sampledForm))\n",
    "print(\"unique users | %s\" % getUniqueUserCount(sampledForm))\n",
    "print(\"RM before | %s\" % len(sampledForm[sampledForm[QTemporality] == answerTemporalities[0]]))\n",
    "print(\"GF before | %s\" % len(getGFormBefores(sampledForm)))\n",
    "print(\"RM after | %s\" % len(sampledForm[sampledForm[QTemporality] == answerTemporalities[1]]))\n",
    "print(\"GF after | %s\" % len(getGFormAfters(sampledForm)))\n",
    "print(\"unique biologists | %s\" % getUniqueUserCount(getSurveysOfBiologists(sampledForm)))\n",
    "print(\"unique gamers | %s\" % getUniqueUserCount(getSurveysOfGamers(sampledForm)))\n",
    "print(\"unique perfect users | %s\" % getUniqueUserCount(getSurveysOfUsersWhoAnsweredBoth(sampledForm)))\n",
    "print(\"unique perfect users | %s\" % getPerfectPretestPostestPairsCount(sampledForm))\n",
    "print()\n",
    "#print(\"(\" + str(pd.to_datetime('today').date()) + \")\")\n",
    "print(\"(\"+dataFilesNamesStem+\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 complete sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotSamples(getDemographicSamples(sampledForm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(sampledForm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Per temporality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 answered only before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_befores = getGFormBefores(sampledForm)\n",
    "rm_befores = getRMBefores(sampledForm)\n",
    "gfrm_befores = getRMBefores(getGFormBefores(sampledForm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gf_befores[QUserId] == rm_befores[QUserId]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotSamples(getDemographicSamples(gf_befores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 answered only after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_afters = getGFormAfters(sampledForm)\n",
    "rm_afters = getRMAfters(sampledForm)\n",
    "gfrm_afters = getRMAfters(getGFormBefores(sampledForm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gf_afters[QUserId] == rm_afters[QUserId]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotSamples(getDemographicSamples(gf_afters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 answered both before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gf_both = getSurveysOfUsersWhoAnsweredBoth(sampledForm, gfMode = True, rmMode = False)\n",
    "rm_both = getSurveysOfUsersWhoAnsweredBoth(sampledForm, gfMode = False, rmMode = True)\n",
    "gfrm_both = getSurveysOfUsersWhoAnsweredBoth(sampledForm, gfMode = True, rmMode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotSamples(getDemographicSamples(gf_both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotSamples(getDemographicSamples(rm_both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotSamples(getDemographicSamples(gfrm_both))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 pretest vs posttest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.4.1 phase1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matrixToDisplay = plotBasicStats(sampledForm, horizontalPlot=True, sortedAlong=\"progression\", figsize=(20,4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrixToDisplay.to_csv(\"../../data/sortedPrePostProgression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrixToDisplay.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Per demography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 English speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cohortEN = sampledForm[sampledForm[QLanguage] == enLanguageID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(cohortEN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 French speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohortFR = sampledForm[sampledForm[QLanguage] == frLanguageID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(cohortFR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohortF = sampledForm[sampledForm[QGender] == 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(cohortF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.4 Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cohortM = sampledForm[sampledForm[QGender] == 'Male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(cohortM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.5 biologists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### strict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cohortBioS = getSurveysOfBiologists(sampledForm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(cohortBioS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### broad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohortBioB = getSurveysOfBiologists(sampledForm, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(cohortBioB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.6 gamers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### strict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cohortGamS = getSurveysOfGamers(sampledForm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(cohortGamS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### broad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohortGamB = getSurveysOfGamers(sampledForm, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotSamples(getTemporalitySamples(cohortGamB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 answered only after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 answers to scientific questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sciBinarizedBefore = getAllBinarized(getRMBefores(sampledForm))\n",
    "#sciBinarizedBefore = getAllBinarized(getGFBefores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        sciBinarizedBefore,\n",
    "                        _abs=False,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlations on survey questions before',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "thisClustermap, overlay = plotCorrelationMatrix(\n",
    "                        sciBinarizedBefore,\n",
    "                        _abs=True,\n",
    "                        _clustered=True,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _metric='correlation'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sciBinarizedAfter = getAllBinarized(getRMAfters(sampledForm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        sciBinarizedAfter,\n",
    "                        _abs=False,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlations on survey questions after',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "thisClustermap, overlay = plotCorrelationMatrix(\n",
    "                        sciBinarizedAfter,\n",
    "                        _abs=False,\n",
    "                        _clustered=True,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _metric='correlation'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thisClustermap.ax_heatmap.annotate(overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dir(thisClustermap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dir(thisClustermap.ax_heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vars(thisClustermap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vars(thisClustermap.ax_heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 answers to all questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allQuestions = correctAnswers + demographicAnswers\n",
    "\n",
    "allBinarized = getAllBinarized(sampledForm, _source = allQuestions)\n",
    "allBinarizedBefore = getAllBinarized(getRMBefores(sampledForm), _source = allQuestions)\n",
    "allBinarizedAfter = getAllBinarized(getRMAfters(sampledForm), _source = allQuestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        allBinarized,\n",
    "                        _abs=True,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlation of all answers',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thisClustermap, overlay = plotCorrelationMatrix(\n",
    "                        allBinarizedAfter,\n",
    "                        _abs=True,\n",
    "                        _clustered=True,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _metric='correlation'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 answers to all questions, only before having played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotCorrelationMatrix( _binarizedMatrix, _title='Questions\\' Correlations', _abs=False, _clustered=False, _questionNumbers=False ):\n",
    "plotCorrelationMatrix(\n",
    "                        allBinarizedBefore,\n",
    "                        _abs=False,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlations on all questions before',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thisClustermap, overlay = plotCorrelationMatrix(\n",
    "                        allBinarizedBefore,\n",
    "                        _abs=True,\n",
    "                        _clustered=True,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _metric='correlation'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 answers to all questions, only after having played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCorrelationMatrix(\n",
    "                        allBinarizedAfter,\n",
    "                        _abs=False,\n",
    "                        _clustered=False,\n",
    "                        _questionNumbers=True,\n",
    "                        _annot = True,\n",
    "                        _figsize = (20,20),\n",
    "                        _title='Correlation of all answers after',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Game sessions\n",
    "<a id=sessions />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#startDate = minimum152Date\n",
    "#endDate = maximum152Date\n",
    "\n",
    "startDate = rmdf['userTime'].min().date() - datetime.timedelta(days=1)\n",
    "endDate = rmdf['userTime'].max().date() + datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesPerDay = rmdf['userTime'].map(lambda t: t.date()).value_counts().sort_index()\n",
    "plotPerDay(valuesPerDay, title='RedMetrics events', startDate=startDate, endDate=endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesPerDay[pd.to_datetime('2017-09-01', utc=True).date():pd.to_datetime('2017-09-30', utc=True).date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesPerDay = rmdf[rmdf['type'] == 'start']['userTime'].map(lambda t: t.date()).value_counts().sort_index()\n",
    "plotPerDay(valuesPerDay, title='sessions', startDate=startDate, endDate=endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesPerDay[pd.to_datetime('2017-09-01', utc=True).date():pd.to_datetime('2017-09-30', utc=True).date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesPerDay = rmdf.groupby('userId').agg({ \"userTime\": np.min })['userTime'].map(lambda t: t.date()).value_counts().sort_index()\n",
    "plotPerDay(valuesPerDay, title='game users', startDate=startDate, endDate=endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesPerDay[pd.to_datetime('2017-09-01', utc=True).date():pd.to_datetime('2017-09-30', utc=True).date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesPerDay = sampledForm.groupby(localplayerguidkey).agg({ QTimestamp: np.min })[QTimestamp].map(lambda t: t.date()).value_counts().sort_index()\n",
    "plotPerDay(valuesPerDay, title='survey answers', startDate=startDate, endDate=endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valuesPerDay[pd.to_datetime('2017-09-01', utc=True).date():pd.to_datetime('2017-09-30', utc=True).date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beforesPerDay = sampledForm[sampledForm[QTemporality] == answerTemporalities[0]].groupby(localplayerguidkey).agg({ QTimestamp: np.min })[QTimestamp].map(lambda t: t.date()).value_counts().sort_index()\n",
    "aftersPerDay = sampledForm[sampledForm[QTemporality] == answerTemporalities[1]].groupby(localplayerguidkey).agg({ QTimestamp: np.min })[QTimestamp].map(lambda t: t.date()).value_counts().sort_index()\n",
    "undefinedPerDay = sampledForm[sampledForm[QTemporality] == answerTemporalities[2]].groupby(localplayerguidkey).agg({ QTimestamp: np.min })[QTimestamp].map(lambda t: t.date()).value_counts().sort_index()\n",
    "\n",
    "plotPerDay(beforesPerDay, title='survey befores', startDate=startDate, endDate=endDate)\n",
    "plotPerDay(aftersPerDay, title='survey afters', startDate=startDate, endDate=endDate)\n",
    "plotPerDay(undefinedPerDay, title='survey undefined', startDate=startDate, endDate=endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Per session and per user analysis\n",
    "<a id=peruser />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. User comparison\n",
    "<a id=usercomp />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do: transfer part of 1.3's \"'Google form analysis' functions tinkering\" code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## percentagesCrossCorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretests = gform[gform[QTemporality] == answerTemporalities[0]]\n",
    "#pretests[pretests[QBBFunctionPlasmid] == ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized = sciBinarizedBefore\n",
    "intermediaryNumerator = getCrossCorrectAnswers(binarized).round().astype(int)*100\n",
    "percentagesCrossCorrect = (intermediaryNumerator / binarized.shape[0]).round().astype(int)\n",
    "totalPerQuestion = np.dot(np.ones(binarized.shape[0]), binarized)\n",
    "sciBinarizedBefore.columns[totalPerQuestion == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPercentageCrossCorrect(binarized, figsize=(40,100)):\n",
    "    \n",
    "    cbar_kws = dict(orientation= \"horizontal\")\n",
    "    #cbar_kws = dict(orientation= \"horizontal\",location=\"top\")\n",
    "    #cbar_kws = dict(orientation= \"horizontal\", position=\"top\")\n",
    "    \n",
    "    intermediaryNumerator = getCrossCorrectAnswers(binarized).round().astype(int)*100\n",
    "    percentagesCrossCorrect = (intermediaryNumerator / binarized.shape[0]).round().astype(int)\n",
    "    _fig = plt.figure(figsize=figsize)\n",
    "    _ax = plt.subplot(121)\n",
    "    _ax.set_title('percentage correct')\n",
    "    sns.heatmap(\n",
    "        percentagesCrossCorrect,\n",
    "        ax=_ax,\n",
    "        cmap=plt.cm.jet,\n",
    "        square=True,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cbar_kws=cbar_kws,\n",
    "        vmin=0,\n",
    "        vmax=100,\n",
    "    )\n",
    "    \n",
    "    totalPerQuestion = np.dot(np.ones(binarized.shape[0]), binarized)\n",
    "    totalPerQuestion[totalPerQuestion == 0] = 1\n",
    "    percentagesConditionalCrossCorrect = (intermediaryNumerator / totalPerQuestion).round().astype(int).fillna(0)\n",
    "    _ax = plt.subplot(122)\n",
    "    _ax.set_title('percentage correct, conditionnally: p(y | x)')\n",
    "    sns.heatmap(\n",
    "        percentagesConditionalCrossCorrect,\n",
    "        ax=_ax,\n",
    "        cmap=plt.cm.jet,\n",
    "        square=True,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cbar_kws=cbar_kws,\n",
    "        vmin=0,\n",
    "        vmax=100,\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "getPercentageCrossCorrect(sciBinarizedBefore, figsize=(40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getPercentageCrossCorrect(sciBinarizedAfter, figsize=(40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# small sample\n",
    "#allData = getAllUserVectorData( getAllUsers( rmdf )[:10] )\n",
    "\n",
    "# complete set\n",
    "#allData = getAllUserVectorData( getAllUsers( rmdf ) )\n",
    "\n",
    "# subjects who answered the sampledForm\n",
    "allData = getAllUserVectorData( getAllResponders(sampledForm), _source = correctAnswers + demographicAnswers, _rmDF = rmdf, _gfDF = sampledForm )\n",
    "\n",
    "# 10 subjects who answered the sampledForm\n",
    "#allData = getAllUserVectorData( getAllResponders(sampledForm)[:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sampledForm), len(getAllResponders(sampledForm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matrixToDisplay = plotBasicStats(sampledForm, horizontalPlot=True, sortedAlong=\"progression\", figsize=(20,4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectCount = allData.shape[1]\n",
    "measuredPretest = 100*allData.loc[pretestScientificQuestions,:].sum(axis='columns')/subjectCount\n",
    "measuredPretest.index = scientificQuestions\n",
    "measuredPosttest = 100*allData.loc[posttestScientificQuestions,:].sum(axis='columns')/subjectCount\n",
    "measuredPosttest.index = scientificQuestions\n",
    "measuredDelta2 = (measuredPosttest - measuredPretest)\n",
    "measuredDelta2 = pd.DataFrame(measuredDelta2.round().astype(int))\n",
    "measuredDelta2.columns = [\"measuredDelta2\"]\n",
    "measuredDelta2 = measuredDelta2.sort_values(by = \"measuredDelta2\", ascending = True).T\n",
    "_fig = plt.figure(figsize=(20,2))\n",
    "_ax1 = plt.subplot(111)\n",
    "_ax1.set_title(\"measuredDelta2\")\n",
    "sns.heatmap(\n",
    "            measuredDelta2,\n",
    "            ax=_ax1,\n",
    "            cmap=plt.cm.jet,\n",
    "            square=True,\n",
    "            annot=True,\n",
    "            fmt='d',\n",
    "            vmin=0,\n",
    "            vmax=100,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(matrixToDisplay.loc['progression',scientificQuestions] - measuredDelta2.loc['measuredDelta2',scientificQuestions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF = pd.DataFrame(columns=[\n",
    "    'pretest1', 'posttest1', 'measuredDelta',\n",
    "    'pretest2', 'posttest2', 'matrixToDisplay'], data = 0, index= scientificQuestions)\n",
    "testDF['pretest1'] = measuredPretest\n",
    "testDF['posttest1'] = measuredPosttest\n",
    "testDF['measuredDelta'] = measuredDelta2.T['measuredDelta2']\n",
    "testDF['pretest2'] = matrixToDisplay.T['pretest'][scientificQuestions]\n",
    "testDF['posttest2'] = matrixToDisplay.T['posttest'][scientificQuestions]\n",
    "testDF['matrixToDisplay'] = matrixToDisplay.T['progression'][scientificQuestions]\n",
    "testDF = testDF.round().astype(int)\n",
    "testDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measuredDelta = allData.loc[deltaScientificQuestions,:].sum(axis='columns')\n",
    "measuredDelta.mean(), measuredDelta.median()\n",
    "measuredDelta.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pretestData = getAllUserVectorData( sampledForm[sampledForm[QTemporality] == answerTemporalities[0]], _source = correctAnswers )\n",
    "#posttestData = getAllUserVectorData( sampledForm[sampledForm[QTemporality] == answerTemporalities[1]], _source = correctAnswers )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAllUserVectorDataCorrelationMatrix(\n",
    "    allData.T,\n",
    "    _abs=False,\n",
    "    _figsize = (40,40),\n",
    "    _clustered=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "demographicCriteria = demographicQuestions.copy()\n",
    "\n",
    "overallScoreCriteria = [\"scorepretest\", \"scoreposttest\", \"scoredelta\",]\n",
    "\n",
    "stemTimesCriteria = [\"ch\" + \"{0:0=2d}\".format(i) for i in range(0,15)]\n",
    "completionTimesCriteria = [st + \"completion\" for st in stemTimesCriteria] + [\"completionTime\"]\n",
    "totalTimesCriteria = [st + \"total\" for st in stemTimesCriteria] + [\"totalTime\"]\n",
    "\n",
    "plotAllUserVectorDataCorrelationMatrix(\n",
    "    allData.T,\n",
    "    _abs=False,\n",
    "    _figsize = (20,20),\n",
    "    _clustered=False,\n",
    "    columnSubset=[]\\\n",
    "        + completionTimesCriteria\n",
    "        + totalTimesCriteria\n",
    "        + pretestScientificQuestions\n",
    "        #+ posttestScientificQuestions\n",
    "        #+ deltaScientificQuestions\n",
    "        + overallScoreCriteria\n",
    "        #+ demographicCriteria\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#completers = rmdf[rmdf['type'] == 'complete'][QUserId]\n",
    "#nonCompleter = rmdf[~rmdf[QUserId].isin(completers)][QUserId].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#getUserDataVector(nonCompleter)#.loc[14,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allData.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# completed vs played time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(index=allData.columns, columns=[\"time\", \"posttestScore\", \"deltaScore\",\"completed\"])\n",
    "for userId in data.index:\n",
    "    data.loc[userId, \"time\"] = getPlayedTimeUser(userId, _rmDF = rmdf)['tutorial']['totalSpentTime'].total_seconds()\n",
    "    data.loc[userId, \"posttestScore\"] = allData.loc['scoreposttest', userId]\n",
    "    data.loc[userId, \"deltaScore\"] = allData.loc['scoredelta', userId]\n",
    "    data.loc[userId, \"completed\"] = allData.loc['complete', userId]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = allScores.copy()\n",
    "x2 = completedScores.copy()\n",
    "y = allPlayedTimes.copy()\n",
    "y2 = completedPlayedTimes.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotDF = pd.DataFrame(index = x.index, data = x)\n",
    "plotDF['times'] = y\n",
    "#plotDF\n",
    "#(plotDF['times'] == y).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[\"posttestScore\"]\n",
    "x2 = data[data[\"completed\"]==1][\"posttestScore\"]\n",
    "y = data[\"time\"]\n",
    "y2 = data[data[\"completed\"]==1][\"time\"]\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "ax1 = plt.subplot(121)\n",
    "plt.scatter(x, y)#, c='blue', alpha=0.5)\n",
    "plt.scatter(x2, y2)#, c='red', alpha=0.5)\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('time')\n",
    "plt.title(\"time against score, n=\" + str(len(x)))\n",
    "#ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "plt.scatter(y, x)\n",
    "plt.scatter(y2, x2)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('score')\n",
    "plt.title(\"score against time, n=\" + str(len(x)))\n",
    "ax2.legend(loc='center left', bbox_to_anchor=(-1.2, 0.9), labels =[\"unfinished games\",\"completed games\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[\"posttestScore\"].astype(float)\n",
    "x2 = data[data[\"completed\"]==1][\"posttestScore\"].astype(float)\n",
    "y = data[\"time\"].astype(float)\n",
    "y2 = data[data[\"completed\"]==1][\"time\"].astype(float)\n",
    "\n",
    "# Get the linear models\n",
    "lm_original = np.polyfit(x, y, 1)\n",
    " \n",
    "# calculate the y values based on the co-efficients from the model\n",
    "r_x, r_y = zip(*((i, i*lm_original[0] + lm_original[1]) for i in x))\n",
    " \n",
    "# Put in to a data frame, to keep is all nice\n",
    "lm_original_plot = pd.DataFrame({\n",
    "'scores' : r_x,\n",
    "'times' : r_y\n",
    "})\n",
    "\n",
    "lm_original_plot = lm_original_plot.drop_duplicates()\n",
    "lm_original_plot = lm_original_plot.sort_values(by=\"scores\")\n",
    "lm_original_plot = lm_original_plot.drop(lm_original_plot.index[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "ax = plt.subplot(111)\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x2, y2)\n",
    "# Plot the original data and model\n",
    "#lm_original_plot.plot(kind='line', color='Red', x='scores', y='times', ax=ax)\n",
    "plt.plot('scores', 'times', data=lm_original_plot, color='Red')\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('time') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear regression 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "x = data[\"posttestScore\"].astype(float)\n",
    "x2 = data[data[\"completed\"]==1][\"posttestScore\"].astype(float)\n",
    "y = data[\"time\"].astype(float)\n",
    "y2 = data[data[\"completed\"]==1][\"time\"].astype(float)\n",
    "\n",
    "xReshaped = x.values.reshape(-1, 1)\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(xReshaped, y)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "pred = regr.predict(xReshaped)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y, pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y, pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(x, y, color='black')\n",
    "plt.plot(x, pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.intercept_,regr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear regression 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=x, y=y, color=\"b\")\n",
    "plt.scatter(x2, y2, color='red')\n",
    "plt.xlabel(\"score\")\n",
    "plt.ylabel(\"time played\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = pd.DataFrame(index = range(0, len(xReshaped)), data = xReshaped, columns = ['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data['time'] = y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source https://www.ritchieng.com/machine-learning-evaluate-linear-regression-model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data2 = data.loc[:, [\"time\", \"posttestScore\"]]\n",
    "data2.index = range(0, data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear regression 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import patsy\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STATSMODELS ###\n",
    "\n",
    "timeScoreformula = 'time ~ posttestScore'\n",
    "\n",
    "# create a fitted model\n",
    "lm1 = smf.ols(formula=timeScoreformula, data=data2).fit()\n",
    "\n",
    "# print the coefficients\n",
    "#lm1.params\n",
    "\n",
    "\n",
    "#lm1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the confidence intervals for the model coefficients\n",
    "lm1.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the p-values for the model coefficients\n",
    "# Represents the probability that the coefficient is actually zero\n",
    "lm1.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the R-squared value for the model\n",
    "lm1.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completed vs non-completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STATSMODELS ###\n",
    "timeScoreformula = 'time ~ posttestScore'\n",
    "lm1 = smf.ols(formula=timeScoreformula, data=data2).fit()\n",
    "lm2 = smf.ols(formula=timeScoreformula, data=data2[data2[\"completed\"] == 0]).fit()\n",
    "lm3 = smf.ols(formula=timeScoreformula, data=data2[data2[\"completed\"] == 1]).fit()\n",
    "lm1.rsquared,lm2.rsquared,lm3.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations between durations and score on questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlations between completion time of checkpoint n and score on question Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallScoreCriteria = [\"scorepretest\", \"scoreposttest\", \"scoredelta\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemTimesCriteria = [\"ch\" + \"{0:0=2d}\".format(i) for i in range(0,15)]\n",
    "completionTimesCriteria = [st + \"completion\" for st in stemTimesCriteria] + [\"completionTime\"]\n",
    "totalTimesCriteria = [st + \"total\" for st in stemTimesCriteria] + [\"totalTime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#chosenPrefix = answerTemporalities[0]\n",
    "chosenPrefix = answerTemporalities[1]\n",
    "#chosenPrefix = \"delta\"\n",
    "\n",
    "chosenCriteria = [chosenPrefix + \" \" + q for q in scientificQuestions]\n",
    "\n",
    "durationsScoresCorrelations = pd.DataFrame(index=completionTimesCriteria+totalTimesCriteria, columns=chosenCriteria, data=np.nan)\n",
    "durationsScoresCorrelations = durationsScoresCorrelations.rename(str, axis='rows')\n",
    "annotationMatrix = np.empty(shape=[durationsScoresCorrelations.shape[0], 1], dtype=int)\n",
    "#annotationMatrix2D = np.empty(durationsScoresCorrelations.shape, dtype=str)\n",
    "\n",
    "allData2 = allData.T.rename(str,axis=\"columns\")\n",
    "for i in range(len(durationsScoresCorrelations.index)):\n",
    "    checkpoint = durationsScoresCorrelations.index[i]\n",
    "    allData3 = allData2[allData2[checkpoint] < pd.Timedelta.max.total_seconds()]\n",
    "    annotationMatrix[i] = len(allData3)\n",
    "    for q in durationsScoresCorrelations.columns:\n",
    "        corr = np.corrcoef(allData3[checkpoint], allData3[q])\n",
    "        if corr[0,0] < 0:\n",
    "            print(\"[\" + checkpoint + \";\" + q + \"]:\" + str(corr[0,0]))\n",
    "        durationsScoresCorrelations.loc[checkpoint, q] = corr[0,1]\n",
    "        \n",
    "_fig, (_a0, _a1) = plt.subplots(1,2, gridspec_kw = {'width_ratios':[50, 1]}, figsize=(15,10))\n",
    "\n",
    "_a0.set_title(\"correlations between times and \" + chosenPrefix + \" scores\")\n",
    "sns.heatmap(durationsScoresCorrelations, ax=_a0, cmap=plt.cm.jet, square=True, vmin=-1, vmax=1,)\n",
    "            # annot=annotationMatrix2D\n",
    "            #cbar_kws= {'panchor':(0.0, 0.0)}\n",
    "\n",
    "_a1.set_title(\"\")\n",
    "sns.heatmap(annotationMatrix, ax=_a1, annot=annotationMatrix)\n",
    "\n",
    "_fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getAllResponders(sampledForm), _source = correctAnswers, _rmDF = rmdf\n",
    "#testUserId = \"4731525f-62dd-4128-ab56-3991b403e17e\"\n",
    "#getUserDataVector(testUserId,_source = correctAnswers, _rmDF = rmdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Game map\n",
    "<a id=map />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#players = rmdf.loc[:, playerFilteringColumns]\n",
    "players = safeGetNormalizedRedMetricsCSV( rmdf )\n",
    "players.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#players = players.dropna(how='any')\n",
    "#players.head(1)\n",
    "#rmdf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#players = players[~players['userId'].isin(excludedIDs)];\n",
    "#players.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sessions (filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionscount = players[\"sessionId\"].nunique()\n",
    "sessionscount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sessions of dev IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uniqueplayers = players['userId']\n",
    "uniqueplayers = uniqueplayers.unique()\n",
    "uniqueplayers.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#uniqueplayers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uniqueplatforms = players['customData.platform'].unique()\n",
    "uniqueplatforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints passed / furthest checkpoint (unfiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = rmdf.loc[:, ['type', 'section', 'sessionId']]\n",
    "checkpoints = checkpoints[checkpoints['type']=='reach'].loc[:,['section','sessionId']]\n",
    "checkpoints = checkpoints[checkpoints['section'].str.startswith('tutorial', na=False)]\n",
    "checkpoints = checkpoints.groupby(\"sessionId\")\n",
    "checkpoints = checkpoints.max()\n",
    "#len(checkpoints)\n",
    "checkpoints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxCheckpointTable = pd.DataFrame({\"maxCheckpoint\" : checkpoints.values.flatten()})\n",
    "maxCheckpointCounts = maxCheckpointTable[\"maxCheckpoint\"].value_counts()\n",
    "maxCheckpointCounts['Start'] = None\n",
    "maxCheckpointCounts = maxCheckpointCounts.sort_index()\n",
    "print('\\nmaxCheckpointCounts=\\n{0}'.format(str(maxCheckpointCounts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "maxCheckpointCountsTable = pd.DataFrame({\"maxCheckpoint\" : maxCheckpointCounts.values})\n",
    "maxCheckpointCountsTableCount = maxCheckpointCountsTable.sum(0)[0]\n",
    "maxCheckpointCountsTableCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoints.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCheckpointCountsTable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCheckpointCountsTable.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "genericTreatment( maxCheckpointCountsTable, \"best checkpoint reached\", \"game sessions\", 0, maxCheckpointCountsTableCount, False, True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starts = rmdf.loc[:, checkpointsRelevantColumns]\n",
    "#starts = checkpoints[checkpoints['type']=='start'].loc[:,['playerId']]\n",
    "#starts = checkpoints[checkpoints['section'].str.startswith('tutorial', na=False)]\n",
    "#starts = checkpoints.groupby(\"playerId\")\n",
    "#starts = checkpoints.max()\n",
    "#starts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTutorial1Count = sessionscount\n",
    "neverReachedGameSessionCount = startTutorial1Count - maxCheckpointCountsTableCount\n",
    "fullMaxCheckpointCounts = maxCheckpointCounts\n",
    "fullMaxCheckpointCounts['Start'] = neverReachedGameSessionCount\n",
    "fullMaxCheckpointCountsTable = pd.DataFrame({\"fullMaxCheckpoint\" : fullMaxCheckpointCounts.values})\n",
    "\n",
    "genericTreatment( fullMaxCheckpointCountsTable, \"best checkpoint reached\", \"game sessions\", 0, startTutorial1Count, False, True )\n",
    "\n",
    "print('\\nfullMaxCheckpointCountsTable=\\n{0}'.format(fullMaxCheckpointCountsTable))\n",
    "fullMaxCheckpointCountsTable.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration of playing sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "durations = players.groupby(\"sessionId\").agg({ \"serverTime\": [ np.min, np.max  ] })\n",
    "durations[\"duration\"] = pd.to_datetime(durations[\"serverTime\"][\"amax\"]) - pd.to_datetime(durations[\"serverTime\"][\"amin\"])\n",
    "durations[\"duration\"] = durations[\"duration\"].map(lambda x: np.timedelta64(x, 's'))\n",
    "durations = durations.sort_values(by=['duration'], ascending=[False])\n",
    "durations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#durations.loc[:,'duration']\n",
    "#durations = durations[4:]\n",
    "durations[\"duration_seconds\"] = durations[\"duration\"].map(lambda x: pd.Timedelta(x).seconds)\n",
    "maxDuration = np.max(durations[\"duration_seconds\"])\n",
    "durations[\"duration_rank\"] = durations[\"duration_seconds\"].rank(ascending=False)\n",
    "ax = durations.plot(x=\"duration_rank\", y=\"duration_seconds\")\n",
    "plt.xlabel(\"game session\")\n",
    "plt.ylabel(\"time played (s)\")\n",
    "#plt.legend('')\n",
    "ax.legend_.remove()\n",
    "plt.xlim(0, sessionscount)\n",
    "plt.ylim(0, maxDuration)\n",
    "durations[\"duration_seconds\"].describe()\n",
    "#durations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 vs Phase 2 comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completion rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCompletedRate(_rmdf):\n",
    "    players = _rmdf[QUserId].nunique()\n",
    "    completers = _rmdf[_rmdf['type'] == 'complete'][QUserId].nunique()\n",
    "    return float(completers)/float(players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getCompletedRate(rmdfPlaytestPretestPosttestUniqueProfilesVolunteers),\\\n",
    "getCompletedRate(rmdfPlaytestPretestPosttestUniqueProfilesVolunteersPhase1),\\\n",
    "getCompletedRate(rmdfPlaytestPretestPosttestUniqueProfilesVolunteersPhase2),\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Played time on critical checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getRecordPlayer(rmdf1522, gform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getRecordPlayer(rmdf160, gform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
