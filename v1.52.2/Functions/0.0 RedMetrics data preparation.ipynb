{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n",
    "Imports libraries\n",
    "\n",
    "Loads RedMetrics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import re\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "from random import randint\n",
    "from ipywidgets import FloatProgress,IntProgress,IntText,Text,interact,interactive,IntSlider,FloatSlider\n",
    "from IPython.display import display\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processRMDF1522 = not ('rmdf1522' in globals())\n",
    "processRMDF160 = not ('rmdf160' in globals())\n",
    "processRMDFTest = not ('rmrdftest' in globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### common variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last1522DataFilesNamesStem = \"2018-04-27\"\n",
    "last160DataFilesNamesStem = \"2018-07-05\"\n",
    "dataFilesNamesStem = \"2018-07-05\"\n",
    "\n",
    "dataFolderPath = \"../../data/\"\n",
    "version1522Suffix = '-1.52.2'\n",
    "version160Suffix = '-1.60'\n",
    "processedSuffix = \"-processed\"\n",
    "testUsersSuffix = \"-testUsers\"\n",
    "testSuffix = \".test\"\n",
    "csvEncoding = 'utf-8'\n",
    "csvSuffix = '.csv'\n",
    "\n",
    "tutorialStem = \"tutorial\"\n",
    "tutorial1Stem = tutorialStem + \"1\"\n",
    "tutorial2Stem = tutorialStem + \"2\"\n",
    "checkpointStem = \".Checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapterCount = 11\n",
    "chapterArrayInt = [i for i in range(chapterCount)]\n",
    "chapterArrayStr = sorted(['\"' + str(i) + '\"' for i in chapterArrayInt])\n",
    "\n",
    "checkpointCount = 15\n",
    "checkpointArrayInt = [i for i in range(checkpointCount)]\n",
    "checkpointArrayStr = sorted([tutorialStem + checkpointStem + \"{0:0=2d}\".format(i) for i in checkpointArrayInt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedRMDF1522Path = dataFolderPath + last1522DataFilesNamesStem + version1522Suffix + processedSuffix + csvSuffix\n",
    "processedRMDF160Path  = dataFolderPath + dataFilesNamesStem         + version160Suffix  + processedSuffix + csvSuffix\n",
    "\n",
    "rmrdf1522Path         = dataFolderPath + last1522DataFilesNamesStem + version1522Suffix                   + csvSuffix\n",
    "rmrdf160Path          = dataFolderPath + dataFilesNamesStem         + version160Suffix                    + csvSuffix\n",
    "\n",
    "rmrdfTestPath         = dataFolderPath + dataFilesNamesStem         + testSuffix                          + csvSuffix\n",
    "testUsersPath         = dataFolderPath                              + testUsersSuffix                     + csvSuffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmdfLoadColumnNames = ['id', 'serverTime', 'userTime',\\\n",
    "                   'playerId', 'playerCustomData',\\\n",
    "                   'type', 'coordinates','section',\\\n",
    "                   'customData.biobrick', 'customData.devices',\\\n",
    "                   'customData.slot', 'customData.sound',\\\n",
    "                   'customData','customData.duration',\\\n",
    "                   'customData.nanobot', 'customData.language',\\\n",
    "                   'customData.controls', 'customData.chapter',\\\n",
    "                   'customData.life','customData.source',\\\n",
    "                   'customData.platform','customData.localplayerguid',\\\n",
    "                   'customData.sametab', 'customData.device',\\\n",
    "                   'customData.energy', 'customData.option',\\\n",
    "                   'customData.newtab','customData.dnabit',\\\n",
    "                   'customData.count', 'customData.plasmid',\\\n",
    "                   'customData.total', 'customData.message',\\\n",
    "                   'customData.graphics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### columns\n",
    "# In RedMetrics data, 'playerId' is actually a session ID.\n",
    "# Permanent player IDs are stored as 'localplayerguid' in 'customdata' attached to 'start' events.\n",
    "rmdfMinimalInitializationColumns = ['customData.localplayerguid']\n",
    "rmdfInitializationColumns = ['customData.localplayerguid', 'playerId', 'type', 'serverTime', 'customData.platform']\n",
    "# TODO check use\n",
    "# rmdfRelevantColumns = ['sessionId', 'serverTime', 'userId', 'customData.platform']\n",
    "rmdfPlayerFilteringColumns = ['sessionId', 'userId', 'customData.platform', 'serverTime']\n",
    "rmdfCheckpointsRelevantColumns = ['sessionId', 'userId', 'type', 'section']\n",
    "rmdfRelevantColumns = ['customData.localplayerguid', 'playerId', 'type']\n",
    "rmdfRenamedRelevantColumns = ['userId', 'sessionId', 'type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading\n",
    "### Data format fixes\n",
    "def userIdConverter(uId):\n",
    "    sUID = str(uId)\n",
    "    if(sUID.startswith('n')):# == 'nan' or == 'null'):\n",
    "        return ''\n",
    "    else:\n",
    "        return sUID.replace('\"','')\n",
    "    \n",
    "def sectionConverter(section):\n",
    "    return re.sub(r'(1|2)\\.', '.', section)\n",
    "    #return section.replace(tutorial1Stem, tutorialStem).replace(tutorial2Stem, tutorialStem)\n",
    "\n",
    "# date string to pd.Timestamp\n",
    "#  RedMetrics timestamps are always UTC according to doc\n",
    "#  https://github.com/CyberCRI/RedMetrics/blob/master/API.md\n",
    "rmdfDateparse = lambda x: pd.to_datetime(x, utc=True)\n",
    "\n",
    "def safeGetNormalizedRedMetricsCSV( df ):\n",
    "    return df.rename(index=str, columns={'customData.localplayerguid' : 'userId', 'playerId': 'sessionId'})\n",
    "    \n",
    "def getNormalizedRedMetricsCSV( df ):\n",
    "    newColumns = np.unique(np.concatenate((rmdfMinimalInitializationColumns, df.columns.values)))\n",
    "    return safeGetNormalizedRedMetricsCSV(df.loc[:,newColumns])\n",
    "\n",
    "def writeTestUsers(testUsers):\n",
    "    try:\n",
    "        if (len(testUsers.columns) == 1) & (testUsers.columns[0] == 'userId'):\n",
    "            testUsers = testUsers.sort_values(by='userId')\n",
    "            testUsers.index = range(len(testUsers))\n",
    "            testUsers.to_csv(testUsersPath, encoding=csvEncoding)\n",
    "        else:\n",
    "            print(\"incorrect testUsers parameter\")\n",
    "    except Exception as e:\n",
    "        print(\"writeTestUsers failed: \" + str(e))\n",
    "\n",
    "def writeRMDF(rmdf, rmdfPath):\n",
    "    rmdf.to_csv(rmdfPath, encoding=csvEncoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllSessions( _rmDF, dropna ):\n",
    "    _result = _rmDF.loc[:, rmdfRenamedRelevantColumns]\n",
    "    _result = _result[_result['type']=='start']\n",
    "    _result = _result.drop('type', 1)\n",
    "    if dropna:\n",
    "        _result = _result.dropna(how='any')\n",
    "    return _result\n",
    "\n",
    "# gets sessions which either:\n",
    "#  - have 'android' or '...editor' as platform\n",
    "#  - are in the RedMetrics test channel\n",
    "def getTestSessions(_rmDF, _rmTestDF, includeAndroid = True, includeEditor = True, includeTest = True):\n",
    "\n",
    "    rmDFTestSessions = set()\n",
    "    rmTestDFTestSessions = set()\n",
    "\n",
    "    #  - have 'android' or '...editor' as platform\n",
    "    if(includeAndroid):\n",
    "        rmDFTestSessions |= set(_rmDF[_rmDF['customData.platform'].isin(['\"android\"'])]['sessionId'])\n",
    "    if(includeEditor):\n",
    "        rmDFTestSessions |= set(_rmDF[_rmDF['customData.platform'].apply(lambda s: str(s).endswith('editor\"'))]['sessionId'])\n",
    "    #print(str(len(rmDFTestSessions)))\n",
    "\n",
    "    #  - are in the RedMetrics test channel\n",
    "    if(includeTest):\n",
    "        rmTestDFTestSessions = set(_rmTestDF['sessionId'])\n",
    "    #print(str(len(rmTestDFTestSessions)))\n",
    "\n",
    "    #  - belong to a user who has a session of the type above\n",
    "    # all the sessions above\n",
    "    testSessions = rmDFTestSessions | rmTestDFTestSessions\n",
    "\n",
    "    return testSessions\n",
    "\n",
    "# gets sessions which either:\n",
    "#  - have 'android' or '...editor' as platform\n",
    "#  - are in the RedMetrics test channel\n",
    "#  - belong to a user who has a session of the type above\n",
    "def getTestUsersSessions(\n",
    "    _rmDF,\n",
    "    _rmTestDF,\n",
    "    includeAndroid = True,\n",
    "    includeEditor = True,\n",
    "    includeTest = True,\n",
    "    otherTestUsers = set(),\n",
    "):\n",
    "\n",
    "    # tables of association of user-sessions\n",
    "    rmDFUsersSessions = getAllSessions(_rmDF, False)\n",
    "    # rmTestDFUsersSessions = getAllSessions(_rmTestDF, False)\n",
    "    \n",
    "    # userSessions = pd.concat([rmDFUsersSessions,rmTestDFUsersSessions])\n",
    "    # userSessions = userSessions.drop_duplicates()\n",
    "\n",
    "    testSessions = getTestSessions(_rmDF, _rmTestDF,\n",
    "                                   includeAndroid = includeAndroid, includeEditor = includeEditor, includeTest = includeTest)\n",
    "\n",
    "    # all the test users\n",
    "    ## users from _rmDF who have test sessions\n",
    "    rmDFTestUsers = set(rmDFUsersSessions[rmDFUsersSessions['sessionId'].isin(testSessions)]['userId'].dropna())\n",
    "    ## all the users from _rmTestDF\n",
    "    rmTestDFTestUsers = set(_rmTestDF['userId'].dropna())\n",
    "    rmTestDFTestUsers.remove('')\n",
    "    ## merge\n",
    "    testUsers = otherTestUsers | rmDFTestUsers | rmTestDFTestUsers\n",
    "    # all the sessions of _rmDF which belong to these users\n",
    "    # allTestSessions = set(rmDFUsersSessions[rmDFUsersSessions['userId'].isin(testUsers)]['sessionId'].dropna())\n",
    "    allTestSessions = testSessions | set(rmDFUsersSessions[rmDFUsersSessions['userId'].isin(testUsers)]['sessionId'].dropna())\n",
    "\n",
    "    return (testUsers,allTestSessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the processing of the rmrdfs has already been done,\n",
    "# just load the preprocessed rmdfs\n",
    "#if processRMDF1522:\n",
    "def loadProcessedRMDFs():\n",
    "    ## Try loading the pre-processed dataframe\n",
    "    rmdfTestUsers = set()\n",
    "    rmdf1522 = []\n",
    "    rmdf160 = []\n",
    "    try:\n",
    "\n",
    "        rmdfTestUsers = set(pd.read_csv(testUsersPath, dtype=str)['userId'])\n",
    "        print(\"rmdfTestUsers read_csv success (1/3)\")\n",
    "        \n",
    "        rmdf1522 = pd.read_csv(\\\n",
    "                            processedRMDF1522Path,\\\n",
    "                            dtype=str, parse_dates=['serverTime','userTime'],\\\n",
    "                            date_parser=rmdfDateparse,\\\n",
    "                           )\n",
    "        if rmdf1522.columns[0] == 'Unnamed: 0':\n",
    "            rmdf1522 = rmdf1522.iloc[:,1:]\n",
    "        print(\"rmdf1522 read_csv success (2/3)\")\n",
    "\n",
    "        rmdf160 = pd.read_csv(\\\n",
    "                            processedRMDF160Path,\\\n",
    "                            dtype=str, parse_dates=['serverTime','userTime'],\\\n",
    "                            date_parser=rmdfDateparse,\\\n",
    "                           )\n",
    "        if rmdf160.columns[0] == 'Unnamed: 0':\n",
    "            rmdf160 = rmdf160.iloc[:,1:]\n",
    "        print(\"rmdf160 read_csv success (3/3)\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"rmdfs will be loaded, processed, saved\")\n",
    "\n",
    "    return (rmdfTestUsers, rmdf1522, rmdf160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RMDFTest loading\n",
    "# necessary variables for RMDFTest loading:\n",
    "# dataFolderPath\n",
    "# dataFilesNamesStem\n",
    "# dateparse\n",
    "# userIdConverter\n",
    "# rmdfLoadColumnNames\n",
    "# getNormalizedRedMetricsCSV\n",
    "\n",
    "# raw redmetrics df loading\n",
    "def loadRMRDF(rmdfPath):\n",
    "    rmrdf  = pd.read_csv(\\\n",
    "                            rmdfPath,\\\n",
    "                            dtype=str,\\\n",
    "                            parse_dates=['serverTime','userTime'],\\\n",
    "                            date_parser=rmdfDateparse,\\\n",
    "                            converters={\\\n",
    "                                        'customData.localplayerguid':userIdConverter,\\\n",
    "                                        'section':sectionConverter,\\\n",
    "                                       }\\\n",
    "                         )\n",
    "    rmrdf = rmrdf.loc[:,rmdfLoadColumnNames]\n",
    "    normalizedRMDF = getNormalizedRedMetricsCSV(rmrdf)\n",
    "    return normalizedRMDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing of raw redmetrics dfs\n",
    "# rmdfTestUsers is a set\n",
    "# rmdf1522 is assumed to be set\n",
    "# rmrdfPath raw df path for reading\n",
    "# rmdfPath processed df path for writing\n",
    "def processRMDF(rmrdfPath, rmdfPath, normalizedRMDFTest, rmdfTestUsers):\n",
    "    #print(\"processRMDF start\")\n",
    "    normalizedRMDF = loadRMRDF(rmrdfPath)\n",
    "\n",
    "    #print(\"call to getTestUsersSessions...\")\n",
    "    (rmdfTestUsers, allTestSessions) = getTestUsersSessions(\n",
    "        _rmDF = normalizedRMDF,\n",
    "        _rmTestDF = normalizedRMDFTest,\n",
    "        otherTestUsers = rmdfTestUsers,\n",
    "    )\n",
    "    #print(\"call to getTestUsersSessions done\")\n",
    "    \n",
    "    writeTestUsers(pd.DataFrame(data=list(rmdfTestUsers), columns=['userId']))\n",
    "    \n",
    "    rmdf = normalizedRMDF[~normalizedRMDF['sessionId'].isin(allTestSessions)]\n",
    "\n",
    "    #print(\"userSessions\")\n",
    "    userSessions = rmdf[rmdf['userId']!=''].loc[:,['userId','sessionId']].dropna(how='any').drop_duplicates()\n",
    "    \n",
    "    intProgress = IntProgress(min=0, max=len(userSessions.index))\n",
    "    display(intProgress)\n",
    "    intText = IntText(0)\n",
    "    display(intText)\n",
    "    \n",
    "    #print(\"loop starting\")\n",
    "    for userSessionsIndex in userSessions.index:\n",
    "        intProgress.value += 1\n",
    "        intText.value += 1\n",
    "        \n",
    "        userId = userSessions.loc[userSessionsIndex, 'userId']\n",
    "        sessionId = userSessions.loc[userSessionsIndex, 'sessionId']\n",
    "        rmdf.loc[rmdf['sessionId']==sessionId,'userId'] = userId\n",
    "\n",
    "    #rmdf1522['userId'].nunique(),userSessions['userId'].nunique(),\\\n",
    "    #rmdf1522[~rmdf1522['userId'].isin(userSessions['userId'].unique())],\\\n",
    "    #userSessions[~userSessions['userId'].isin(rmdf1522['userId'].unique())]\n",
    "\n",
    "#### Saving to csv\n",
    "    #print(\"saving to csv\")\n",
    "    writeRMDF(rmdf, rmdfPath)\n",
    "    #print(\"processRMDF done\")\n",
    "    \n",
    "    return (rmdf, rmdfTestUsers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processRMDF1522 = not ('rmdf1522' in globals())\n",
    "processRMDF160 = not ('rmdf160' in globals())\n",
    "processRMDFTest = not ('normalizedRMDFTest' in globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processRMDF1522, processRMDF160, processRMDFTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if processRMDF1522 or processRMDF160 or processRMDFTest:\n",
    "    \n",
    "    ## calls\n",
    "    #print(\"STEP 1\")\n",
    "    (testUsers, rmdf1522, rmdf160) = loadProcessedRMDFs()\n",
    "    #print(type(rmdfTestUsers))\n",
    "\n",
    "    process1522 = (len(rmdf1522) == 0)\n",
    "    process160  = (len(rmdf160)  == 0)\n",
    "\n",
    "    normalizedRMDFTest = []\n",
    "\n",
    "    if process1522 or process160:\n",
    "        #print(\"STEP test\")\n",
    "        normalizedRMDFTest = loadRMRDF(rmrdfTestPath)\n",
    "    if process1522:\n",
    "        #print(\"STEP 1522\")\n",
    "        (rmdf1522, testUsers) = processRMDF(rmrdf1522Path, processedRMDF1522Path, normalizedRMDFTest, testUsers)\n",
    "    if process160:\n",
    "        #print(\"STEP 160\")\n",
    "        (rmdf160, testUsers) = processRMDF(rmrdf160Path, processedRMDF160Path, normalizedRMDFTest, testUsers)\n",
    "    \n",
    "    # concatenation of all redmetrics events pertaining to 1.52.2 survey: rmdf1522 and rmdf160\n",
    "    rmdfConcat = pd.concat([rmdf1522, rmdf160])\n",
    "    rmdfConcat.index = range(0, len(rmdfConcat.index))\n",
    "    \n",
    "    #print(\"STEP done\")\n",
    "#else:\n",
    "    #print(\"all done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmdf1522['userId'].nunique(), rmdf160['userId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmdf1522['userTime'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rdf = pd.concat([part100, \n",
    "                      part131, part132, part133, \n",
    "                      part140, \n",
    "                      part150, part151, part1522])\n",
    "\n",
    "df = getNormalizedRedMetricsCSV(rdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rdf100 = pd.read_csv(\"../../data/1.0.csv\")\n",
    "rdf131 = pd.read_csv(\"../../data/1.31.csv\")\n",
    "rdf132 = pd.read_csv(\"../../data/1.32.csv\")\n",
    "rdf133 = pd.read_csv(\"../../data/1.33.csv\")\n",
    "rdf140 = pd.read_csv(\"../../data/1.40.csv\")\n",
    "rdf150 = pd.read_csv(\"../../data/1.50.csv\")\n",
    "rdf151 = pd.read_csv(\"../../data/1.51.csv\")\n",
    "\n",
    "part100 = rdf100.loc[:,relevantColumns]\n",
    "part131 = rdf131.loc[:,relevantColumns]\n",
    "part132 = rdf132.loc[:,relevantColumns]\n",
    "part133 = rdf133.loc[:,relevantColumns]\n",
    "part140 = rdf140.loc[:,relevantColumns]\n",
    "part150 = rdf150.loc[:,relevantColumns]\n",
    "part151 = rdf151.loc[:,relevantColumns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rdftest = pd.read_csv(\"../../data/2017-10-11.test.csv\")\n",
    "dftest = getNormalizedRedMetricsCSV(rdftest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOD: get rid of warning\n",
    "    \n",
    "    DtypeWarning: Columns (18,22,28,32,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
    "    interactivity=interactivity, compiler=compiler, result=result)\n",
    "\n",
    "using https://stackoverflow.com/questions/24251219/pandas-read-csv-low-memory-and-dtype-options"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
